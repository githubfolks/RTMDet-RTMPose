[10:41:28] Training on: mps (Apple Silicon GPU)

============================================================
IMPROVED TRAINING CONFIGURATION
============================================================
  Epochs: 300
  Batch size: 8
  Base LR: 0.001
  Warmup epochs: 5
  Augmentation: True
  Soft labels: True
  Data samples: 3065
============================================================

/Users/vikram/workspace/RTMDet-RTMPose/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
[10:41:31] Epoch [1/300], Step [0/384], Loss: 5.8501, LR: 0.000010
[10:41:34] Epoch [1/300], Step [20/384], Loss: 5.8402, LR: 0.000010
[10:41:36] Epoch [1/300], Step [40/384], Loss: 5.8600, LR: 0.000010
[10:41:38] Epoch [1/300], Step [60/384], Loss: 5.8129, LR: 0.000010
[10:41:39] Epoch [1/300], Step [80/384], Loss: 5.8361, LR: 0.000010
[10:41:40] Epoch [1/300], Step [100/384], Loss: 5.7931, LR: 0.000010
[10:41:42] Epoch [1/300], Step [120/384], Loss: 5.8096, LR: 0.000010
[10:41:43] Epoch [1/300], Step [140/384], Loss: 5.8478, LR: 0.000010
[10:41:45] Epoch [1/300], Step [160/384], Loss: 5.8416, LR: 0.000010
[10:41:46] Epoch [1/300], Step [180/384], Loss: 5.7820, LR: 0.000010
[10:41:47] Epoch [1/300], Step [200/384], Loss: 5.7775, LR: 0.000010
[10:41:48] Epoch [1/300], Step [220/384], Loss: 5.7894, LR: 0.000010
[10:41:50] Epoch [1/300], Step [240/384], Loss: 5.8038, LR: 0.000010
[10:41:51] Epoch [1/300], Step [260/384], Loss: 5.7981, LR: 0.000010
[10:41:52] Epoch [1/300], Step [280/384], Loss: 5.8051, LR: 0.000010
[10:41:53] Epoch [1/300], Step [300/384], Loss: 5.7582, LR: 0.000010
[10:41:54] Epoch [1/300], Step [320/384], Loss: 5.7737, LR: 0.000010
[10:41:56] Epoch [1/300], Step [340/384], Loss: 5.7217, LR: 0.000010
[10:41:57] Epoch [1/300], Step [360/384], Loss: 5.7796, LR: 0.000010
[10:41:58] Epoch [1/300], Step [380/384], Loss: 5.7333, LR: 0.000010
[10:41:59] Epoch 1 Complete. Avg Loss: 5.7925, LR: 0.000010
  -> New best model saved (loss: 5.7925)
[10:41:59] Epoch [2/300], Step [0/384], Loss: 5.8088, LR: 0.000208
[10:42:00] Epoch [2/300], Step [20/384], Loss: 5.5423, LR: 0.000208
[10:42:02] Epoch [2/300], Step [40/384], Loss: 5.2043, LR: 0.000208
[10:42:03] Epoch [2/300], Step [60/384], Loss: 4.9314, LR: 0.000208
[10:42:04] Epoch [2/300], Step [80/384], Loss: 5.1448, LR: 0.000208
[10:42:06] Epoch [2/300], Step [100/384], Loss: 5.1063, LR: 0.000208
[10:42:07] Epoch [2/300], Step [120/384], Loss: 4.7523, LR: 0.000208
[10:42:08] Epoch [2/300], Step [140/384], Loss: 5.0755, LR: 0.000208
[10:42:09] Epoch [2/300], Step [160/384], Loss: 4.6462, LR: 0.000208
[10:42:10] Epoch [2/300], Step [180/384], Loss: 4.3879, LR: 0.000208
[10:42:12] Epoch [2/300], Step [200/384], Loss: 4.5967, LR: 0.000208
[10:42:13] Epoch [2/300], Step [220/384], Loss: 4.7739, LR: 0.000208
[10:42:14] Epoch [2/300], Step [240/384], Loss: 4.5620, LR: 0.000208
[10:42:16] Epoch [2/300], Step [260/384], Loss: 4.9307, LR: 0.000208
[10:42:17] Epoch [2/300], Step [280/384], Loss: 4.9524, LR: 0.000208
[10:42:18] Epoch [2/300], Step [300/384], Loss: 4.3937, LR: 0.000208
[10:42:20] Epoch [2/300], Step [320/384], Loss: 4.5296, LR: 0.000208
[10:42:22] Epoch [2/300], Step [340/384], Loss: 4.5989, LR: 0.000208
[10:42:23] Epoch [2/300], Step [360/384], Loss: 4.9803, LR: 0.000208
[10:42:25] Epoch [2/300], Step [380/384], Loss: 4.8430, LR: 0.000208
[10:42:25] Epoch 2 Complete. Avg Loss: 4.8781, LR: 0.000208
  -> New best model saved (loss: 4.8781)
[10:42:25] Epoch [3/300], Step [0/384], Loss: 4.1671, LR: 0.000406
[10:42:27] Epoch [3/300], Step [20/384], Loss: 4.6588, LR: 0.000406
[10:42:29] Epoch [3/300], Step [40/384], Loss: 4.6322, LR: 0.000406
[10:42:31] Epoch [3/300], Step [60/384], Loss: 4.5309, LR: 0.000406
[10:42:33] Epoch [3/300], Step [80/384], Loss: 4.5008, LR: 0.000406
[10:42:35] Epoch [3/300], Step [100/384], Loss: 4.9304, LR: 0.000406
[10:42:37] Epoch [3/300], Step [120/384], Loss: 4.5156, LR: 0.000406
[10:42:39] Epoch [3/300], Step [140/384], Loss: 4.1695, LR: 0.000406
[10:42:41] Epoch [3/300], Step [160/384], Loss: 4.1693, LR: 0.000406
[10:42:42] Epoch [3/300], Step [180/384], Loss: 4.3567, LR: 0.000406
[10:42:44] Epoch [3/300], Step [200/384], Loss: 4.5932, LR: 0.000406
[10:42:46] Epoch [3/300], Step [220/384], Loss: 4.6061, LR: 0.000406
[10:42:48] Epoch [3/300], Step [240/384], Loss: 4.1162, LR: 0.000406
[10:42:50] Epoch [3/300], Step [260/384], Loss: 5.1323, LR: 0.000406
[10:42:53] Epoch [3/300], Step [280/384], Loss: 4.5176, LR: 0.000406
[10:42:55] Epoch [3/300], Step [300/384], Loss: 4.6126, LR: 0.000406
[10:42:57] Epoch [3/300], Step [320/384], Loss: 4.0230, LR: 0.000406
[10:42:59] Epoch [3/300], Step [340/384], Loss: 4.7012, LR: 0.000406
[10:43:02] Epoch [3/300], Step [360/384], Loss: 4.2527, LR: 0.000406
[10:43:04] Epoch [3/300], Step [380/384], Loss: 4.9831, LR: 0.000406
[10:43:04] Epoch 3 Complete. Avg Loss: 4.4921, LR: 0.000406
  -> New best model saved (loss: 4.4921)
[10:43:04] Epoch [4/300], Step [0/384], Loss: 4.2591, LR: 0.000604
[10:43:07] Epoch [4/300], Step [20/384], Loss: 4.7949, LR: 0.000604
[10:43:08] Epoch [4/300], Step [40/384], Loss: 4.5098, LR: 0.000604
[10:43:09] Epoch [4/300], Step [60/384], Loss: 4.5251, LR: 0.000604
[10:43:11] Epoch [4/300], Step [80/384], Loss: 4.9430, LR: 0.000604
[10:43:13] Epoch [4/300], Step [100/384], Loss: 4.0187, LR: 0.000604
[10:43:15] Epoch [4/300], Step [120/384], Loss: 4.3756, LR: 0.000604
[10:43:17] Epoch [4/300], Step [140/384], Loss: 4.1731, LR: 0.000604
[10:43:20] Epoch [4/300], Step [160/384], Loss: 4.1449, LR: 0.000604
[10:43:22] Epoch [4/300], Step [180/384], Loss: 4.5023, LR: 0.000604
[10:43:24] Epoch [4/300], Step [200/384], Loss: 4.1747, LR: 0.000604
[10:43:26] Epoch [4/300], Step [220/384], Loss: 5.0522, LR: 0.000604
[10:43:27] Epoch [4/300], Step [240/384], Loss: 4.4680, LR: 0.000604
[10:43:30] Epoch [4/300], Step [260/384], Loss: 4.4273, LR: 0.000604
[10:43:32] Epoch [4/300], Step [280/384], Loss: 4.0898, LR: 0.000604
[10:43:34] Epoch [4/300], Step [300/384], Loss: 3.9764, LR: 0.000604
[10:43:36] Epoch [4/300], Step [320/384], Loss: 4.3555, LR: 0.000604
[10:43:38] Epoch [4/300], Step [340/384], Loss: 4.3024, LR: 0.000604
[10:43:40] Epoch [4/300], Step [360/384], Loss: 3.7727, LR: 0.000604
[10:43:42] Epoch [4/300], Step [380/384], Loss: 4.3390, LR: 0.000604
[10:43:42] Epoch 4 Complete. Avg Loss: 4.3046, LR: 0.000604
  -> New best model saved (loss: 4.3046)
[10:43:43] Epoch [5/300], Step [0/384], Loss: 4.2467, LR: 0.000802
[10:43:45] Epoch [5/300], Step [20/384], Loss: 4.0407, LR: 0.000802
[10:43:47] Epoch [5/300], Step [40/384], Loss: 4.9015, LR: 0.000802
[10:43:49] Epoch [5/300], Step [60/384], Loss: 4.1060, LR: 0.000802
[10:43:52] Epoch [5/300], Step [80/384], Loss: 4.1241, LR: 0.000802
[10:43:54] Epoch [5/300], Step [100/384], Loss: 4.0476, LR: 0.000802
[10:43:56] Epoch [5/300], Step [120/384], Loss: 4.5468, LR: 0.000802
[10:43:58] Epoch [5/300], Step [140/384], Loss: 3.8822, LR: 0.000802
[10:44:00] Epoch [5/300], Step [160/384], Loss: 4.1143, LR: 0.000802
[10:44:03] Epoch [5/300], Step [180/384], Loss: 4.0721, LR: 0.000802
[10:44:05] Epoch [5/300], Step [200/384], Loss: 4.0693, LR: 0.000802
[10:44:07] Epoch [5/300], Step [220/384], Loss: 4.3818, LR: 0.000802
[10:44:09] Epoch [5/300], Step [240/384], Loss: 4.0695, LR: 0.000802
[10:44:12] Epoch [5/300], Step [260/384], Loss: 3.8574, LR: 0.000802
[10:44:14] Epoch [5/300], Step [280/384], Loss: 4.7296, LR: 0.000802
[10:44:16] Epoch [5/300], Step [300/384], Loss: 3.9510, LR: 0.000802
[10:44:18] Epoch [5/300], Step [320/384], Loss: 3.7474, LR: 0.000802
[10:44:20] Epoch [5/300], Step [340/384], Loss: 4.2578, LR: 0.000802
[10:44:22] Epoch [5/300], Step [360/384], Loss: 5.0017, LR: 0.000802
[10:44:25] Epoch [5/300], Step [380/384], Loss: 4.0570, LR: 0.000802
/Users/vikram/workspace/RTMDet-RTMPose/venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[10:44:25] Epoch 5 Complete. Avg Loss: 4.1672, LR: 0.000802
  -> New best model saved (loss: 4.1672)
[10:44:26] Epoch [6/300], Step [0/384], Loss: 4.2570, LR: 0.001000
[10:44:27] Epoch [6/300], Step [20/384], Loss: 3.8644, LR: 0.001000
[10:44:30] Epoch [6/300], Step [40/384], Loss: 4.2642, LR: 0.001000
[10:44:32] Epoch [6/300], Step [60/384], Loss: 4.5356, LR: 0.001000
[10:44:34] Epoch [6/300], Step [80/384], Loss: 4.6529, LR: 0.001000
[10:44:36] Epoch [6/300], Step [100/384], Loss: 3.9229, LR: 0.001000
[10:44:37] Epoch [6/300], Step [120/384], Loss: 4.6259, LR: 0.001000
[10:44:39] Epoch [6/300], Step [140/384], Loss: 3.9277, LR: 0.001000
[10:44:42] Epoch [6/300], Step [160/384], Loss: 3.7661, LR: 0.001000
[10:44:44] Epoch [6/300], Step [180/384], Loss: 4.0941, LR: 0.001000
[10:44:46] Epoch [6/300], Step [200/384], Loss: 3.6846, LR: 0.001000
[10:44:48] Epoch [6/300], Step [220/384], Loss: 4.3983, LR: 0.001000
[10:44:51] Epoch [6/300], Step [240/384], Loss: 4.1301, LR: 0.001000
[10:44:53] Epoch [6/300], Step [260/384], Loss: 3.7175, LR: 0.001000
[10:44:54] Epoch [6/300], Step [280/384], Loss: 4.2397, LR: 0.001000
[10:44:56] Epoch [6/300], Step [300/384], Loss: 4.6174, LR: 0.001000
[10:44:59] Epoch [6/300], Step [320/384], Loss: 4.2079, LR: 0.001000
[10:45:01] Epoch [6/300], Step [340/384], Loss: 4.3334, LR: 0.001000
[10:45:03] Epoch [6/300], Step [360/384], Loss: 3.4941, LR: 0.001000
[10:45:05] Epoch [6/300], Step [380/384], Loss: 4.4649, LR: 0.001000
[10:45:06] Epoch 6 Complete. Avg Loss: 4.0552, LR: 0.001000
  -> New best model saved (loss: 4.0552)
[10:45:06] Epoch [7/300], Step [0/384], Loss: 4.3564, LR: 0.001000
[10:45:08] Epoch [7/300], Step [20/384], Loss: 3.7909, LR: 0.001000
[10:45:11] Epoch [7/300], Step [40/384], Loss: 4.1984, LR: 0.001000
[10:45:13] Epoch [7/300], Step [60/384], Loss: 4.0621, LR: 0.001000
[10:45:15] Epoch [7/300], Step [80/384], Loss: 3.4843, LR: 0.001000
[10:45:17] Epoch [7/300], Step [100/384], Loss: 3.9302, LR: 0.001000
[10:45:19] Epoch [7/300], Step [120/384], Loss: 3.6349, LR: 0.001000
[10:45:21] Epoch [7/300], Step [140/384], Loss: 4.2996, LR: 0.001000
[10:45:23] Epoch [7/300], Step [160/384], Loss: 3.4203, LR: 0.001000
[10:45:25] Epoch [7/300], Step [180/384], Loss: 3.5089, LR: 0.001000
[10:45:28] Epoch [7/300], Step [200/384], Loss: 4.6107, LR: 0.001000
[10:45:30] Epoch [7/300], Step [220/384], Loss: 3.6163, LR: 0.001000
[10:45:32] Epoch [7/300], Step [240/384], Loss: 3.5573, LR: 0.001000
[10:45:34] Epoch [7/300], Step [260/384], Loss: 3.9236, LR: 0.001000
[10:45:36] Epoch [7/300], Step [280/384], Loss: 4.5898, LR: 0.001000
[10:45:39] Epoch [7/300], Step [300/384], Loss: 4.7636, LR: 0.001000
[10:45:41] Epoch [7/300], Step [320/384], Loss: 4.4320, LR: 0.001000
[10:45:43] Epoch [7/300], Step [340/384], Loss: 4.0702, LR: 0.001000
[10:45:45] Epoch [7/300], Step [360/384], Loss: 3.2162, LR: 0.001000
[10:45:47] Epoch [7/300], Step [380/384], Loss: 4.3515, LR: 0.001000
[10:45:48] Epoch 7 Complete. Avg Loss: 3.8751, LR: 0.001000
  -> New best model saved (loss: 3.8751)
[10:45:48] Epoch [8/300], Step [0/384], Loss: 4.5939, LR: 0.001000
[10:45:50] Epoch [8/300], Step [20/384], Loss: 3.7285, LR: 0.001000
[10:45:53] Epoch [8/300], Step [40/384], Loss: 4.1163, LR: 0.001000
[10:45:55] Epoch [8/300], Step [60/384], Loss: 3.7543, LR: 0.001000
[10:45:56] Epoch [8/300], Step [80/384], Loss: 3.7234, LR: 0.001000
[10:45:59] Epoch [8/300], Step [100/384], Loss: 3.8974, LR: 0.001000
[10:46:01] Epoch [8/300], Step [120/384], Loss: 4.5483, LR: 0.001000
[10:46:03] Epoch [8/300], Step [140/384], Loss: 4.1558, LR: 0.001000
[10:46:05] Epoch [8/300], Step [160/384], Loss: 4.3874, LR: 0.001000
[10:46:07] Epoch [8/300], Step [180/384], Loss: 4.4112, LR: 0.001000
[10:46:09] Epoch [8/300], Step [200/384], Loss: 3.6887, LR: 0.001000
[10:46:12] Epoch [8/300], Step [220/384], Loss: 4.0270, LR: 0.001000
[10:46:14] Epoch [8/300], Step [240/384], Loss: 3.2583, LR: 0.001000
[10:46:16] Epoch [8/300], Step [260/384], Loss: 3.8567, LR: 0.001000
[10:46:18] Epoch [8/300], Step [280/384], Loss: 4.2912, LR: 0.001000
[10:46:20] Epoch [8/300], Step [300/384], Loss: 3.4384, LR: 0.001000
[10:46:22] Epoch [8/300], Step [320/384], Loss: 3.3995, LR: 0.001000
[10:46:24] Epoch [8/300], Step [340/384], Loss: 3.9206, LR: 0.001000
[10:46:27] Epoch [8/300], Step [360/384], Loss: 4.1936, LR: 0.001000
[10:46:29] Epoch [8/300], Step [380/384], Loss: 3.7943, LR: 0.001000
[10:46:29] Epoch 8 Complete. Avg Loss: 3.7638, LR: 0.001000
  -> New best model saved (loss: 3.7638)
[10:46:29] Epoch [9/300], Step [0/384], Loss: 3.6863, LR: 0.001000
[10:46:31] Epoch [9/300], Step [20/384], Loss: 4.0071, LR: 0.001000
[10:46:34] Epoch [9/300], Step [40/384], Loss: 3.6508, LR: 0.001000
[10:46:36] Epoch [9/300], Step [60/384], Loss: 3.5472, LR: 0.001000
[10:46:38] Epoch [9/300], Step [80/384], Loss: 4.7496, LR: 0.001000
[10:46:40] Epoch [9/300], Step [100/384], Loss: 3.5976, LR: 0.001000
[10:46:42] Epoch [9/300], Step [120/384], Loss: 3.2007, LR: 0.001000
[10:46:44] Epoch [9/300], Step [140/384], Loss: 3.7609, LR: 0.001000
[10:46:46] Epoch [9/300], Step [160/384], Loss: 3.7691, LR: 0.001000
[10:46:48] Epoch [9/300], Step [180/384], Loss: 3.6562, LR: 0.001000
[10:46:51] Epoch [9/300], Step [200/384], Loss: 3.7266, LR: 0.001000
[10:46:53] Epoch [9/300], Step [220/384], Loss: 3.7352, LR: 0.001000
[10:46:55] Epoch [9/300], Step [240/384], Loss: 4.2001, LR: 0.001000
[10:46:57] Epoch [9/300], Step [260/384], Loss: 3.4028, LR: 0.001000
[10:46:59] Epoch [9/300], Step [280/384], Loss: 3.6067, LR: 0.001000
[10:47:01] Epoch [9/300], Step [300/384], Loss: 3.4847, LR: 0.001000
[10:47:04] Epoch [9/300], Step [320/384], Loss: 3.5435, LR: 0.001000
[10:47:06] Epoch [9/300], Step [340/384], Loss: 3.3552, LR: 0.001000
[10:47:08] Epoch [9/300], Step [360/384], Loss: 3.4449, LR: 0.001000
[10:47:10] Epoch [9/300], Step [380/384], Loss: 3.5819, LR: 0.001000
[10:47:11] Epoch 9 Complete. Avg Loss: 3.6630, LR: 0.001000
  -> New best model saved (loss: 3.6630)
[10:47:11] Epoch [10/300], Step [0/384], Loss: 3.6914, LR: 0.001000
[10:47:13] Epoch [10/300], Step [20/384], Loss: 3.2893, LR: 0.001000
[10:47:16] Epoch [10/300], Step [40/384], Loss: 4.0051, LR: 0.001000
[10:47:18] Epoch [10/300], Step [60/384], Loss: 3.4751, LR: 0.001000
[10:47:20] Epoch [10/300], Step [80/384], Loss: 4.1323, LR: 0.001000
[10:47:22] Epoch [10/300], Step [100/384], Loss: 3.8421, LR: 0.001000
[10:47:24] Epoch [10/300], Step [120/384], Loss: 3.6352, LR: 0.001000
[10:47:26] Epoch [10/300], Step [140/384], Loss: 3.2854, LR: 0.001000
[10:47:28] Epoch [10/300], Step [160/384], Loss: 3.7430, LR: 0.001000
[10:47:30] Epoch [10/300], Step [180/384], Loss: 3.4147, LR: 0.001000
[10:47:33] Epoch [10/300], Step [200/384], Loss: 3.8641, LR: 0.001000
[10:47:35] Epoch [10/300], Step [220/384], Loss: 3.6198, LR: 0.001000
[10:47:37] Epoch [10/300], Step [240/384], Loss: 4.0868, LR: 0.001000
[10:47:40] Epoch [10/300], Step [260/384], Loss: 3.5392, LR: 0.001000
[10:47:42] Epoch [10/300], Step [280/384], Loss: 3.7879, LR: 0.001000
[10:47:44] Epoch [10/300], Step [300/384], Loss: 3.4716, LR: 0.001000
[10:47:46] Epoch [10/300], Step [320/384], Loss: 3.9781, LR: 0.001000
[10:47:48] Epoch [10/300], Step [340/384], Loss: 3.1582, LR: 0.001000
[10:47:50] Epoch [10/300], Step [360/384], Loss: 3.2864, LR: 0.001000
[10:47:52] Epoch [10/300], Step [380/384], Loss: 2.9426, LR: 0.001000
[10:47:52] Epoch 10 Complete. Avg Loss: 3.5857, LR: 0.001000
  -> New best model saved (loss: 3.5857)
[10:47:53] Epoch [11/300], Step [0/384], Loss: 3.2203, LR: 0.000999
[10:47:55] Epoch [11/300], Step [20/384], Loss: 3.0521, LR: 0.000999
[10:47:57] Epoch [11/300], Step [40/384], Loss: 3.6945, LR: 0.000999
[10:47:59] Epoch [11/300], Step [60/384], Loss: 3.0394, LR: 0.000999
[10:48:01] Epoch [11/300], Step [80/384], Loss: 3.9551, LR: 0.000999
[10:48:03] Epoch [11/300], Step [100/384], Loss: 3.7661, LR: 0.000999
[10:48:06] Epoch [11/300], Step [120/384], Loss: 3.1809, LR: 0.000999
[10:48:08] Epoch [11/300], Step [140/384], Loss: 3.5863, LR: 0.000999
[10:48:10] Epoch [11/300], Step [160/384], Loss: 3.6639, LR: 0.000999
[10:48:12] Epoch [11/300], Step [180/384], Loss: 3.6217, LR: 0.000999
[10:48:14] Epoch [11/300], Step [200/384], Loss: 3.3349, LR: 0.000999
[10:48:17] Epoch [11/300], Step [220/384], Loss: 3.5866, LR: 0.000999
[10:48:19] Epoch [11/300], Step [240/384], Loss: 3.1590, LR: 0.000999
[10:48:21] Epoch [11/300], Step [260/384], Loss: 3.7004, LR: 0.000999
[10:48:23] Epoch [11/300], Step [280/384], Loss: 2.9702, LR: 0.000999
[10:48:25] Epoch [11/300], Step [300/384], Loss: 3.8166, LR: 0.000999
[10:48:27] Epoch [11/300], Step [320/384], Loss: 3.2331, LR: 0.000999
[10:48:29] Epoch [11/300], Step [340/384], Loss: 3.6188, LR: 0.000999
[10:48:32] Epoch [11/300], Step [360/384], Loss: 3.1539, LR: 0.000999
[10:48:34] Epoch [11/300], Step [380/384], Loss: 3.7528, LR: 0.000999
[10:48:34] Epoch 11 Complete. Avg Loss: 3.4850, LR: 0.000999
  -> New best model saved (loss: 3.4850)
[10:48:34] Epoch [12/300], Step [0/384], Loss: 3.2168, LR: 0.000999
[10:48:36] Epoch [12/300], Step [20/384], Loss: 3.1864, LR: 0.000999
[10:48:39] Epoch [12/300], Step [40/384], Loss: 3.1575, LR: 0.000999
[10:48:41] Epoch [12/300], Step [60/384], Loss: 3.8288, LR: 0.000999
[10:48:43] Epoch [12/300], Step [80/384], Loss: 3.2779, LR: 0.000999
[10:48:45] Epoch [12/300], Step [100/384], Loss: 3.5097, LR: 0.000999
[10:48:47] Epoch [12/300], Step [120/384], Loss: 2.9987, LR: 0.000999
[10:48:49] Epoch [12/300], Step [140/384], Loss: 2.9020, LR: 0.000999
[10:48:51] Epoch [12/300], Step [160/384], Loss: 3.0298, LR: 0.000999
[10:48:53] Epoch [12/300], Step [180/384], Loss: 3.4727, LR: 0.000999
[10:48:55] Epoch [12/300], Step [200/384], Loss: 4.2159, LR: 0.000999
[10:48:57] Epoch [12/300], Step [220/384], Loss: 3.6336, LR: 0.000999
[10:48:59] Epoch [12/300], Step [240/384], Loss: 3.5733, LR: 0.000999
[10:49:02] Epoch [12/300], Step [260/384], Loss: 3.0498, LR: 0.000999
[10:49:04] Epoch [12/300], Step [280/384], Loss: 3.0150, LR: 0.000999
[10:49:06] Epoch [12/300], Step [300/384], Loss: 3.9184, LR: 0.000999
[10:49:08] Epoch [12/300], Step [320/384], Loss: 3.4041, LR: 0.000999
[10:49:11] Epoch [12/300], Step [340/384], Loss: 2.4198, LR: 0.000999
[10:49:13] Epoch [12/300], Step [360/384], Loss: 3.4614, LR: 0.000999
[10:49:15] Epoch [12/300], Step [380/384], Loss: 3.5001, LR: 0.000999
[10:49:16] Epoch 12 Complete. Avg Loss: 3.4294, LR: 0.000999
  -> New best model saved (loss: 3.4294)
[10:49:16] Epoch [13/300], Step [0/384], Loss: 3.0512, LR: 0.000999
[10:49:18] Epoch [13/300], Step [20/384], Loss: 2.8761, LR: 0.000999
[10:49:20] Epoch [13/300], Step [40/384], Loss: 3.3002, LR: 0.000999
[10:49:23] Epoch [13/300], Step [60/384], Loss: 3.5541, LR: 0.000999
[10:49:25] Epoch [13/300], Step [80/384], Loss: 2.9032, LR: 0.000999
[10:49:27] Epoch [13/300], Step [100/384], Loss: 3.3619, LR: 0.000999
[10:49:29] Epoch [13/300], Step [120/384], Loss: 3.1209, LR: 0.000999
[10:49:31] Epoch [13/300], Step [140/384], Loss: 3.3261, LR: 0.000999
[10:49:33] Epoch [13/300], Step [160/384], Loss: 3.7778, LR: 0.000999
[10:49:35] Epoch [13/300], Step [180/384], Loss: 3.1919, LR: 0.000999
[10:49:37] Epoch [13/300], Step [200/384], Loss: 4.1542, LR: 0.000999
[10:49:40] Epoch [13/300], Step [220/384], Loss: 3.2878, LR: 0.000999
[10:49:42] Epoch [13/300], Step [240/384], Loss: 3.0431, LR: 0.000999
[10:49:44] Epoch [13/300], Step [260/384], Loss: 3.2654, LR: 0.000999
[10:49:46] Epoch [13/300], Step [280/384], Loss: 3.7886, LR: 0.000999
[10:49:48] Epoch [13/300], Step [300/384], Loss: 3.3231, LR: 0.000999
[10:49:50] Epoch [13/300], Step [320/384], Loss: 3.3039, LR: 0.000999
[10:49:53] Epoch [13/300], Step [340/384], Loss: 2.8958, LR: 0.000999
[10:49:55] Epoch [13/300], Step [360/384], Loss: 3.5852, LR: 0.000999
[10:49:57] Epoch [13/300], Step [380/384], Loss: 3.5647, LR: 0.000999
[10:49:58] Epoch 13 Complete. Avg Loss: 3.3669, LR: 0.000999
  -> New best model saved (loss: 3.3669)
[10:49:58] Epoch [14/300], Step [0/384], Loss: 3.4100, LR: 0.000998
[10:50:00] Epoch [14/300], Step [20/384], Loss: 3.6998, LR: 0.000998
[10:50:02] Epoch [14/300], Step [40/384], Loss: 3.0741, LR: 0.000998
[10:50:04] Epoch [14/300], Step [60/384], Loss: 3.4727, LR: 0.000998
[10:50:07] Epoch [14/300], Step [80/384], Loss: 3.1540, LR: 0.000998
[10:50:09] Epoch [14/300], Step [100/384], Loss: 3.4669, LR: 0.000998
[10:50:11] Epoch [14/300], Step [120/384], Loss: 2.4926, LR: 0.000998
[10:50:13] Epoch [14/300], Step [140/384], Loss: 3.1903, LR: 0.000998
[10:50:16] Epoch [14/300], Step [160/384], Loss: 3.6245, LR: 0.000998
[10:50:18] Epoch [14/300], Step [180/384], Loss: 3.1471, LR: 0.000998
[10:50:20] Epoch [14/300], Step [200/384], Loss: 2.9827, LR: 0.000998
[10:50:22] Epoch [14/300], Step [220/384], Loss: 3.2240, LR: 0.000998
[10:50:24] Epoch [14/300], Step [240/384], Loss: 2.7352, LR: 0.000998
[10:50:26] Epoch [14/300], Step [260/384], Loss: 3.3814, LR: 0.000998
[10:50:29] Epoch [14/300], Step [280/384], Loss: 3.2685, LR: 0.000998
[10:50:31] Epoch [14/300], Step [300/384], Loss: 2.9463, LR: 0.000998
[10:50:33] Epoch [14/300], Step [320/384], Loss: 4.1653, LR: 0.000998
[10:50:35] Epoch [14/300], Step [340/384], Loss: 2.7153, LR: 0.000998
[10:50:37] Epoch [14/300], Step [360/384], Loss: 3.0613, LR: 0.000998
[10:50:39] Epoch [14/300], Step [380/384], Loss: 3.3884, LR: 0.000998
[10:50:39] Epoch 14 Complete. Avg Loss: 3.2806, LR: 0.000998
  -> New best model saved (loss: 3.2806)
[10:50:39] Epoch [15/300], Step [0/384], Loss: 3.6892, LR: 0.000998
[10:50:41] Epoch [15/300], Step [20/384], Loss: 3.2863, LR: 0.000998
[10:50:44] Epoch [15/300], Step [40/384], Loss: 3.4994, LR: 0.000998
[10:50:46] Epoch [15/300], Step [60/384], Loss: 2.8827, LR: 0.000998
[10:50:48] Epoch [15/300], Step [80/384], Loss: 3.2449, LR: 0.000998
[10:50:50] Epoch [15/300], Step [100/384], Loss: 3.0504, LR: 0.000998
[10:50:51] Epoch [15/300], Step [120/384], Loss: 3.1236, LR: 0.000998
[10:50:53] Epoch [15/300], Step [140/384], Loss: 2.8939, LR: 0.000998
[10:50:55] Epoch [15/300], Step [160/384], Loss: 3.2441, LR: 0.000998
[10:50:58] Epoch [15/300], Step [180/384], Loss: 3.3994, LR: 0.000998
[10:51:00] Epoch [15/300], Step [200/384], Loss: 3.5958, LR: 0.000998
[10:51:02] Epoch [15/300], Step [220/384], Loss: 3.6552, LR: 0.000998
[10:51:04] Epoch [15/300], Step [240/384], Loss: 3.5527, LR: 0.000998
[10:51:06] Epoch [15/300], Step [260/384], Loss: 3.1816, LR: 0.000998
[10:51:09] Epoch [15/300], Step [280/384], Loss: 3.2769, LR: 0.000998
[10:51:11] Epoch [15/300], Step [300/384], Loss: 2.6356, LR: 0.000998
[10:51:13] Epoch [15/300], Step [320/384], Loss: 3.4177, LR: 0.000998
[10:51:15] Epoch [15/300], Step [340/384], Loss: 3.0409, LR: 0.000998
[10:51:17] Epoch [15/300], Step [360/384], Loss: 3.3297, LR: 0.000998
[10:51:19] Epoch [15/300], Step [380/384], Loss: 3.1942, LR: 0.000998
[10:51:20] Epoch 15 Complete. Avg Loss: 3.2471, LR: 0.000998
  -> New best model saved (loss: 3.2471)
[10:51:20] Epoch [16/300], Step [0/384], Loss: 3.2014, LR: 0.000997
[10:51:22] Epoch [16/300], Step [20/384], Loss: 3.0060, LR: 0.000997
[10:51:24] Epoch [16/300], Step [40/384], Loss: 3.0880, LR: 0.000997
[10:51:27] Epoch [16/300], Step [60/384], Loss: 3.5546, LR: 0.000997
[10:51:29] Epoch [16/300], Step [80/384], Loss: 3.2654, LR: 0.000997
[10:51:31] Epoch [16/300], Step [100/384], Loss: 3.6654, LR: 0.000997
[10:51:33] Epoch [16/300], Step [120/384], Loss: 3.2227, LR: 0.000997
[10:51:36] Epoch [16/300], Step [140/384], Loss: 3.0793, LR: 0.000997
[10:51:38] Epoch [16/300], Step [160/384], Loss: 3.5972, LR: 0.000997
[10:51:40] Epoch [16/300], Step [180/384], Loss: 3.4920, LR: 0.000997
[10:51:42] Epoch [16/300], Step [200/384], Loss: 3.5063, LR: 0.000997
[10:51:44] Epoch [16/300], Step [220/384], Loss: 2.9785, LR: 0.000997
[10:51:46] Epoch [16/300], Step [240/384], Loss: 3.2998, LR: 0.000997
[10:51:48] Epoch [16/300], Step [260/384], Loss: 3.0256, LR: 0.000997
[10:51:50] Epoch [16/300], Step [280/384], Loss: 3.3015, LR: 0.000997
[10:51:53] Epoch [16/300], Step [300/384], Loss: 4.2397, LR: 0.000997
[10:51:55] Epoch [16/300], Step [320/384], Loss: 3.2333, LR: 0.000997
[10:51:57] Epoch [16/300], Step [340/384], Loss: 4.1210, LR: 0.000997
[10:51:59] Epoch [16/300], Step [360/384], Loss: 3.2955, LR: 0.000997
[10:52:01] Epoch [16/300], Step [380/384], Loss: 3.0684, LR: 0.000997
[10:52:02] Epoch 16 Complete. Avg Loss: 3.2020, LR: 0.000997
  -> New best model saved (loss: 3.2020)
[10:52:02] Epoch [17/300], Step [0/384], Loss: 3.1698, LR: 0.000997
[10:52:04] Epoch [17/300], Step [20/384], Loss: 2.5389, LR: 0.000997
[10:52:07] Epoch [17/300], Step [40/384], Loss: 2.8250, LR: 0.000997
[10:52:09] Epoch [17/300], Step [60/384], Loss: 3.0913, LR: 0.000997
[10:52:11] Epoch [17/300], Step [80/384], Loss: 2.9841, LR: 0.000997
[10:52:13] Epoch [17/300], Step [100/384], Loss: 3.4869, LR: 0.000997
[10:52:15] Epoch [17/300], Step [120/384], Loss: 3.3749, LR: 0.000997
[10:52:17] Epoch [17/300], Step [140/384], Loss: 4.2435, LR: 0.000997
[10:52:20] Epoch [17/300], Step [160/384], Loss: 3.4191, LR: 0.000997
[10:52:22] Epoch [17/300], Step [180/384], Loss: 2.9609, LR: 0.000997
[10:52:24] Epoch [17/300], Step [200/384], Loss: 3.4380, LR: 0.000997
[10:52:26] Epoch [17/300], Step [220/384], Loss: 4.2042, LR: 0.000997
[10:52:28] Epoch [17/300], Step [240/384], Loss: 3.6257, LR: 0.000997
[10:52:30] Epoch [17/300], Step [260/384], Loss: 2.8746, LR: 0.000997
[10:52:32] Epoch [17/300], Step [280/384], Loss: 3.1876, LR: 0.000997
[10:52:35] Epoch [17/300], Step [300/384], Loss: 2.6938, LR: 0.000997
[10:52:37] Epoch [17/300], Step [320/384], Loss: 3.1235, LR: 0.000997
[10:52:39] Epoch [17/300], Step [340/384], Loss: 3.3088, LR: 0.000997
[10:52:41] Epoch [17/300], Step [360/384], Loss: 3.0378, LR: 0.000997
[10:52:43] Epoch [17/300], Step [380/384], Loss: 3.1221, LR: 0.000997
[10:52:43] Epoch 17 Complete. Avg Loss: 3.1662, LR: 0.000997
  -> New best model saved (loss: 3.1662)
[10:52:44] Epoch [18/300], Step [0/384], Loss: 2.8191, LR: 0.000996
[10:52:46] Epoch [18/300], Step [20/384], Loss: 2.8417, LR: 0.000996
[10:52:48] Epoch [18/300], Step [40/384], Loss: 2.9760, LR: 0.000996
[10:52:50] Epoch [18/300], Step [60/384], Loss: 2.8246, LR: 0.000996
[10:52:52] Epoch [18/300], Step [80/384], Loss: 2.6590, LR: 0.000996
[10:52:54] Epoch [18/300], Step [100/384], Loss: 3.6645, LR: 0.000996
[10:52:56] Epoch [18/300], Step [120/384], Loss: 3.0598, LR: 0.000996
[10:52:59] Epoch [18/300], Step [140/384], Loss: 3.4385, LR: 0.000996
[10:53:01] Epoch [18/300], Step [160/384], Loss: 3.1269, LR: 0.000996
[10:53:03] Epoch [18/300], Step [180/384], Loss: 2.9257, LR: 0.000996
[10:53:05] Epoch [18/300], Step [200/384], Loss: 2.6735, LR: 0.000996
[10:53:07] Epoch [18/300], Step [220/384], Loss: 3.4324, LR: 0.000996
[10:53:09] Epoch [18/300], Step [240/384], Loss: 3.0726, LR: 0.000996
[10:53:12] Epoch [18/300], Step [260/384], Loss: 2.8336, LR: 0.000996
[10:53:14] Epoch [18/300], Step [280/384], Loss: 3.7298, LR: 0.000996
[10:53:16] Epoch [18/300], Step [300/384], Loss: 3.0965, LR: 0.000996
[10:53:19] Epoch [18/300], Step [320/384], Loss: 2.6867, LR: 0.000996
[10:53:21] Epoch [18/300], Step [340/384], Loss: 4.0906, LR: 0.000996
[10:53:23] Epoch [18/300], Step [360/384], Loss: 2.8929, LR: 0.000996
[10:53:25] Epoch [18/300], Step [380/384], Loss: 3.4677, LR: 0.000996
[10:53:25] Epoch 18 Complete. Avg Loss: 3.1229, LR: 0.000996
  -> New best model saved (loss: 3.1229)
[10:53:25] Epoch [19/300], Step [0/384], Loss: 3.1639, LR: 0.000995
[10:53:27] Epoch [19/300], Step [20/384], Loss: 2.5997, LR: 0.000995
[10:53:30] Epoch [19/300], Step [40/384], Loss: 2.9652, LR: 0.000995
[10:53:32] Epoch [19/300], Step [60/384], Loss: 2.4211, LR: 0.000995
[10:53:34] Epoch [19/300], Step [80/384], Loss: 2.8784, LR: 0.000995
[10:53:36] Epoch [19/300], Step [100/384], Loss: 3.1911, LR: 0.000995
[10:53:38] Epoch [19/300], Step [120/384], Loss: 3.5351, LR: 0.000995
[10:53:40] Epoch [19/300], Step [140/384], Loss: 2.5180, LR: 0.000995
[10:53:43] Epoch [19/300], Step [160/384], Loss: 3.1756, LR: 0.000995
[10:53:45] Epoch [19/300], Step [180/384], Loss: 2.4176, LR: 0.000995
[10:53:47] Epoch [19/300], Step [200/384], Loss: 2.4612, LR: 0.000995
[10:53:49] Epoch [19/300], Step [220/384], Loss: 3.1190, LR: 0.000995
[10:53:52] Epoch [19/300], Step [240/384], Loss: 3.5001, LR: 0.000995
[10:53:54] Epoch [19/300], Step [260/384], Loss: 3.1595, LR: 0.000995
[10:53:56] Epoch [19/300], Step [280/384], Loss: 3.0730, LR: 0.000995
[10:53:58] Epoch [19/300], Step [300/384], Loss: 3.1588, LR: 0.000995
[10:54:00] Epoch [19/300], Step [320/384], Loss: 3.2331, LR: 0.000995
[10:54:02] Epoch [19/300], Step [340/384], Loss: 3.0648, LR: 0.000995
[10:54:04] Epoch [19/300], Step [360/384], Loss: 3.0597, LR: 0.000995
[10:54:07] Epoch [19/300], Step [380/384], Loss: 2.8907, LR: 0.000995
[10:54:07] Epoch 19 Complete. Avg Loss: 3.0904, LR: 0.000995
  -> New best model saved (loss: 3.0904)
[10:54:07] Epoch [20/300], Step [0/384], Loss: 2.8803, LR: 0.000995
[10:54:09] Epoch [20/300], Step [20/384], Loss: 3.0881, LR: 0.000995
[10:54:12] Epoch [20/300], Step [40/384], Loss: 2.7336, LR: 0.000995
[10:54:14] Epoch [20/300], Step [60/384], Loss: 3.6156, LR: 0.000995
[10:54:16] Epoch [20/300], Step [80/384], Loss: 2.9599, LR: 0.000995
[10:54:18] Epoch [20/300], Step [100/384], Loss: 3.3052, LR: 0.000995
[10:54:20] Epoch [20/300], Step [120/384], Loss: 2.6415, LR: 0.000995
[10:54:22] Epoch [20/300], Step [140/384], Loss: 2.6698, LR: 0.000995
[10:54:25] Epoch [20/300], Step [160/384], Loss: 3.3293, LR: 0.000995
[10:54:27] Epoch [20/300], Step [180/384], Loss: 2.5817, LR: 0.000995
[10:54:29] Epoch [20/300], Step [200/384], Loss: 4.1001, LR: 0.000995
[10:54:31] Epoch [20/300], Step [220/384], Loss: 2.8032, LR: 0.000995
[10:54:33] Epoch [20/300], Step [240/384], Loss: 2.8191, LR: 0.000995
[10:54:35] Epoch [20/300], Step [260/384], Loss: 3.1085, LR: 0.000995
[10:54:38] Epoch [20/300], Step [280/384], Loss: 3.1734, LR: 0.000995
[10:54:40] Epoch [20/300], Step [300/384], Loss: 2.6544, LR: 0.000995
[10:54:42] Epoch [20/300], Step [320/384], Loss: 4.1610, LR: 0.000995
[10:54:44] Epoch [20/300], Step [340/384], Loss: 2.9140, LR: 0.000995
[10:54:46] Epoch [20/300], Step [360/384], Loss: 3.0871, LR: 0.000995
[10:54:48] Epoch [20/300], Step [380/384], Loss: 3.0474, LR: 0.000995
[10:54:49] Epoch 20 Complete. Avg Loss: 3.0392, LR: 0.000995
  -> New best model saved (loss: 3.0392)
[10:54:49] Epoch [21/300], Step [0/384], Loss: 3.9566, LR: 0.000994
[10:54:51] Epoch [21/300], Step [20/384], Loss: 2.9594, LR: 0.000994
[10:54:53] Epoch [21/300], Step [40/384], Loss: 3.6020, LR: 0.000994
[10:54:55] Epoch [21/300], Step [60/384], Loss: 3.3492, LR: 0.000994
[10:54:57] Epoch [21/300], Step [80/384], Loss: 2.9639, LR: 0.000994
[10:54:59] Epoch [21/300], Step [100/384], Loss: 2.5918, LR: 0.000994
[10:55:02] Epoch [21/300], Step [120/384], Loss: 3.5039, LR: 0.000994
[10:55:04] Epoch [21/300], Step [140/384], Loss: 3.2819, LR: 0.000994
[10:55:07] Epoch [21/300], Step [160/384], Loss: 2.3836, LR: 0.000994
[10:55:09] Epoch [21/300], Step [180/384], Loss: 3.1600, LR: 0.000994
[10:55:11] Epoch [21/300], Step [200/384], Loss: 2.9434, LR: 0.000994
[10:55:13] Epoch [21/300], Step [220/384], Loss: 2.4710, LR: 0.000994
[10:55:15] Epoch [21/300], Step [240/384], Loss: 2.6814, LR: 0.000994
[10:55:17] Epoch [21/300], Step [260/384], Loss: 3.3251, LR: 0.000994
[10:55:19] Epoch [21/300], Step [280/384], Loss: 3.2242, LR: 0.000994
[10:55:21] Epoch [21/300], Step [300/384], Loss: 3.0963, LR: 0.000994
[10:55:23] Epoch [21/300], Step [320/384], Loss: 2.7903, LR: 0.000994
[10:55:26] Epoch [21/300], Step [340/384], Loss: 2.8193, LR: 0.000994
[10:55:28] Epoch [21/300], Step [360/384], Loss: 2.8577, LR: 0.000994
[10:55:30] Epoch [21/300], Step [380/384], Loss: 2.5619, LR: 0.000994
[10:55:30] Epoch 21 Complete. Avg Loss: 3.0233, LR: 0.000994
  -> New best model saved (loss: 3.0233)
[10:55:31] Epoch [22/300], Step [0/384], Loss: 2.7992, LR: 0.000993
[10:55:33] Epoch [22/300], Step [20/384], Loss: 3.5297, LR: 0.000993
[10:55:35] Epoch [22/300], Step [40/384], Loss: 2.5849, LR: 0.000993
[10:55:37] Epoch [22/300], Step [60/384], Loss: 2.6270, LR: 0.000993
[10:55:39] Epoch [22/300], Step [80/384], Loss: 2.7325, LR: 0.000993
[10:55:42] Epoch [22/300], Step [100/384], Loss: 2.9831, LR: 0.000993
[10:55:44] Epoch [22/300], Step [120/384], Loss: 2.4170, LR: 0.000993
[10:55:46] Epoch [22/300], Step [140/384], Loss: 2.5447, LR: 0.000993
[10:55:48] Epoch [22/300], Step [160/384], Loss: 2.8374, LR: 0.000993
[10:55:50] Epoch [22/300], Step [180/384], Loss: 2.9212, LR: 0.000993
[10:55:53] Epoch [22/300], Step [200/384], Loss: 2.9570, LR: 0.000993
[10:55:55] Epoch [22/300], Step [220/384], Loss: 2.6331, LR: 0.000993
[10:55:57] Epoch [22/300], Step [240/384], Loss: 3.1826, LR: 0.000993
[10:55:59] Epoch [22/300], Step [260/384], Loss: 2.8714, LR: 0.000993
[10:56:02] Epoch [22/300], Step [280/384], Loss: 2.8023, LR: 0.000993
[10:56:04] Epoch [22/300], Step [300/384], Loss: 3.3711, LR: 0.000993
[10:56:06] Epoch [22/300], Step [320/384], Loss: 3.1722, LR: 0.000993
[10:56:08] Epoch [22/300], Step [340/384], Loss: 2.9402, LR: 0.000993
[10:56:10] Epoch [22/300], Step [360/384], Loss: 3.0030, LR: 0.000993
[10:56:12] Epoch [22/300], Step [380/384], Loss: 3.5238, LR: 0.000993
[10:56:13] Epoch 22 Complete. Avg Loss: 2.9969, LR: 0.000993
  -> New best model saved (loss: 2.9969)
[10:56:13] Epoch [23/300], Step [0/384], Loss: 3.5560, LR: 0.000992
[10:56:15] Epoch [23/300], Step [20/384], Loss: 3.0200, LR: 0.000992
[10:56:17] Epoch [23/300], Step [40/384], Loss: 3.4099, LR: 0.000992
[10:56:19] Epoch [23/300], Step [60/384], Loss: 3.3910, LR: 0.000992
[10:56:21] Epoch [23/300], Step [80/384], Loss: 2.9205, LR: 0.000992
[10:56:24] Epoch [23/300], Step [100/384], Loss: 3.2379, LR: 0.000992
[10:56:26] Epoch [23/300], Step [120/384], Loss: 2.4395, LR: 0.000992
[10:56:28] Epoch [23/300], Step [140/384], Loss: 4.1307, LR: 0.000992
[10:56:31] Epoch [23/300], Step [160/384], Loss: 3.1070, LR: 0.000992
[10:56:33] Epoch [23/300], Step [180/384], Loss: 2.6526, LR: 0.000992
[10:56:35] Epoch [23/300], Step [200/384], Loss: 2.7193, LR: 0.000992
[10:56:37] Epoch [23/300], Step [220/384], Loss: 2.3440, LR: 0.000992
[10:56:40] Epoch [23/300], Step [240/384], Loss: 3.1296, LR: 0.000992
[10:56:42] Epoch [23/300], Step [260/384], Loss: 2.7509, LR: 0.000992
[10:56:44] Epoch [23/300], Step [280/384], Loss: 3.1653, LR: 0.000992
[10:56:46] Epoch [23/300], Step [300/384], Loss: 2.8611, LR: 0.000992
[10:56:48] Epoch [23/300], Step [320/384], Loss: 3.6025, LR: 0.000992
[10:56:51] Epoch [23/300], Step [340/384], Loss: 3.5837, LR: 0.000992
[10:56:53] Epoch [23/300], Step [360/384], Loss: 3.2050, LR: 0.000992
[10:56:55] Epoch [23/300], Step [380/384], Loss: 2.6540, LR: 0.000992
[10:56:55] Epoch 23 Complete. Avg Loss: 2.9531, LR: 0.000992
  -> New best model saved (loss: 2.9531)
[10:56:56] Epoch [24/300], Step [0/384], Loss: 2.9822, LR: 0.000991
[10:56:58] Epoch [24/300], Step [20/384], Loss: 3.1748, LR: 0.000991
[10:57:00] Epoch [24/300], Step [40/384], Loss: 2.8447, LR: 0.000991
[10:57:02] Epoch [24/300], Step [60/384], Loss: 2.9587, LR: 0.000991
[10:57:04] Epoch [24/300], Step [80/384], Loss: 2.3701, LR: 0.000991
[10:57:07] Epoch [24/300], Step [100/384], Loss: 2.1900, LR: 0.000991
[10:57:09] Epoch [24/300], Step [120/384], Loss: 2.5305, LR: 0.000991
[10:57:11] Epoch [24/300], Step [140/384], Loss: 3.2339, LR: 0.000991
[10:57:13] Epoch [24/300], Step [160/384], Loss: 2.8513, LR: 0.000991
[10:57:16] Epoch [24/300], Step [180/384], Loss: 3.2291, LR: 0.000991
[10:57:18] Epoch [24/300], Step [200/384], Loss: 3.3535, LR: 0.000991
[10:57:20] Epoch [24/300], Step [220/384], Loss: 3.3272, LR: 0.000991
[10:57:22] Epoch [24/300], Step [240/384], Loss: 4.0709, LR: 0.000991
[10:57:24] Epoch [24/300], Step [260/384], Loss: 2.9936, LR: 0.000991
[10:57:27] Epoch [24/300], Step [280/384], Loss: 3.1384, LR: 0.000991
[10:57:29] Epoch [24/300], Step [300/384], Loss: 2.9951, LR: 0.000991
[10:57:31] Epoch [24/300], Step [320/384], Loss: 2.9845, LR: 0.000991
[10:57:33] Epoch [24/300], Step [340/384], Loss: 3.4670, LR: 0.000991
[10:57:35] Epoch [24/300], Step [360/384], Loss: 2.9227, LR: 0.000991
[10:57:37] Epoch [24/300], Step [380/384], Loss: 3.3194, LR: 0.000991
[10:57:38] Epoch 24 Complete. Avg Loss: 2.9482, LR: 0.000991
  -> New best model saved (loss: 2.9482)
[10:57:38] Epoch [25/300], Step [0/384], Loss: 3.3391, LR: 0.000990
[10:57:40] Epoch [25/300], Step [20/384], Loss: 3.5865, LR: 0.000990
[10:57:42] Epoch [25/300], Step [40/384], Loss: 2.7038, LR: 0.000990
[10:57:45] Epoch [25/300], Step [60/384], Loss: 2.8229, LR: 0.000990
[10:57:47] Epoch [25/300], Step [80/384], Loss: 2.6558, LR: 0.000990
[10:57:49] Epoch [25/300], Step [100/384], Loss: 2.7662, LR: 0.000990
[10:57:51] Epoch [25/300], Step [120/384], Loss: 2.6202, LR: 0.000990
[10:57:53] Epoch [25/300], Step [140/384], Loss: 2.6616, LR: 0.000990
[10:57:55] Epoch [25/300], Step [160/384], Loss: 2.8452, LR: 0.000990
[10:57:57] Epoch [25/300], Step [180/384], Loss: 3.1319, LR: 0.000990
[10:58:00] Epoch [25/300], Step [200/384], Loss: 2.9689, LR: 0.000990
[10:58:02] Epoch [25/300], Step [220/384], Loss: 2.6093, LR: 0.000990
[10:58:04] Epoch [25/300], Step [240/384], Loss: 2.8101, LR: 0.000990
[10:58:06] Epoch [25/300], Step [260/384], Loss: 2.7990, LR: 0.000990
[10:58:08] Epoch [25/300], Step [280/384], Loss: 2.7213, LR: 0.000990
[10:58:10] Epoch [25/300], Step [300/384], Loss: 3.0580, LR: 0.000990
[10:58:12] Epoch [25/300], Step [320/384], Loss: 2.2348, LR: 0.000990
[10:58:15] Epoch [25/300], Step [340/384], Loss: 3.1760, LR: 0.000990
[10:58:17] Epoch [25/300], Step [360/384], Loss: 3.6077, LR: 0.000990
[10:58:19] Epoch [25/300], Step [380/384], Loss: 2.7396, LR: 0.000990
[10:58:19] Epoch 25 Complete. Avg Loss: 2.9198, LR: 0.000990
  -> New best model saved (loss: 2.9198)
[10:58:19] Epoch [26/300], Step [0/384], Loss: 3.3938, LR: 0.000989
[10:58:22] Epoch [26/300], Step [20/384], Loss: 3.0120, LR: 0.000989
[10:58:24] Epoch [26/300], Step [40/384], Loss: 2.6442, LR: 0.000989
[10:58:26] Epoch [26/300], Step [60/384], Loss: 2.0639, LR: 0.000989
[10:58:29] Epoch [26/300], Step [80/384], Loss: 2.8331, LR: 0.000989
[10:58:31] Epoch [26/300], Step [100/384], Loss: 2.7337, LR: 0.000989
[10:58:32] Epoch [26/300], Step [120/384], Loss: 3.5458, LR: 0.000989
[10:58:35] Epoch [26/300], Step [140/384], Loss: 3.8747, LR: 0.000989
[10:58:37] Epoch [26/300], Step [160/384], Loss: 3.0937, LR: 0.000989
[10:58:39] Epoch [26/300], Step [180/384], Loss: 2.4713, LR: 0.000989
[10:58:41] Epoch [26/300], Step [200/384], Loss: 2.5621, LR: 0.000989
[10:58:43] Epoch [26/300], Step [220/384], Loss: 2.9187, LR: 0.000989
[10:58:45] Epoch [26/300], Step [240/384], Loss: 3.4164, LR: 0.000989
[10:58:47] Epoch [26/300], Step [260/384], Loss: 2.9586, LR: 0.000989
[10:58:50] Epoch [26/300], Step [280/384], Loss: 2.9965, LR: 0.000989
[10:58:52] Epoch [26/300], Step [300/384], Loss: 2.7210, LR: 0.000989
[10:58:54] Epoch [26/300], Step [320/384], Loss: 2.3191, LR: 0.000989
[10:58:56] Epoch [26/300], Step [340/384], Loss: 3.7708, LR: 0.000989
[10:58:58] Epoch [26/300], Step [360/384], Loss: 2.2216, LR: 0.000989
[10:59:01] Epoch [26/300], Step [380/384], Loss: 2.6340, LR: 0.000989
[10:59:01] Epoch 26 Complete. Avg Loss: 2.8956, LR: 0.000989
  -> New best model saved (loss: 2.8956)
[10:59:01] Epoch [27/300], Step [0/384], Loss: 3.1395, LR: 0.000988
[10:59:03] Epoch [27/300], Step [20/384], Loss: 2.2579, LR: 0.000988
[10:59:06] Epoch [27/300], Step [40/384], Loss: 2.2231, LR: 0.000988
[10:59:08] Epoch [27/300], Step [60/384], Loss: 2.7347, LR: 0.000988
[10:59:10] Epoch [27/300], Step [80/384], Loss: 3.7430, LR: 0.000988
[10:59:12] Epoch [27/300], Step [100/384], Loss: 2.6283, LR: 0.000988
[10:59:14] Epoch [27/300], Step [120/384], Loss: 3.0670, LR: 0.000988
[10:59:16] Epoch [27/300], Step [140/384], Loss: 3.1962, LR: 0.000988
[10:59:18] Epoch [27/300], Step [160/384], Loss: 3.1257, LR: 0.000988
[10:59:21] Epoch [27/300], Step [180/384], Loss: 2.9695, LR: 0.000988
[10:59:23] Epoch [27/300], Step [200/384], Loss: 3.1984, LR: 0.000988
[10:59:25] Epoch [27/300], Step [220/384], Loss: 2.8854, LR: 0.000988
[10:59:27] Epoch [27/300], Step [240/384], Loss: 2.2330, LR: 0.000988
[10:59:29] Epoch [27/300], Step [260/384], Loss: 2.6500, LR: 0.000988
[10:59:32] Epoch [27/300], Step [280/384], Loss: 3.3043, LR: 0.000988
[10:59:34] Epoch [27/300], Step [300/384], Loss: 2.7781, LR: 0.000988
[10:59:36] Epoch [27/300], Step [320/384], Loss: 2.8713, LR: 0.000988
[10:59:38] Epoch [27/300], Step [340/384], Loss: 2.8161, LR: 0.000988
[10:59:40] Epoch [27/300], Step [360/384], Loss: 3.5757, LR: 0.000988
[10:59:42] Epoch [27/300], Step [380/384], Loss: 2.7178, LR: 0.000988
[10:59:43] Epoch 27 Complete. Avg Loss: 2.8560, LR: 0.000988
  -> New best model saved (loss: 2.8560)
[10:59:43] Epoch [28/300], Step [0/384], Loss: 2.9626, LR: 0.000986
[10:59:45] Epoch [28/300], Step [20/384], Loss: 2.9450, LR: 0.000986
[10:59:47] Epoch [28/300], Step [40/384], Loss: 1.9665, LR: 0.000986
[10:59:49] Epoch [28/300], Step [60/384], Loss: 2.9103, LR: 0.000986
[10:59:52] Epoch [28/300], Step [80/384], Loss: 2.6726, LR: 0.000986
[10:59:54] Epoch [28/300], Step [100/384], Loss: 3.0243, LR: 0.000986
[10:59:56] Epoch [28/300], Step [120/384], Loss: 2.9497, LR: 0.000986
[10:59:58] Epoch [28/300], Step [140/384], Loss: 2.5213, LR: 0.000986
[11:00:00] Epoch [28/300], Step [160/384], Loss: 3.0919, LR: 0.000986
[11:00:02] Epoch [28/300], Step [180/384], Loss: 2.8080, LR: 0.000986
[11:00:05] Epoch [28/300], Step [200/384], Loss: 3.1448, LR: 0.000986
[11:00:07] Epoch [28/300], Step [220/384], Loss: 1.9690, LR: 0.000986
[11:00:09] Epoch [28/300], Step [240/384], Loss: 1.8950, LR: 0.000986
[11:00:11] Epoch [28/300], Step [260/384], Loss: 2.9396, LR: 0.000986
[11:00:13] Epoch [28/300], Step [280/384], Loss: 3.0341, LR: 0.000986
[11:00:15] Epoch [28/300], Step [300/384], Loss: 2.6338, LR: 0.000986
[11:00:17] Epoch [28/300], Step [320/384], Loss: 2.7706, LR: 0.000986
[11:00:20] Epoch [28/300], Step [340/384], Loss: 2.2401, LR: 0.000986
[11:00:22] Epoch [28/300], Step [360/384], Loss: 2.6357, LR: 0.000986
[11:00:24] Epoch [28/300], Step [380/384], Loss: 2.7191, LR: 0.000986
[11:00:24] Epoch 28 Complete. Avg Loss: 2.8122, LR: 0.000986
  -> New best model saved (loss: 2.8122)
[11:00:24] Epoch [29/300], Step [0/384], Loss: 2.7286, LR: 0.000985
[11:00:27] Epoch [29/300], Step [20/384], Loss: 2.6266, LR: 0.000985
[11:00:29] Epoch [29/300], Step [40/384], Loss: 3.0624, LR: 0.000985
[11:00:31] Epoch [29/300], Step [60/384], Loss: 2.8476, LR: 0.000985
[11:00:34] Epoch [29/300], Step [80/384], Loss: 2.7329, LR: 0.000985
[11:00:36] Epoch [29/300], Step [100/384], Loss: 3.0551, LR: 0.000985
[11:00:38] Epoch [29/300], Step [120/384], Loss: 2.5345, LR: 0.000985
[11:00:40] Epoch [29/300], Step [140/384], Loss: 2.1943, LR: 0.000985
[11:00:42] Epoch [29/300], Step [160/384], Loss: 2.3501, LR: 0.000985
[11:00:44] Epoch [29/300], Step [180/384], Loss: 2.7877, LR: 0.000985
[11:00:46] Epoch [29/300], Step [200/384], Loss: 3.6590, LR: 0.000985
[11:00:48] Epoch [29/300], Step [220/384], Loss: 3.4144, LR: 0.000985
[11:00:50] Epoch [29/300], Step [240/384], Loss: 2.9974, LR: 0.000985
[11:00:52] Epoch [29/300], Step [260/384], Loss: 2.6115, LR: 0.000985
[11:00:54] Epoch [29/300], Step [280/384], Loss: 3.1904, LR: 0.000985
[11:00:56] Epoch [29/300], Step [300/384], Loss: 2.4754, LR: 0.000985
[11:00:58] Epoch [29/300], Step [320/384], Loss: 2.8555, LR: 0.000985
[11:01:00] Epoch [29/300], Step [340/384], Loss: 2.6113, LR: 0.000985
[11:01:02] Epoch [29/300], Step [360/384], Loss: 2.9164, LR: 0.000985
[11:01:05] Epoch [29/300], Step [380/384], Loss: 2.6409, LR: 0.000985
[11:01:05] Epoch 29 Complete. Avg Loss: 2.8300, LR: 0.000985
[11:01:05] Epoch [30/300], Step [0/384], Loss: 2.7560, LR: 0.000984
[11:01:07] Epoch [30/300], Step [20/384], Loss: 2.7406, LR: 0.000984
[11:01:09] Epoch [30/300], Step [40/384], Loss: 2.5206, LR: 0.000984
[11:01:12] Epoch [30/300], Step [60/384], Loss: 3.1373, LR: 0.000984
[11:01:14] Epoch [30/300], Step [80/384], Loss: 2.7715, LR: 0.000984
[11:01:16] Epoch [30/300], Step [100/384], Loss: 3.0019, LR: 0.000984
[11:01:18] Epoch [30/300], Step [120/384], Loss: 2.5580, LR: 0.000984
[11:01:20] Epoch [30/300], Step [140/384], Loss: 2.9619, LR: 0.000984
[11:01:22] Epoch [30/300], Step [160/384], Loss: 3.5791, LR: 0.000984
[11:01:25] Epoch [30/300], Step [180/384], Loss: 2.6252, LR: 0.000984
[11:01:27] Epoch [30/300], Step [200/384], Loss: 2.5344, LR: 0.000984
[11:01:29] Epoch [30/300], Step [220/384], Loss: 2.5777, LR: 0.000984
[11:01:31] Epoch [30/300], Step [240/384], Loss: 3.5904, LR: 0.000984
[11:01:32] Epoch [30/300], Step [260/384], Loss: 2.5564, LR: 0.000984
[11:01:34] Epoch [30/300], Step [280/384], Loss: 3.2271, LR: 0.000984
[11:01:36] Epoch [30/300], Step [300/384], Loss: 2.9558, LR: 0.000984
[11:01:38] Epoch [30/300], Step [320/384], Loss: 3.1752, LR: 0.000984
[11:01:41] Epoch [30/300], Step [340/384], Loss: 2.6865, LR: 0.000984
[11:01:43] Epoch [30/300], Step [360/384], Loss: 2.5929, LR: 0.000984
[11:01:45] Epoch [30/300], Step [380/384], Loss: 2.6212, LR: 0.000984
[11:01:45] Epoch 30 Complete. Avg Loss: 2.7896, LR: 0.000984
  -> New best model saved (loss: 2.7896)
[11:01:45] Epoch [31/300], Step [0/384], Loss: 2.6040, LR: 0.000983
[11:01:48] Epoch [31/300], Step [20/384], Loss: 2.4014, LR: 0.000983
[11:01:50] Epoch [31/300], Step [40/384], Loss: 2.7550, LR: 0.000983
[11:01:52] Epoch [31/300], Step [60/384], Loss: 2.2940, LR: 0.000983
[11:01:54] Epoch [31/300], Step [80/384], Loss: 2.5435, LR: 0.000983
[11:01:56] Epoch [31/300], Step [100/384], Loss: 3.0003, LR: 0.000983
[11:01:58] Epoch [31/300], Step [120/384], Loss: 3.1126, LR: 0.000983
[11:02:00] Epoch [31/300], Step [140/384], Loss: 3.4859, LR: 0.000983
[11:02:03] Epoch [31/300], Step [160/384], Loss: 2.3811, LR: 0.000983
[11:02:05] Epoch [31/300], Step [180/384], Loss: 2.8169, LR: 0.000983
[11:02:07] Epoch [31/300], Step [200/384], Loss: 3.0150, LR: 0.000983
[11:02:09] Epoch [31/300], Step [220/384], Loss: 3.5621, LR: 0.000983
[11:02:11] Epoch [31/300], Step [240/384], Loss: 2.7715, LR: 0.000983
[11:02:13] Epoch [31/300], Step [260/384], Loss: 3.1237, LR: 0.000983
[11:02:16] Epoch [31/300], Step [280/384], Loss: 2.8046, LR: 0.000983
[11:02:18] Epoch [31/300], Step [300/384], Loss: 2.5269, LR: 0.000983
[11:02:20] Epoch [31/300], Step [320/384], Loss: 2.2267, LR: 0.000983
[11:02:22] Epoch [31/300], Step [340/384], Loss: 3.0333, LR: 0.000983
[11:02:24] Epoch [31/300], Step [360/384], Loss: 2.7831, LR: 0.000983
[11:02:26] Epoch [31/300], Step [380/384], Loss: 3.1315, LR: 0.000983
[11:02:26] Epoch 31 Complete. Avg Loss: 2.8034, LR: 0.000983
[11:02:27] Epoch [32/300], Step [0/384], Loss: 2.5636, LR: 0.000981
[11:02:29] Epoch [32/300], Step [20/384], Loss: 2.9594, LR: 0.000981
[11:02:31] Epoch [32/300], Step [40/384], Loss: 2.3251, LR: 0.000981
[11:02:33] Epoch [32/300], Step [60/384], Loss: 2.5033, LR: 0.000981
[11:02:35] Epoch [32/300], Step [80/384], Loss: 2.8134, LR: 0.000981
[11:02:37] Epoch [32/300], Step [100/384], Loss: 2.5433, LR: 0.000981
[11:02:39] Epoch [32/300], Step [120/384], Loss: 3.1136, LR: 0.000981
[11:02:41] Epoch [32/300], Step [140/384], Loss: 3.2582, LR: 0.000981
[11:02:44] Epoch [32/300], Step [160/384], Loss: 2.5085, LR: 0.000981
[11:02:46] Epoch [32/300], Step [180/384], Loss: 2.4074, LR: 0.000981
[11:02:48] Epoch [32/300], Step [200/384], Loss: 3.0011, LR: 0.000981
[11:02:51] Epoch [32/300], Step [220/384], Loss: 2.5774, LR: 0.000981
[11:02:52] Epoch [32/300], Step [240/384], Loss: 2.8915, LR: 0.000981
[11:02:55] Epoch [32/300], Step [260/384], Loss: 2.5440, LR: 0.000981
[11:02:57] Epoch [32/300], Step [280/384], Loss: 2.7759, LR: 0.000981
[11:02:59] Epoch [32/300], Step [300/384], Loss: 2.8356, LR: 0.000981
[11:03:01] Epoch [32/300], Step [320/384], Loss: 2.1574, LR: 0.000981
[11:03:03] Epoch [32/300], Step [340/384], Loss: 2.4461, LR: 0.000981
[11:03:05] Epoch [32/300], Step [360/384], Loss: 2.5357, LR: 0.000981
[11:03:08] Epoch [32/300], Step [380/384], Loss: 3.3742, LR: 0.000981
[11:03:08] Epoch 32 Complete. Avg Loss: 2.7485, LR: 0.000981
  -> New best model saved (loss: 2.7485)
[11:03:08] Epoch [33/300], Step [0/384], Loss: 2.5751, LR: 0.000980
[11:03:10] Epoch [33/300], Step [20/384], Loss: 3.1093, LR: 0.000980
[11:03:13] Epoch [33/300], Step [40/384], Loss: 2.5885, LR: 0.000980
[11:03:15] Epoch [33/300], Step [60/384], Loss: 3.0057, LR: 0.000980
[11:03:17] Epoch [33/300], Step [80/384], Loss: 2.3029, LR: 0.000980
[11:03:19] Epoch [33/300], Step [100/384], Loss: 2.5771, LR: 0.000980
[11:03:22] Epoch [33/300], Step [120/384], Loss: 2.7869, LR: 0.000980
[11:03:24] Epoch [33/300], Step [140/384], Loss: 2.3737, LR: 0.000980
[11:03:26] Epoch [33/300], Step [160/384], Loss: 2.0297, LR: 0.000980
[11:03:28] Epoch [33/300], Step [180/384], Loss: 3.9357, LR: 0.000980
[11:03:30] Epoch [33/300], Step [200/384], Loss: 2.9840, LR: 0.000980
[11:03:32] Epoch [33/300], Step [220/384], Loss: 2.8774, LR: 0.000980
[11:03:34] Epoch [33/300], Step [240/384], Loss: 3.2477, LR: 0.000980
[11:03:36] Epoch [33/300], Step [260/384], Loss: 2.7777, LR: 0.000980
[11:03:39] Epoch [33/300], Step [280/384], Loss: 2.6133, LR: 0.000980
[11:03:40] Epoch [33/300], Step [300/384], Loss: 2.4963, LR: 0.000980
[11:03:43] Epoch [33/300], Step [320/384], Loss: 2.9318, LR: 0.000980
[11:03:45] Epoch [33/300], Step [340/384], Loss: 2.4760, LR: 0.000980
[11:03:47] Epoch [33/300], Step [360/384], Loss: 2.8985, LR: 0.000980
[11:03:49] Epoch [33/300], Step [380/384], Loss: 3.4804, LR: 0.000980
[11:03:49] Epoch 33 Complete. Avg Loss: 2.7364, LR: 0.000980
  -> New best model saved (loss: 2.7364)
[11:03:49] Epoch [34/300], Step [0/384], Loss: 2.0857, LR: 0.000978
[11:03:52] Epoch [34/300], Step [20/384], Loss: 2.2994, LR: 0.000978
[11:03:54] Epoch [34/300], Step [40/384], Loss: 2.5631, LR: 0.000978
[11:03:56] Epoch [34/300], Step [60/384], Loss: 2.2731, LR: 0.000978
[11:03:58] Epoch [34/300], Step [80/384], Loss: 2.6437, LR: 0.000978
[11:04:00] Epoch [34/300], Step [100/384], Loss: 2.6856, LR: 0.000978
[11:04:03] Epoch [34/300], Step [120/384], Loss: 3.1994, LR: 0.000978
[11:04:05] Epoch [34/300], Step [140/384], Loss: 3.1174, LR: 0.000978
[11:04:07] Epoch [34/300], Step [160/384], Loss: 2.3550, LR: 0.000978
[11:04:09] Epoch [34/300], Step [180/384], Loss: 2.9750, LR: 0.000978
[11:04:11] Epoch [34/300], Step [200/384], Loss: 2.8956, LR: 0.000978
[11:04:13] Epoch [34/300], Step [220/384], Loss: 2.5810, LR: 0.000978
[11:04:15] Epoch [34/300], Step [240/384], Loss: 2.7852, LR: 0.000978
[11:04:17] Epoch [34/300], Step [260/384], Loss: 2.8821, LR: 0.000978
[11:04:19] Epoch [34/300], Step [280/384], Loss: 2.5595, LR: 0.000978
[11:04:22] Epoch [34/300], Step [300/384], Loss: 2.6243, LR: 0.000978
[11:04:24] Epoch [34/300], Step [320/384], Loss: 2.4649, LR: 0.000978
[11:04:26] Epoch [34/300], Step [340/384], Loss: 2.6548, LR: 0.000978
[11:04:28] Epoch [34/300], Step [360/384], Loss: 2.9717, LR: 0.000978
[11:04:31] Epoch [34/300], Step [380/384], Loss: 2.8178, LR: 0.000978
[11:04:31] Epoch 34 Complete. Avg Loss: 2.7354, LR: 0.000978
  -> New best model saved (loss: 2.7354)
[11:04:31] Epoch [35/300], Step [0/384], Loss: 2.1611, LR: 0.000977
[11:04:33] Epoch [35/300], Step [20/384], Loss: 2.8625, LR: 0.000977
[11:04:35] Epoch [35/300], Step [40/384], Loss: 2.8724, LR: 0.000977
[11:04:38] Epoch [35/300], Step [60/384], Loss: 2.6725, LR: 0.000977
[11:04:40] Epoch [35/300], Step [80/384], Loss: 2.7374, LR: 0.000977
[11:04:42] Epoch [35/300], Step [100/384], Loss: 2.8138, LR: 0.000977
[11:04:44] Epoch [35/300], Step [120/384], Loss: 2.8634, LR: 0.000977
[11:04:47] Epoch [35/300], Step [140/384], Loss: 2.3782, LR: 0.000977
[11:04:49] Epoch [35/300], Step [160/384], Loss: 2.5938, LR: 0.000977
[11:04:51] Epoch [35/300], Step [180/384], Loss: 4.0471, LR: 0.000977
[11:04:53] Epoch [35/300], Step [200/384], Loss: 2.6467, LR: 0.000977
[11:04:55] Epoch [35/300], Step [220/384], Loss: 2.4319, LR: 0.000977
[11:04:57] Epoch [35/300], Step [240/384], Loss: 2.1844, LR: 0.000977
[11:04:59] Epoch [35/300], Step [260/384], Loss: 2.7253, LR: 0.000977
[11:05:02] Epoch [35/300], Step [280/384], Loss: 2.2752, LR: 0.000977
[11:05:04] Epoch [35/300], Step [300/384], Loss: 3.0251, LR: 0.000977
[11:05:06] Epoch [35/300], Step [320/384], Loss: 2.4481, LR: 0.000977
[11:05:08] Epoch [35/300], Step [340/384], Loss: 3.3373, LR: 0.000977
[11:05:10] Epoch [35/300], Step [360/384], Loss: 2.6707, LR: 0.000977
[11:05:12] Epoch [35/300], Step [380/384], Loss: 2.3929, LR: 0.000977
[11:05:12] Epoch 35 Complete. Avg Loss: 2.6915, LR: 0.000977
  -> New best model saved (loss: 2.6915)
[11:05:12] Epoch [36/300], Step [0/384], Loss: 1.9724, LR: 0.000975
[11:05:15] Epoch [36/300], Step [20/384], Loss: 2.7923, LR: 0.000975
[11:05:17] Epoch [36/300], Step [40/384], Loss: 2.8801, LR: 0.000975
[11:05:19] Epoch [36/300], Step [60/384], Loss: 2.8738, LR: 0.000975
[11:05:21] Epoch [36/300], Step [80/384], Loss: 3.1018, LR: 0.000975
[11:05:23] Epoch [36/300], Step [100/384], Loss: 2.8234, LR: 0.000975
[11:05:25] Epoch [36/300], Step [120/384], Loss: 2.2238, LR: 0.000975
[11:05:28] Epoch [36/300], Step [140/384], Loss: 3.0286, LR: 0.000975
[11:05:30] Epoch [36/300], Step [160/384], Loss: 3.2822, LR: 0.000975
[11:05:32] Epoch [36/300], Step [180/384], Loss: 2.0347, LR: 0.000975
[11:05:34] Epoch [36/300], Step [200/384], Loss: 2.6000, LR: 0.000975
[11:05:36] Epoch [36/300], Step [220/384], Loss: 3.5350, LR: 0.000975
[11:05:38] Epoch [36/300], Step [240/384], Loss: 2.7406, LR: 0.000975
[11:05:40] Epoch [36/300], Step [260/384], Loss: 2.7964, LR: 0.000975
[11:05:42] Epoch [36/300], Step [280/384], Loss: 2.1895, LR: 0.000975
[11:05:44] Epoch [36/300], Step [300/384], Loss: 2.9360, LR: 0.000975
[11:05:47] Epoch [36/300], Step [320/384], Loss: 2.9460, LR: 0.000975
[11:05:49] Epoch [36/300], Step [340/384], Loss: 2.6718, LR: 0.000975
[11:05:51] Epoch [36/300], Step [360/384], Loss: 2.5208, LR: 0.000975
[11:05:53] Epoch [36/300], Step [380/384], Loss: 1.9941, LR: 0.000975
[11:05:54] Epoch 36 Complete. Avg Loss: 2.6957, LR: 0.000975
[11:05:54] Epoch [37/300], Step [0/384], Loss: 2.8005, LR: 0.000973
[11:05:56] Epoch [37/300], Step [20/384], Loss: 2.1474, LR: 0.000973
[11:05:58] Epoch [37/300], Step [40/384], Loss: 2.8402, LR: 0.000973
[11:06:00] Epoch [37/300], Step [60/384], Loss: 2.8322, LR: 0.000973
[11:06:02] Epoch [37/300], Step [80/384], Loss: 2.0815, LR: 0.000973
[11:06:05] Epoch [37/300], Step [100/384], Loss: 2.8520, LR: 0.000973
[11:06:07] Epoch [37/300], Step [120/384], Loss: 2.6527, LR: 0.000973
[11:06:09] Epoch [37/300], Step [140/384], Loss: 2.6187, LR: 0.000973
[11:06:11] Epoch [37/300], Step [160/384], Loss: 2.5038, LR: 0.000973
[11:06:13] Epoch [37/300], Step [180/384], Loss: 2.9264, LR: 0.000973
[11:06:15] Epoch [37/300], Step [200/384], Loss: 3.0302, LR: 0.000973
[11:06:18] Epoch [37/300], Step [220/384], Loss: 2.5564, LR: 0.000973
[11:06:19] Epoch [37/300], Step [240/384], Loss: 2.2058, LR: 0.000973
[11:06:22] Epoch [37/300], Step [260/384], Loss: 2.8643, LR: 0.000973
[11:06:24] Epoch [37/300], Step [280/384], Loss: 2.8694, LR: 0.000973
[11:06:26] Epoch [37/300], Step [300/384], Loss: 2.7883, LR: 0.000973
[11:19:56] Epoch [37/300], Step [320/384], Loss: 2.8419, LR: 0.000973
[11:19:58] Epoch [37/300], Step [340/384], Loss: 3.1370, LR: 0.000973
[11:20:01] Epoch [37/300], Step [360/384], Loss: 2.6937, LR: 0.000973
[11:20:03] Epoch [37/300], Step [380/384], Loss: 3.1454, LR: 0.000973
[11:20:03] Epoch 37 Complete. Avg Loss: 2.6863, LR: 0.000973
  -> New best model saved (loss: 2.6863)
[11:20:04] Epoch [38/300], Step [0/384], Loss: 2.2332, LR: 0.000972
[11:20:06] Epoch [38/300], Step [20/384], Loss: 2.6464, LR: 0.000972
[11:20:08] Epoch [38/300], Step [40/384], Loss: 2.5099, LR: 0.000972
[11:20:10] Epoch [38/300], Step [60/384], Loss: 2.1898, LR: 0.000972
[11:20:13] Epoch [38/300], Step [80/384], Loss: 2.7717, LR: 0.000972
[11:20:15] Epoch [38/300], Step [100/384], Loss: 2.8344, LR: 0.000972
[11:20:17] Epoch [38/300], Step [120/384], Loss: 2.8637, LR: 0.000972
[11:20:20] Epoch [38/300], Step [140/384], Loss: 2.8463, LR: 0.000972
[11:20:22] Epoch [38/300], Step [160/384], Loss: 2.8553, LR: 0.000972
[11:20:24] Epoch [38/300], Step [180/384], Loss: 2.6546, LR: 0.000972
[11:20:26] Epoch [38/300], Step [200/384], Loss: 1.9785, LR: 0.000972
[11:20:28] Epoch [38/300], Step [220/384], Loss: 2.8280, LR: 0.000972
[11:20:30] Epoch [38/300], Step [240/384], Loss: 3.0470, LR: 0.000972
[11:20:32] Epoch [38/300], Step [260/384], Loss: 2.4113, LR: 0.000972
[11:20:35] Epoch [38/300], Step [280/384], Loss: 2.5091, LR: 0.000972
[11:20:37] Epoch [38/300], Step [300/384], Loss: 2.3874, LR: 0.000972
[11:20:39] Epoch [38/300], Step [320/384], Loss: 2.2366, LR: 0.000972
[11:20:41] Epoch [38/300], Step [340/384], Loss: 2.7921, LR: 0.000972
[11:20:43] Epoch [38/300], Step [360/384], Loss: 2.1013, LR: 0.000972
[11:20:45] Epoch [38/300], Step [380/384], Loss: 2.4760, LR: 0.000972
[11:20:46] Epoch 38 Complete. Avg Loss: 2.6590, LR: 0.000972
  -> New best model saved (loss: 2.6590)
[11:20:46] Epoch [39/300], Step [0/384], Loss: 2.1196, LR: 0.000970
[11:20:48] Epoch [39/300], Step [20/384], Loss: 2.3872, LR: 0.000970
[11:20:50] Epoch [39/300], Step [40/384], Loss: 2.7588, LR: 0.000970
[11:20:53] Epoch [39/300], Step [60/384], Loss: 2.6081, LR: 0.000970
[11:20:55] Epoch [39/300], Step [80/384], Loss: 2.3370, LR: 0.000970
[11:20:57] Epoch [39/300], Step [100/384], Loss: 3.4120, LR: 0.000970
[11:20:59] Epoch [39/300], Step [120/384], Loss: 3.9986, LR: 0.000970
[11:21:01] Epoch [39/300], Step [140/384], Loss: 3.0083, LR: 0.000970
[11:21:03] Epoch [39/300], Step [160/384], Loss: 2.4682, LR: 0.000970
[11:21:06] Epoch [39/300], Step [180/384], Loss: 2.1597, LR: 0.000970
[11:21:08] Epoch [39/300], Step [200/384], Loss: 2.7243, LR: 0.000970
[11:21:10] Epoch [39/300], Step [220/384], Loss: 2.6596, LR: 0.000970
[11:21:12] Epoch [39/300], Step [240/384], Loss: 2.9755, LR: 0.000970
[11:21:14] Epoch [39/300], Step [260/384], Loss: 2.4686, LR: 0.000970
[11:21:16] Epoch [39/300], Step [280/384], Loss: 2.3054, LR: 0.000970
[11:21:18] Epoch [39/300], Step [300/384], Loss: 2.9339, LR: 0.000970
[11:21:20] Epoch [39/300], Step [320/384], Loss: 2.2944, LR: 0.000970
[11:21:22] Epoch [39/300], Step [340/384], Loss: 2.3772, LR: 0.000970
[11:21:25] Epoch [39/300], Step [360/384], Loss: 3.2047, LR: 0.000970
[11:21:27] Epoch [39/300], Step [380/384], Loss: 3.0832, LR: 0.000970
[11:21:27] Epoch 39 Complete. Avg Loss: 2.6401, LR: 0.000970
  -> New best model saved (loss: 2.6401)
[11:21:27] Epoch [40/300], Step [0/384], Loss: 2.7485, LR: 0.000968
[11:21:29] Epoch [40/300], Step [20/384], Loss: 2.4975, LR: 0.000968
[11:21:31] Epoch [40/300], Step [40/384], Loss: 2.5272, LR: 0.000968
[11:21:34] Epoch [40/300], Step [60/384], Loss: 2.7035, LR: 0.000968
[11:21:36] Epoch [40/300], Step [80/384], Loss: 2.5261, LR: 0.000968
[11:21:38] Epoch [40/300], Step [100/384], Loss: 2.6069, LR: 0.000968
[11:21:40] Epoch [40/300], Step [120/384], Loss: 3.3088, LR: 0.000968
[11:21:42] Epoch [40/300], Step [140/384], Loss: 2.4909, LR: 0.000968
[11:21:44] Epoch [40/300], Step [160/384], Loss: 2.9859, LR: 0.000968
[11:21:47] Epoch [40/300], Step [180/384], Loss: 2.9978, LR: 0.000968
[11:21:49] Epoch [40/300], Step [200/384], Loss: 2.9968, LR: 0.000968
[11:21:51] Epoch [40/300], Step [220/384], Loss: 2.4442, LR: 0.000968
[11:21:53] Epoch [40/300], Step [240/384], Loss: 2.8710, LR: 0.000968
[11:21:55] Epoch [40/300], Step [260/384], Loss: 2.1333, LR: 0.000968
[11:21:57] Epoch [40/300], Step [280/384], Loss: 2.9166, LR: 0.000968
[11:22:00] Epoch [40/300], Step [300/384], Loss: 2.8891, LR: 0.000968
[11:22:02] Epoch [40/300], Step [320/384], Loss: 2.2511, LR: 0.000968
[11:22:04] Epoch [40/300], Step [340/384], Loss: 2.1282, LR: 0.000968
[11:22:06] Epoch [40/300], Step [360/384], Loss: 2.2949, LR: 0.000968
[11:22:08] Epoch [40/300], Step [380/384], Loss: 2.7225, LR: 0.000968
[11:22:08] Epoch 40 Complete. Avg Loss: 2.6414, LR: 0.000968
[11:22:09] Epoch [41/300], Step [0/384], Loss: 2.5836, LR: 0.000966
[11:22:11] Epoch [41/300], Step [20/384], Loss: 2.8251, LR: 0.000966
[11:22:13] Epoch [41/300], Step [40/384], Loss: 2.2798, LR: 0.000966
[11:22:16] Epoch [41/300], Step [60/384], Loss: 3.2173, LR: 0.000966
[11:22:18] Epoch [41/300], Step [80/384], Loss: 3.1620, LR: 0.000966
[11:22:20] Epoch [41/300], Step [100/384], Loss: 2.7077, LR: 0.000966
[11:22:22] Epoch [41/300], Step [120/384], Loss: 2.4818, LR: 0.000966
[11:22:24] Epoch [41/300], Step [140/384], Loss: 2.3982, LR: 0.000966
[11:22:26] Epoch [41/300], Step [160/384], Loss: 2.3816, LR: 0.000966
[11:22:29] Epoch [41/300], Step [180/384], Loss: 2.9363, LR: 0.000966
[11:22:31] Epoch [41/300], Step [200/384], Loss: 2.8739, LR: 0.000966
[11:22:33] Epoch [41/300], Step [220/384], Loss: 2.3601, LR: 0.000966
[11:22:35] Epoch [41/300], Step [240/384], Loss: 2.9013, LR: 0.000966
[11:22:37] Epoch [41/300], Step [260/384], Loss: 2.9541, LR: 0.000966
[11:22:39] Epoch [41/300], Step [280/384], Loss: 2.5852, LR: 0.000966
[11:22:41] Epoch [41/300], Step [300/384], Loss: 2.2284, LR: 0.000966
[11:22:44] Epoch [41/300], Step [320/384], Loss: 2.4820, LR: 0.000966
[11:22:46] Epoch [41/300], Step [340/384], Loss: 3.1637, LR: 0.000966
[11:22:48] Epoch [41/300], Step [360/384], Loss: 2.7907, LR: 0.000966
[11:22:50] Epoch [41/300], Step [380/384], Loss: 3.2478, LR: 0.000966
[11:22:51] Epoch 41 Complete. Avg Loss: 2.6557, LR: 0.000966
[11:22:51] Epoch [42/300], Step [0/384], Loss: 2.7891, LR: 0.000964
[11:22:53] Epoch [42/300], Step [20/384], Loss: 2.4135, LR: 0.000964
[11:22:55] Epoch [42/300], Step [40/384], Loss: 2.8066, LR: 0.000964
[11:22:57] Epoch [42/300], Step [60/384], Loss: 3.3387, LR: 0.000964
[11:22:59] Epoch [42/300], Step [80/384], Loss: 2.4034, LR: 0.000964
[11:23:02] Epoch [42/300], Step [100/384], Loss: 2.0623, LR: 0.000964
[11:23:04] Epoch [42/300], Step [120/384], Loss: 2.4967, LR: 0.000964
[11:23:06] Epoch [42/300], Step [140/384], Loss: 2.9367, LR: 0.000964
[11:23:08] Epoch [42/300], Step [160/384], Loss: 2.1361, LR: 0.000964
[11:23:11] Epoch [42/300], Step [180/384], Loss: 2.7551, LR: 0.000964
[11:23:13] Epoch [42/300], Step [200/384], Loss: 2.3893, LR: 0.000964
[11:23:15] Epoch [42/300], Step [220/384], Loss: 2.2256, LR: 0.000964
[11:23:17] Epoch [42/300], Step [240/384], Loss: 3.1756, LR: 0.000964
[11:23:19] Epoch [42/300], Step [260/384], Loss: 2.7361, LR: 0.000964
[11:23:21] Epoch [42/300], Step [280/384], Loss: 2.8340, LR: 0.000964
[11:23:23] Epoch [42/300], Step [300/384], Loss: 2.5032, LR: 0.000964
[11:23:25] Epoch [42/300], Step [320/384], Loss: 2.9847, LR: 0.000964
[11:23:28] Epoch [42/300], Step [340/384], Loss: 2.7304, LR: 0.000964
[11:23:30] Epoch [42/300], Step [360/384], Loss: 2.3769, LR: 0.000964
[11:23:32] Epoch [42/300], Step [380/384], Loss: 2.6554, LR: 0.000964
[11:23:32] Epoch 42 Complete. Avg Loss: 2.6071, LR: 0.000964
  -> New best model saved (loss: 2.6071)
[11:23:32] Epoch [43/300], Step [0/384], Loss: 2.6822, LR: 0.000962
[11:23:35] Epoch [43/300], Step [20/384], Loss: 2.9449, LR: 0.000962
[11:23:37] Epoch [43/300], Step [40/384], Loss: 2.5261, LR: 0.000962
[11:23:39] Epoch [43/300], Step [60/384], Loss: 2.6058, LR: 0.000962
[11:23:41] Epoch [43/300], Step [80/384], Loss: 2.9755, LR: 0.000962
[11:23:43] Epoch [43/300], Step [100/384], Loss: 2.6753, LR: 0.000962
[11:23:45] Epoch [43/300], Step [120/384], Loss: 2.7654, LR: 0.000962
[11:23:48] Epoch [43/300], Step [140/384], Loss: 2.7316, LR: 0.000962
[11:23:50] Epoch [43/300], Step [160/384], Loss: 2.2964, LR: 0.000962
[11:23:52] Epoch [43/300], Step [180/384], Loss: 2.6436, LR: 0.000962
[11:23:54] Epoch [43/300], Step [200/384], Loss: 2.3070, LR: 0.000962
[11:23:56] Epoch [43/300], Step [220/384], Loss: 2.9339, LR: 0.000962
[11:23:59] Epoch [43/300], Step [240/384], Loss: 2.7610, LR: 0.000962
[11:24:01] Epoch [43/300], Step [260/384], Loss: 2.0588, LR: 0.000962
[11:24:03] Epoch [43/300], Step [280/384], Loss: 2.6644, LR: 0.000962
[11:24:05] Epoch [43/300], Step [300/384], Loss: 2.5606, LR: 0.000962
[11:24:08] Epoch [43/300], Step [320/384], Loss: 2.5900, LR: 0.000962
[11:24:10] Epoch [43/300], Step [340/384], Loss: 2.5644, LR: 0.000962
[11:24:12] Epoch [43/300], Step [360/384], Loss: 2.5338, LR: 0.000962
[11:24:14] Epoch [43/300], Step [380/384], Loss: 2.8363, LR: 0.000962
[11:24:14] Epoch 43 Complete. Avg Loss: 2.6018, LR: 0.000962
  -> New best model saved (loss: 2.6018)
[11:24:14] Epoch [44/300], Step [0/384], Loss: 2.5968, LR: 0.000960
[11:24:16] Epoch [44/300], Step [20/384], Loss: 2.5631, LR: 0.000960
[11:24:18] Epoch [44/300], Step [40/384], Loss: 2.8717, LR: 0.000960
[11:24:21] Epoch [44/300], Step [60/384], Loss: 2.8687, LR: 0.000960
[11:24:23] Epoch [44/300], Step [80/384], Loss: 2.1493, LR: 0.000960
[11:24:25] Epoch [44/300], Step [100/384], Loss: 2.9252, LR: 0.000960
[11:24:27] Epoch [44/300], Step [120/384], Loss: 2.3440, LR: 0.000960
[11:24:29] Epoch [44/300], Step [140/384], Loss: 2.5442, LR: 0.000960
[11:24:32] Epoch [44/300], Step [160/384], Loss: 2.5682, LR: 0.000960
[11:24:34] Epoch [44/300], Step [180/384], Loss: 2.6207, LR: 0.000960
[11:24:36] Epoch [44/300], Step [200/384], Loss: 2.5283, LR: 0.000960
[11:24:38] Epoch [44/300], Step [220/384], Loss: 3.2564, LR: 0.000960
[11:24:40] Epoch [44/300], Step [240/384], Loss: 2.0635, LR: 0.000960
[11:24:42] Epoch [44/300], Step [260/384], Loss: 2.2710, LR: 0.000960
[11:24:45] Epoch [44/300], Step [280/384], Loss: 2.4148, LR: 0.000960
[11:24:47] Epoch [44/300], Step [300/384], Loss: 2.5338, LR: 0.000960
[11:24:49] Epoch [44/300], Step [320/384], Loss: 2.5746, LR: 0.000960
[11:24:51] Epoch [44/300], Step [340/384], Loss: 2.4796, LR: 0.000960
[11:24:53] Epoch [44/300], Step [360/384], Loss: 4.1804, LR: 0.000960
[11:24:55] Epoch [44/300], Step [380/384], Loss: 2.1119, LR: 0.000960
[11:24:56] Epoch 44 Complete. Avg Loss: 2.5905, LR: 0.000960
  -> New best model saved (loss: 2.5905)
[11:24:56] Epoch [45/300], Step [0/384], Loss: 2.5637, LR: 0.000958
[11:24:58] Epoch [45/300], Step [20/384], Loss: 2.2695, LR: 0.000958
[11:25:00] Epoch [45/300], Step [40/384], Loss: 2.6834, LR: 0.000958
[11:25:03] Epoch [45/300], Step [60/384], Loss: 2.0664, LR: 0.000958
[11:25:05] Epoch [45/300], Step [80/384], Loss: 2.2845, LR: 0.000958
[11:25:07] Epoch [45/300], Step [100/384], Loss: 2.6759, LR: 0.000958
[11:25:09] Epoch [45/300], Step [120/384], Loss: 2.6413, LR: 0.000958
[11:25:11] Epoch [45/300], Step [140/384], Loss: 2.6453, LR: 0.000958
[11:25:13] Epoch [45/300], Step [160/384], Loss: 2.1597, LR: 0.000958
[11:25:16] Epoch [45/300], Step [180/384], Loss: 1.8824, LR: 0.000958
[11:25:18] Epoch [45/300], Step [200/384], Loss: 2.9299, LR: 0.000958
[11:25:20] Epoch [45/300], Step [220/384], Loss: 2.1955, LR: 0.000958
[11:25:22] Epoch [45/300], Step [240/384], Loss: 2.5271, LR: 0.000958
[11:25:24] Epoch [45/300], Step [260/384], Loss: 2.6467, LR: 0.000958
[11:25:26] Epoch [45/300], Step [280/384], Loss: 2.3456, LR: 0.000958
[11:25:28] Epoch [45/300], Step [300/384], Loss: 2.5359, LR: 0.000958
[11:25:31] Epoch [45/300], Step [320/384], Loss: 2.4419, LR: 0.000958
[11:25:33] Epoch [45/300], Step [340/384], Loss: 2.5891, LR: 0.000958
[11:25:36] Epoch [45/300], Step [360/384], Loss: 3.1068, LR: 0.000958
[11:25:38] Epoch [45/300], Step [380/384], Loss: 3.4906, LR: 0.000958
[11:25:38] Epoch 45 Complete. Avg Loss: 2.5627, LR: 0.000958
  -> New best model saved (loss: 2.5627)
[11:25:38] Epoch [46/300], Step [0/384], Loss: 2.3431, LR: 0.000956
[11:25:41] Epoch [46/300], Step [20/384], Loss: 2.2206, LR: 0.000956
[11:25:43] Epoch [46/300], Step [40/384], Loss: 2.6457, LR: 0.000956
[11:25:45] Epoch [46/300], Step [60/384], Loss: 1.7873, LR: 0.000956
[11:25:47] Epoch [46/300], Step [80/384], Loss: 2.5071, LR: 0.000956
[11:25:50] Epoch [46/300], Step [100/384], Loss: 2.1594, LR: 0.000956
[11:25:52] Epoch [46/300], Step [120/384], Loss: 3.1532, LR: 0.000956
[11:25:54] Epoch [46/300], Step [140/384], Loss: 2.2887, LR: 0.000956
[11:25:56] Epoch [46/300], Step [160/384], Loss: 2.1021, LR: 0.000956
[11:25:58] Epoch [46/300], Step [180/384], Loss: 2.3949, LR: 0.000956
[11:26:01] Epoch [46/300], Step [200/384], Loss: 2.3086, LR: 0.000956
[11:26:03] Epoch [46/300], Step [220/384], Loss: 2.2673, LR: 0.000956
[11:26:05] Epoch [46/300], Step [240/384], Loss: 2.5204, LR: 0.000956
[11:26:07] Epoch [46/300], Step [260/384], Loss: 2.3425, LR: 0.000956
[11:26:09] Epoch [46/300], Step [280/384], Loss: 2.6430, LR: 0.000956
[11:26:11] Epoch [46/300], Step [300/384], Loss: 2.4705, LR: 0.000956
[11:26:13] Epoch [46/300], Step [320/384], Loss: 2.6190, LR: 0.000956
[11:26:16] Epoch [46/300], Step [340/384], Loss: 2.8447, LR: 0.000956
[11:26:18] Epoch [46/300], Step [360/384], Loss: 2.8323, LR: 0.000956
[11:26:20] Epoch [46/300], Step [380/384], Loss: 3.4127, LR: 0.000956
[11:26:21] Epoch 46 Complete. Avg Loss: 2.5497, LR: 0.000956
  -> New best model saved (loss: 2.5497)
[11:26:21] Epoch [47/300], Step [0/384], Loss: 2.2206, LR: 0.000954
[11:26:23] Epoch [47/300], Step [20/384], Loss: 2.2549, LR: 0.000954
[11:26:25] Epoch [47/300], Step [40/384], Loss: 2.6977, LR: 0.000954
[11:26:27] Epoch [47/300], Step [60/384], Loss: 1.9731, LR: 0.000954
[11:26:29] Epoch [47/300], Step [80/384], Loss: 2.9701, LR: 0.000954
[11:26:31] Epoch [47/300], Step [100/384], Loss: 2.9060, LR: 0.000954
[11:26:33] Epoch [47/300], Step [120/384], Loss: 2.8000, LR: 0.000954
[11:26:36] Epoch [47/300], Step [140/384], Loss: 2.4599, LR: 0.000954
[11:26:38] Epoch [47/300], Step [160/384], Loss: 2.3210, LR: 0.000954
[11:26:40] Epoch [47/300], Step [180/384], Loss: 2.2012, LR: 0.000954
[11:26:43] Epoch [47/300], Step [200/384], Loss: 2.2239, LR: 0.000954
[11:26:45] Epoch [47/300], Step [220/384], Loss: 1.8883, LR: 0.000954
[11:26:47] Epoch [47/300], Step [240/384], Loss: 3.0393, LR: 0.000954
[11:26:49] Epoch [47/300], Step [260/384], Loss: 2.2959, LR: 0.000954
[11:26:51] Epoch [47/300], Step [280/384], Loss: 2.8937, LR: 0.000954
[11:26:53] Epoch [47/300], Step [300/384], Loss: 3.2723, LR: 0.000954
[11:26:56] Epoch [47/300], Step [320/384], Loss: 2.2791, LR: 0.000954
[11:26:58] Epoch [47/300], Step [340/384], Loss: 2.6465, LR: 0.000954
[11:27:00] Epoch [47/300], Step [360/384], Loss: 2.5109, LR: 0.000954
[11:27:02] Epoch [47/300], Step [380/384], Loss: 2.6529, LR: 0.000954
[11:27:02] Epoch 47 Complete. Avg Loss: 2.5442, LR: 0.000954
  -> New best model saved (loss: 2.5442)
[11:27:02] Epoch [48/300], Step [0/384], Loss: 2.5416, LR: 0.000951
[11:27:05] Epoch [48/300], Step [20/384], Loss: 2.3984, LR: 0.000951
[11:27:07] Epoch [48/300], Step [40/384], Loss: 2.3922, LR: 0.000951
[11:27:09] Epoch [48/300], Step [60/384], Loss: 2.1812, LR: 0.000951
[11:27:11] Epoch [48/300], Step [80/384], Loss: 2.0882, LR: 0.000951
[11:27:13] Epoch [48/300], Step [100/384], Loss: 2.3759, LR: 0.000951
[11:27:15] Epoch [48/300], Step [120/384], Loss: 2.3343, LR: 0.000951
[11:27:17] Epoch [48/300], Step [140/384], Loss: 3.0008, LR: 0.000951
[11:27:19] Epoch [48/300], Step [160/384], Loss: 2.6683, LR: 0.000951
[11:27:22] Epoch [48/300], Step [180/384], Loss: 3.1519, LR: 0.000951
[11:27:24] Epoch [48/300], Step [200/384], Loss: 2.3656, LR: 0.000951
[11:27:26] Epoch [48/300], Step [220/384], Loss: 2.5778, LR: 0.000951
[11:27:28] Epoch [48/300], Step [240/384], Loss: 2.4742, LR: 0.000951
[11:27:30] Epoch [48/300], Step [260/384], Loss: 2.5732, LR: 0.000951
[11:27:32] Epoch [48/300], Step [280/384], Loss: 2.0463, LR: 0.000951
[11:27:35] Epoch [48/300], Step [300/384], Loss: 2.3669, LR: 0.000951
[11:27:37] Epoch [48/300], Step [320/384], Loss: 2.6182, LR: 0.000951
[11:27:39] Epoch [48/300], Step [340/384], Loss: 2.6725, LR: 0.000951
[11:27:41] Epoch [48/300], Step [360/384], Loss: 3.7836, LR: 0.000951
[11:27:43] Epoch [48/300], Step [380/384], Loss: 2.3646, LR: 0.000951
[11:27:44] Epoch 48 Complete. Avg Loss: 2.5352, LR: 0.000951
  -> New best model saved (loss: 2.5352)
[11:27:44] Epoch [49/300], Step [0/384], Loss: 2.8938, LR: 0.000949
[11:27:46] Epoch [49/300], Step [20/384], Loss: 2.6439, LR: 0.000949
[11:27:48] Epoch [49/300], Step [40/384], Loss: 2.1338, LR: 0.000949
[11:27:50] Epoch [49/300], Step [60/384], Loss: 2.6303, LR: 0.000949
[11:27:53] Epoch [49/300], Step [80/384], Loss: 2.4724, LR: 0.000949
[11:27:55] Epoch [49/300], Step [100/384], Loss: 2.2653, LR: 0.000949
[11:27:57] Epoch [49/300], Step [120/384], Loss: 1.9603, LR: 0.000949
[11:27:59] Epoch [49/300], Step [140/384], Loss: 2.4123, LR: 0.000949
[11:28:01] Epoch [49/300], Step [160/384], Loss: 2.5576, LR: 0.000949
[11:28:04] Epoch [49/300], Step [180/384], Loss: 2.5854, LR: 0.000949
[11:28:06] Epoch [49/300], Step [200/384], Loss: 2.1507, LR: 0.000949
[11:28:08] Epoch [49/300], Step [220/384], Loss: 2.7603, LR: 0.000949
[11:28:10] Epoch [49/300], Step [240/384], Loss: 2.7111, LR: 0.000949
[11:28:12] Epoch [49/300], Step [260/384], Loss: 2.6804, LR: 0.000949
[11:28:14] Epoch [49/300], Step [280/384], Loss: 2.8211, LR: 0.000949
[11:28:17] Epoch [49/300], Step [300/384], Loss: 1.8567, LR: 0.000949
[11:28:19] Epoch [49/300], Step [320/384], Loss: 2.6752, LR: 0.000949
[11:28:21] Epoch [49/300], Step [340/384], Loss: 2.3746, LR: 0.000949
[11:28:23] Epoch [49/300], Step [360/384], Loss: 2.4040, LR: 0.000949
[11:28:25] Epoch [49/300], Step [380/384], Loss: 2.6325, LR: 0.000949
[11:28:26] Epoch 49 Complete. Avg Loss: 2.5258, LR: 0.000949
  -> New best model saved (loss: 2.5258)
[11:28:26] Epoch [50/300], Step [0/384], Loss: 2.8912, LR: 0.000947
[11:28:28] Epoch [50/300], Step [20/384], Loss: 2.8889, LR: 0.000947
[11:28:31] Epoch [50/300], Step [40/384], Loss: 1.9347, LR: 0.000947
[11:28:33] Epoch [50/300], Step [60/384], Loss: 3.1483, LR: 0.000947
[11:28:35] Epoch [50/300], Step [80/384], Loss: 2.4090, LR: 0.000947
[11:28:37] Epoch [50/300], Step [100/384], Loss: 2.3172, LR: 0.000947
[11:28:39] Epoch [50/300], Step [120/384], Loss: 1.8981, LR: 0.000947
[11:28:41] Epoch [50/300], Step [140/384], Loss: 2.6720, LR: 0.000947
[11:28:43] Epoch [50/300], Step [160/384], Loss: 2.6187, LR: 0.000947
[11:28:46] Epoch [50/300], Step [180/384], Loss: 3.6051, LR: 0.000947
[11:28:48] Epoch [50/300], Step [200/384], Loss: 2.6912, LR: 0.000947
[11:28:50] Epoch [50/300], Step [220/384], Loss: 2.3421, LR: 0.000947
[11:28:52] Epoch [50/300], Step [240/384], Loss: 2.3601, LR: 0.000947
[11:28:54] Epoch [50/300], Step [260/384], Loss: 2.5390, LR: 0.000947
[11:28:56] Epoch [50/300], Step [280/384], Loss: 3.3280, LR: 0.000947
[11:28:58] Epoch [50/300], Step [300/384], Loss: 2.5592, LR: 0.000947
[11:29:00] Epoch [50/300], Step [320/384], Loss: 2.6881, LR: 0.000947
[11:29:03] Epoch [50/300], Step [340/384], Loss: 2.6305, LR: 0.000947
[11:29:05] Epoch [50/300], Step [360/384], Loss: 2.5418, LR: 0.000947
[11:29:07] Epoch [50/300], Step [380/384], Loss: 2.3148, LR: 0.000947
[11:29:07] Epoch 50 Complete. Avg Loss: 2.5163, LR: 0.000947
  -> New best model saved (loss: 2.5163)
[11:29:08] Epoch [51/300], Step [0/384], Loss: 2.6997, LR: 0.000944
[11:29:10] Epoch [51/300], Step [20/384], Loss: 2.4708, LR: 0.000944
[11:29:12] Epoch [51/300], Step [40/384], Loss: 3.0945, LR: 0.000944
[11:29:14] Epoch [51/300], Step [60/384], Loss: 2.1593, LR: 0.000944
[11:29:17] Epoch [51/300], Step [80/384], Loss: 2.6042, LR: 0.000944
[11:29:19] Epoch [51/300], Step [100/384], Loss: 2.4501, LR: 0.000944
[11:29:21] Epoch [51/300], Step [120/384], Loss: 3.0857, LR: 0.000944
[11:29:23] Epoch [51/300], Step [140/384], Loss: 2.3352, LR: 0.000944
[11:29:25] Epoch [51/300], Step [160/384], Loss: 2.6020, LR: 0.000944
[11:29:27] Epoch [51/300], Step [180/384], Loss: 2.2718, LR: 0.000944
[11:29:30] Epoch [51/300], Step [200/384], Loss: 2.4091, LR: 0.000944
[11:29:32] Epoch [51/300], Step [220/384], Loss: 2.3532, LR: 0.000944
[11:29:34] Epoch [51/300], Step [240/384], Loss: 2.6653, LR: 0.000944
[11:29:36] Epoch [51/300], Step [260/384], Loss: 2.5934, LR: 0.000944
[11:29:38] Epoch [51/300], Step [280/384], Loss: 2.7307, LR: 0.000944
[11:29:40] Epoch [51/300], Step [300/384], Loss: 1.9383, LR: 0.000944
[11:29:43] Epoch [51/300], Step [320/384], Loss: 2.7572, LR: 0.000944
[11:29:45] Epoch [51/300], Step [340/384], Loss: 3.3423, LR: 0.000944
[11:29:47] Epoch [51/300], Step [360/384], Loss: 2.7441, LR: 0.000944
[11:29:49] Epoch [51/300], Step [380/384], Loss: 2.3379, LR: 0.000944
[11:29:49] Epoch 51 Complete. Avg Loss: 2.5057, LR: 0.000944
  -> New best model saved (loss: 2.5057)
[11:29:49] Epoch [52/300], Step [0/384], Loss: 2.1105, LR: 0.000942
[11:29:52] Epoch [52/300], Step [20/384], Loss: 2.0617, LR: 0.000942
[11:29:53] Epoch [52/300], Step [40/384], Loss: 2.4080, LR: 0.000942
[11:29:55] Epoch [52/300], Step [60/384], Loss: 2.1066, LR: 0.000942
[11:29:58] Epoch [52/300], Step [80/384], Loss: 2.0913, LR: 0.000942
[11:30:00] Epoch [52/300], Step [100/384], Loss: 2.6754, LR: 0.000942
[11:30:02] Epoch [52/300], Step [120/384], Loss: 2.2155, LR: 0.000942
[11:30:04] Epoch [52/300], Step [140/384], Loss: 2.4342, LR: 0.000942
[11:30:06] Epoch [52/300], Step [160/384], Loss: 2.7404, LR: 0.000942
[11:30:09] Epoch [52/300], Step [180/384], Loss: 3.1067, LR: 0.000942
[11:30:11] Epoch [52/300], Step [200/384], Loss: 2.9765, LR: 0.000942
[11:30:13] Epoch [52/300], Step [220/384], Loss: 2.7363, LR: 0.000942
[11:30:15] Epoch [52/300], Step [240/384], Loss: 2.0958, LR: 0.000942
[11:30:18] Epoch [52/300], Step [260/384], Loss: 2.0433, LR: 0.000942
[11:30:37] Epoch [52/300], Step [280/384], Loss: 3.1512, LR: 0.000942
[11:30:40] Epoch [52/300], Step [300/384], Loss: 2.7850, LR: 0.000942
[11:30:42] Epoch [52/300], Step [320/384], Loss: 2.7001, LR: 0.000942
[11:30:44] Epoch [52/300], Step [340/384], Loss: 2.7472, LR: 0.000942
[11:30:46] Epoch [52/300], Step [360/384], Loss: 2.2606, LR: 0.000942
[11:30:48] Epoch [52/300], Step [380/384], Loss: 2.6556, LR: 0.000942
[11:30:49] Epoch 52 Complete. Avg Loss: 2.4813, LR: 0.000942
  -> New best model saved (loss: 2.4813)
[11:30:49] Epoch [53/300], Step [0/384], Loss: 2.0655, LR: 0.000939
[11:30:51] Epoch [53/300], Step [20/384], Loss: 2.8355, LR: 0.000939
[11:30:54] Epoch [53/300], Step [40/384], Loss: 2.1879, LR: 0.000939
[11:30:55] Epoch [53/300], Step [60/384], Loss: 2.4606, LR: 0.000939
[11:30:58] Epoch [53/300], Step [80/384], Loss: 2.4752, LR: 0.000939
[11:31:00] Epoch [53/300], Step [100/384], Loss: 3.3974, LR: 0.000939
[11:31:02] Epoch [53/300], Step [120/384], Loss: 2.1143, LR: 0.000939
[11:31:04] Epoch [53/300], Step [140/384], Loss: 2.4098, LR: 0.000939
[11:31:06] Epoch [53/300], Step [160/384], Loss: 2.4894, LR: 0.000939
[11:31:08] Epoch [53/300], Step [180/384], Loss: 2.3500, LR: 0.000939
[11:31:10] Epoch [53/300], Step [200/384], Loss: 3.0720, LR: 0.000939
[11:31:13] Epoch [53/300], Step [220/384], Loss: 2.7520, LR: 0.000939
[11:31:15] Epoch [53/300], Step [240/384], Loss: 2.1855, LR: 0.000939
[11:31:17] Epoch [53/300], Step [260/384], Loss: 2.7084, LR: 0.000939
[11:31:19] Epoch [53/300], Step [280/384], Loss: 2.6660, LR: 0.000939
[11:31:21] Epoch [53/300], Step [300/384], Loss: 2.1738, LR: 0.000939
[11:31:23] Epoch [53/300], Step [320/384], Loss: 2.3174, LR: 0.000939
[11:31:26] Epoch [53/300], Step [340/384], Loss: 2.6951, LR: 0.000939
[11:31:28] Epoch [53/300], Step [360/384], Loss: 2.4646, LR: 0.000939
[11:31:30] Epoch [53/300], Step [380/384], Loss: 3.2682, LR: 0.000939
[11:31:30] Epoch 53 Complete. Avg Loss: 2.4763, LR: 0.000939
  -> New best model saved (loss: 2.4763)
[11:31:30] Epoch [54/300], Step [0/384], Loss: 2.3982, LR: 0.000937
[11:31:33] Epoch [54/300], Step [20/384], Loss: 2.6068, LR: 0.000937
[11:31:35] Epoch [54/300], Step [40/384], Loss: 2.5396, LR: 0.000937
[11:31:37] Epoch [54/300], Step [60/384], Loss: 2.3422, LR: 0.000937
[11:31:40] Epoch [54/300], Step [80/384], Loss: 2.5334, LR: 0.000937
[11:31:42] Epoch [54/300], Step [100/384], Loss: 2.8883, LR: 0.000937
[11:31:44] Epoch [54/300], Step [120/384], Loss: 2.5147, LR: 0.000937
[11:31:46] Epoch [54/300], Step [140/384], Loss: 2.6443, LR: 0.000937
[11:31:48] Epoch [54/300], Step [160/384], Loss: 2.9756, LR: 0.000937
[11:31:50] Epoch [54/300], Step [180/384], Loss: 2.6056, LR: 0.000937
[11:31:52] Epoch [54/300], Step [200/384], Loss: 2.7176, LR: 0.000937
[11:31:54] Epoch [54/300], Step [220/384], Loss: 2.6887, LR: 0.000937
[11:31:56] Epoch [54/300], Step [240/384], Loss: 3.0886, LR: 0.000937
[11:31:58] Epoch [54/300], Step [260/384], Loss: 2.2940, LR: 0.000937
[11:32:01] Epoch [54/300], Step [280/384], Loss: 2.5644, LR: 0.000937
[11:32:03] Epoch [54/300], Step [300/384], Loss: 1.9903, LR: 0.000937
[11:32:05] Epoch [54/300], Step [320/384], Loss: 2.6567, LR: 0.000937
[11:32:07] Epoch [54/300], Step [340/384], Loss: 2.4800, LR: 0.000937
[11:32:09] Epoch [54/300], Step [360/384], Loss: 2.2605, LR: 0.000937
[11:32:12] Epoch [54/300], Step [380/384], Loss: 3.2694, LR: 0.000937
[11:32:12] Epoch 54 Complete. Avg Loss: 2.4708, LR: 0.000937
  -> New best model saved (loss: 2.4708)
[11:32:12] Epoch [55/300], Step [0/384], Loss: 2.7393, LR: 0.000934
[11:32:14] Epoch [55/300], Step [20/384], Loss: 2.0168, LR: 0.000934
[11:32:16] Epoch [55/300], Step [40/384], Loss: 2.6727, LR: 0.000934
[11:32:18] Epoch [55/300], Step [60/384], Loss: 2.9090, LR: 0.000934
[11:32:20] Epoch [55/300], Step [80/384], Loss: 2.3125, LR: 0.000934
[11:32:23] Epoch [55/300], Step [100/384], Loss: 1.9769, LR: 0.000934
[11:32:25] Epoch [55/300], Step [120/384], Loss: 2.5836, LR: 0.000934
[11:32:27] Epoch [55/300], Step [140/384], Loss: 3.4912, LR: 0.000934
[11:32:29] Epoch [55/300], Step [160/384], Loss: 2.4369, LR: 0.000934
[11:32:31] Epoch [55/300], Step [180/384], Loss: 2.6869, LR: 0.000934
[11:32:33] Epoch [55/300], Step [200/384], Loss: 1.9122, LR: 0.000934
[11:32:36] Epoch [55/300], Step [220/384], Loss: 2.5148, LR: 0.000934
[11:32:38] Epoch [55/300], Step [240/384], Loss: 2.6076, LR: 0.000934
[11:32:40] Epoch [55/300], Step [260/384], Loss: 2.5446, LR: 0.000934
[11:32:42] Epoch [55/300], Step [280/384], Loss: 3.1675, LR: 0.000934
[11:32:45] Epoch [55/300], Step [300/384], Loss: 2.2551, LR: 0.000934
[11:32:47] Epoch [55/300], Step [320/384], Loss: 2.2329, LR: 0.000934
[11:32:49] Epoch [55/300], Step [340/384], Loss: 2.4577, LR: 0.000934
[11:32:51] Epoch [55/300], Step [360/384], Loss: 1.9507, LR: 0.000934
[11:32:53] Epoch [55/300], Step [380/384], Loss: 2.5799, LR: 0.000934
[11:32:53] Epoch 55 Complete. Avg Loss: 2.4777, LR: 0.000934
[11:32:54] Epoch [56/300], Step [0/384], Loss: 3.0674, LR: 0.000931
[11:32:56] Epoch [56/300], Step [20/384], Loss: 2.3802, LR: 0.000931
[11:32:58] Epoch [56/300], Step [40/384], Loss: 2.9018, LR: 0.000931
[11:33:00] Epoch [56/300], Step [60/384], Loss: 3.1246, LR: 0.000931
[11:33:02] Epoch [56/300], Step [80/384], Loss: 2.0169, LR: 0.000931
[11:33:04] Epoch [56/300], Step [100/384], Loss: 2.1628, LR: 0.000931
[11:33:06] Epoch [56/300], Step [120/384], Loss: 2.5428, LR: 0.000931
[11:33:09] Epoch [56/300], Step [140/384], Loss: 2.3923, LR: 0.000931
[11:33:11] Epoch [56/300], Step [160/384], Loss: 2.1026, LR: 0.000931
[11:33:13] Epoch [56/300], Step [180/384], Loss: 2.6855, LR: 0.000931
[11:33:15] Epoch [56/300], Step [200/384], Loss: 2.1841, LR: 0.000931
[11:33:18] Epoch [56/300], Step [220/384], Loss: 2.2593, LR: 0.000931
[11:33:20] Epoch [56/300], Step [240/384], Loss: 2.7057, LR: 0.000931
[11:33:22] Epoch [56/300], Step [260/384], Loss: 2.0551, LR: 0.000931
[11:33:24] Epoch [56/300], Step [280/384], Loss: 2.7971, LR: 0.000931
[11:33:26] Epoch [56/300], Step [300/384], Loss: 2.8277, LR: 0.000931
[11:33:28] Epoch [56/300], Step [320/384], Loss: 2.0906, LR: 0.000931
[11:33:30] Epoch [56/300], Step [340/384], Loss: 2.3917, LR: 0.000931
[11:33:33] Epoch [56/300], Step [360/384], Loss: 2.7115, LR: 0.000931
[11:33:35] Epoch [56/300], Step [380/384], Loss: 2.5101, LR: 0.000931
[11:33:35] Epoch 56 Complete. Avg Loss: 2.4701, LR: 0.000931
  -> New best model saved (loss: 2.4701)
[11:33:35] Epoch [57/300], Step [0/384], Loss: 2.2460, LR: 0.000929
[11:33:38] Epoch [57/300], Step [20/384], Loss: 2.3694, LR: 0.000929
[11:33:40] Epoch [57/300], Step [40/384], Loss: 2.1897, LR: 0.000929
[11:33:42] Epoch [57/300], Step [60/384], Loss: 2.7519, LR: 0.000929
[11:33:44] Epoch [57/300], Step [80/384], Loss: 2.8201, LR: 0.000929
[11:33:46] Epoch [57/300], Step [100/384], Loss: 2.2967, LR: 0.000929
[11:33:48] Epoch [57/300], Step [120/384], Loss: 2.1346, LR: 0.000929
[11:33:50] Epoch [57/300], Step [140/384], Loss: 2.4296, LR: 0.000929
[11:33:53] Epoch [57/300], Step [160/384], Loss: 2.4307, LR: 0.000929
[11:33:55] Epoch [57/300], Step [180/384], Loss: 2.1664, LR: 0.000929
[11:33:57] Epoch [57/300], Step [200/384], Loss: 2.1093, LR: 0.000929
[11:33:59] Epoch [57/300], Step [220/384], Loss: 2.5274, LR: 0.000929
[11:34:01] Epoch [57/300], Step [240/384], Loss: 2.4717, LR: 0.000929
[11:34:03] Epoch [57/300], Step [260/384], Loss: 2.6582, LR: 0.000929
[11:34:06] Epoch [57/300], Step [280/384], Loss: 2.2191, LR: 0.000929
[11:34:08] Epoch [57/300], Step [300/384], Loss: 2.3912, LR: 0.000929
[11:34:10] Epoch [57/300], Step [320/384], Loss: 2.5965, LR: 0.000929
[11:34:12] Epoch [57/300], Step [340/384], Loss: 2.2727, LR: 0.000929
[11:34:14] Epoch [57/300], Step [360/384], Loss: 2.3845, LR: 0.000929
[11:34:16] Epoch [57/300], Step [380/384], Loss: 2.8130, LR: 0.000929
[11:34:17] Epoch 57 Complete. Avg Loss: 2.4471, LR: 0.000929
  -> New best model saved (loss: 2.4471)
[11:34:17] Epoch [58/300], Step [0/384], Loss: 2.4903, LR: 0.000926
[11:34:19] Epoch [58/300], Step [20/384], Loss: 2.3150, LR: 0.000926
[11:34:21] Epoch [58/300], Step [40/384], Loss: 2.1253, LR: 0.000926
[11:34:23] Epoch [58/300], Step [60/384], Loss: 2.1739, LR: 0.000926
[11:34:26] Epoch [58/300], Step [80/384], Loss: 2.3594, LR: 0.000926
[11:34:28] Epoch [58/300], Step [100/384], Loss: 2.4416, LR: 0.000926
[11:34:30] Epoch [58/300], Step [120/384], Loss: 2.4085, LR: 0.000926
[11:34:32] Epoch [58/300], Step [140/384], Loss: 2.3194, LR: 0.000926
[11:34:34] Epoch [58/300], Step [160/384], Loss: 2.1434, LR: 0.000926
[11:34:36] Epoch [58/300], Step [180/384], Loss: 2.1411, LR: 0.000926
[11:34:38] Epoch [58/300], Step [200/384], Loss: 2.1155, LR: 0.000926
[11:34:40] Epoch [58/300], Step [220/384], Loss: 2.1951, LR: 0.000926
[11:34:43] Epoch [58/300], Step [240/384], Loss: 2.0872, LR: 0.000926
[11:34:45] Epoch [58/300], Step [260/384], Loss: 2.9844, LR: 0.000926
[11:34:47] Epoch [58/300], Step [280/384], Loss: 2.2173, LR: 0.000926
[11:34:49] Epoch [58/300], Step [300/384], Loss: 2.4725, LR: 0.000926
[11:34:51] Epoch [58/300], Step [320/384], Loss: 2.9949, LR: 0.000926
[11:34:54] Epoch [58/300], Step [340/384], Loss: 2.2820, LR: 0.000926
[11:34:56] Epoch [58/300], Step [360/384], Loss: 2.6712, LR: 0.000926
[11:34:58] Epoch [58/300], Step [380/384], Loss: 3.3529, LR: 0.000926
[11:34:58] Epoch 58 Complete. Avg Loss: 2.4349, LR: 0.000926
  -> New best model saved (loss: 2.4349)
[11:34:59] Epoch [59/300], Step [0/384], Loss: 2.3595, LR: 0.000923
[11:35:01] Epoch [59/300], Step [20/384], Loss: 1.9557, LR: 0.000923
[11:35:03] Epoch [59/300], Step [40/384], Loss: 2.3463, LR: 0.000923
[11:35:05] Epoch [59/300], Step [60/384], Loss: 2.1414, LR: 0.000923
[11:35:07] Epoch [59/300], Step [80/384], Loss: 2.0428, LR: 0.000923
[11:35:09] Epoch [59/300], Step [100/384], Loss: 2.1368, LR: 0.000923
[11:35:11] Epoch [59/300], Step [120/384], Loss: 2.0001, LR: 0.000923
[11:35:13] Epoch [59/300], Step [140/384], Loss: 1.9085, LR: 0.000923
[11:35:15] Epoch [59/300], Step [160/384], Loss: 2.3273, LR: 0.000923
[11:35:18] Epoch [59/300], Step [180/384], Loss: 2.2166, LR: 0.000923
[11:35:20] Epoch [59/300], Step [200/384], Loss: 2.2942, LR: 0.000923
[11:35:22] Epoch [59/300], Step [220/384], Loss: 2.6495, LR: 0.000923
[11:35:24] Epoch [59/300], Step [240/384], Loss: 2.3902, LR: 0.000923
[11:35:27] Epoch [59/300], Step [260/384], Loss: 2.3044, LR: 0.000923
[11:35:29] Epoch [59/300], Step [280/384], Loss: 2.3621, LR: 0.000923
[11:35:31] Epoch [59/300], Step [300/384], Loss: 2.4340, LR: 0.000923
[11:35:33] Epoch [59/300], Step [320/384], Loss: 2.2920, LR: 0.000923
[11:35:35] Epoch [59/300], Step [340/384], Loss: 2.1657, LR: 0.000923
[11:35:37] Epoch [59/300], Step [360/384], Loss: 2.2218, LR: 0.000923
[11:35:40] Epoch [59/300], Step [380/384], Loss: 2.2777, LR: 0.000923
[11:35:40] Epoch 59 Complete. Avg Loss: 2.4480, LR: 0.000923
[11:35:40] Epoch [60/300], Step [0/384], Loss: 2.5180, LR: 0.000920
[11:35:42] Epoch [60/300], Step [20/384], Loss: 1.8922, LR: 0.000920
[11:35:44] Epoch [60/300], Step [40/384], Loss: 2.2820, LR: 0.000920
[11:35:47] Epoch [60/300], Step [60/384], Loss: 2.7948, LR: 0.000920
[11:35:49] Epoch [60/300], Step [80/384], Loss: 2.6357, LR: 0.000920
[11:35:51] Epoch [60/300], Step [100/384], Loss: 2.5833, LR: 0.000920
[11:35:53] Epoch [60/300], Step [120/384], Loss: 1.8790, LR: 0.000920
[11:35:55] Epoch [60/300], Step [140/384], Loss: 2.2602, LR: 0.000920
[11:35:57] Epoch [60/300], Step [160/384], Loss: 2.4690, LR: 0.000920
[11:36:00] Epoch [60/300], Step [180/384], Loss: 2.2595, LR: 0.000920
[11:36:02] Epoch [60/300], Step [200/384], Loss: 2.1855, LR: 0.000920
[11:36:04] Epoch [60/300], Step [220/384], Loss: 3.1478, LR: 0.000920
[11:36:06] Epoch [60/300], Step [240/384], Loss: 2.0490, LR: 0.000920
[11:36:08] Epoch [60/300], Step [260/384], Loss: 2.6515, LR: 0.000920
[11:36:10] Epoch [60/300], Step [280/384], Loss: 1.9193, LR: 0.000920
[11:36:12] Epoch [60/300], Step [300/384], Loss: 2.1021, LR: 0.000920
[11:36:14] Epoch [60/300], Step [320/384], Loss: 2.3142, LR: 0.000920
[11:36:17] Epoch [60/300], Step [340/384], Loss: 2.3523, LR: 0.000920
[11:36:19] Epoch [60/300], Step [360/384], Loss: 2.1195, LR: 0.000920
[11:36:21] Epoch [60/300], Step [380/384], Loss: 2.7769, LR: 0.000920
[11:36:21] Epoch 60 Complete. Avg Loss: 2.4434, LR: 0.000920
[11:36:22] Epoch [61/300], Step [0/384], Loss: 1.9896, LR: 0.000917
[11:36:24] Epoch [61/300], Step [20/384], Loss: 1.9745, LR: 0.000917
[11:36:26] Epoch [61/300], Step [40/384], Loss: 2.2438, LR: 0.000917
[11:36:28] Epoch [61/300], Step [60/384], Loss: 2.4232, LR: 0.000917
[11:36:30] Epoch [61/300], Step [80/384], Loss: 2.6699, LR: 0.000917
[11:36:32] Epoch [61/300], Step [100/384], Loss: 2.2519, LR: 0.000917
[11:36:34] Epoch [61/300], Step [120/384], Loss: 2.4078, LR: 0.000917
[11:36:37] Epoch [61/300], Step [140/384], Loss: 2.3201, LR: 0.000917
[11:36:39] Epoch [61/300], Step [160/384], Loss: 1.8518, LR: 0.000917
[11:36:41] Epoch [61/300], Step [180/384], Loss: 2.1940, LR: 0.000917
[11:36:43] Epoch [61/300], Step [200/384], Loss: 2.2255, LR: 0.000917
[11:36:45] Epoch [61/300], Step [220/384], Loss: 2.0682, LR: 0.000917
[11:36:47] Epoch [61/300], Step [240/384], Loss: 3.3073, LR: 0.000917
[11:36:50] Epoch [61/300], Step [260/384], Loss: 1.8513, LR: 0.000917
[11:36:52] Epoch [61/300], Step [280/384], Loss: 2.2858, LR: 0.000917
[11:36:54] Epoch [61/300], Step [300/384], Loss: 2.3583, LR: 0.000917
[11:36:56] Epoch [61/300], Step [320/384], Loss: 2.4539, LR: 0.000917
[11:36:58] Epoch [61/300], Step [340/384], Loss: 2.6922, LR: 0.000917
[11:37:01] Epoch [61/300], Step [360/384], Loss: 2.0375, LR: 0.000917
[11:37:03] Epoch [61/300], Step [380/384], Loss: 3.0193, LR: 0.000917
[11:37:03] Epoch 61 Complete. Avg Loss: 2.4345, LR: 0.000917
  -> New best model saved (loss: 2.4345)
[11:37:03] Epoch [62/300], Step [0/384], Loss: 2.4742, LR: 0.000915
[11:37:05] Epoch [62/300], Step [20/384], Loss: 3.2701, LR: 0.000915
[11:37:08] Epoch [62/300], Step [40/384], Loss: 2.3167, LR: 0.000915
[11:37:10] Epoch [62/300], Step [60/384], Loss: 2.3654, LR: 0.000915
[11:37:12] Epoch [62/300], Step [80/384], Loss: 2.2846, LR: 0.000915
[11:37:14] Epoch [62/300], Step [100/384], Loss: 2.0551, LR: 0.000915
[11:37:16] Epoch [62/300], Step [120/384], Loss: 2.2219, LR: 0.000915
[11:37:18] Epoch [62/300], Step [140/384], Loss: 2.4764, LR: 0.000915
[11:37:21] Epoch [62/300], Step [160/384], Loss: 2.3336, LR: 0.000915
[11:37:23] Epoch [62/300], Step [180/384], Loss: 2.0517, LR: 0.000915
[11:37:25] Epoch [62/300], Step [200/384], Loss: 2.4763, LR: 0.000915
[11:37:27] Epoch [62/300], Step [220/384], Loss: 2.0106, LR: 0.000915
[11:37:29] Epoch [62/300], Step [240/384], Loss: 2.4920, LR: 0.000915
[11:37:31] Epoch [62/300], Step [260/384], Loss: 2.0552, LR: 0.000915
[11:37:33] Epoch [62/300], Step [280/384], Loss: 2.2127, LR: 0.000915
[11:37:36] Epoch [62/300], Step [300/384], Loss: 2.4549, LR: 0.000915
[11:37:38] Epoch [62/300], Step [320/384], Loss: 2.0148, LR: 0.000915
[11:37:40] Epoch [62/300], Step [340/384], Loss: 2.7985, LR: 0.000915
[11:37:42] Epoch [62/300], Step [360/384], Loss: 2.7160, LR: 0.000915
[11:37:44] Epoch [62/300], Step [380/384], Loss: 2.6669, LR: 0.000915
[11:37:45] Epoch 62 Complete. Avg Loss: 2.4051, LR: 0.000915
  -> New best model saved (loss: 2.4051)
[11:37:45] Epoch [63/300], Step [0/384], Loss: 2.3058, LR: 0.000912
[11:37:47] Epoch [63/300], Step [20/384], Loss: 2.3892, LR: 0.000912
[11:37:49] Epoch [63/300], Step [40/384], Loss: 2.1936, LR: 0.000912
[11:37:51] Epoch [63/300], Step [60/384], Loss: 2.4664, LR: 0.000912
[11:37:54] Epoch [63/300], Step [80/384], Loss: 2.1659, LR: 0.000912
[11:37:56] Epoch [63/300], Step [100/384], Loss: 2.3612, LR: 0.000912
[11:37:58] Epoch [63/300], Step [120/384], Loss: 2.4895, LR: 0.000912
[11:38:00] Epoch [63/300], Step [140/384], Loss: 1.9422, LR: 0.000912
[11:38:02] Epoch [63/300], Step [160/384], Loss: 2.5585, LR: 0.000912
[11:38:05] Epoch [63/300], Step [180/384], Loss: 2.2136, LR: 0.000912
[11:38:07] Epoch [63/300], Step [200/384], Loss: 2.3223, LR: 0.000912
[11:38:09] Epoch [63/300], Step [220/384], Loss: 2.7662, LR: 0.000912
[11:38:11] Epoch [63/300], Step [240/384], Loss: 2.4286, LR: 0.000912
[11:38:13] Epoch [63/300], Step [260/384], Loss: 1.9269, LR: 0.000912
[11:38:15] Epoch [63/300], Step [280/384], Loss: 2.0863, LR: 0.000912
[11:38:18] Epoch [63/300], Step [300/384], Loss: 1.9803, LR: 0.000912
[11:38:20] Epoch [63/300], Step [320/384], Loss: 2.0664, LR: 0.000912
[11:38:22] Epoch [63/300], Step [340/384], Loss: 2.8844, LR: 0.000912
[11:38:24] Epoch [63/300], Step [360/384], Loss: 2.7973, LR: 0.000912
[11:38:26] Epoch [63/300], Step [380/384], Loss: 3.4506, LR: 0.000912
[11:38:26] Epoch 63 Complete. Avg Loss: 2.3940, LR: 0.000912
  -> New best model saved (loss: 2.3940)
[11:38:27] Epoch [64/300], Step [0/384], Loss: 2.1433, LR: 0.000909
[11:38:29] Epoch [64/300], Step [20/384], Loss: 2.6967, LR: 0.000909
[11:38:31] Epoch [64/300], Step [40/384], Loss: 2.5005, LR: 0.000909
[11:38:33] Epoch [64/300], Step [60/384], Loss: 2.8142, LR: 0.000909
[11:38:36] Epoch [64/300], Step [80/384], Loss: 2.4169, LR: 0.000909
[11:38:38] Epoch [64/300], Step [100/384], Loss: 2.0100, LR: 0.000909
[11:38:40] Epoch [64/300], Step [120/384], Loss: 2.7950, LR: 0.000909
[11:38:42] Epoch [64/300], Step [140/384], Loss: 2.1489, LR: 0.000909
[11:38:44] Epoch [64/300], Step [160/384], Loss: 2.5345, LR: 0.000909
[11:38:46] Epoch [64/300], Step [180/384], Loss: 2.2211, LR: 0.000909
[11:38:48] Epoch [64/300], Step [200/384], Loss: 1.9480, LR: 0.000909
[11:38:50] Epoch [64/300], Step [220/384], Loss: 2.1563, LR: 0.000909
[11:38:52] Epoch [64/300], Step [240/384], Loss: 2.6102, LR: 0.000909
[11:38:55] Epoch [64/300], Step [260/384], Loss: 2.5291, LR: 0.000909
[11:38:57] Epoch [64/300], Step [280/384], Loss: 1.9772, LR: 0.000909
[11:38:59] Epoch [64/300], Step [300/384], Loss: 2.4210, LR: 0.000909
[11:39:01] Epoch [64/300], Step [320/384], Loss: 2.5185, LR: 0.000909
[11:39:03] Epoch [64/300], Step [340/384], Loss: 3.3163, LR: 0.000909
[11:39:06] Epoch [64/300], Step [360/384], Loss: 2.3151, LR: 0.000909
[11:39:08] Epoch [64/300], Step [380/384], Loss: 2.6284, LR: 0.000909
[11:39:08] Epoch 64 Complete. Avg Loss: 2.3831, LR: 0.000909
  -> New best model saved (loss: 2.3831)
[11:39:08] Epoch [65/300], Step [0/384], Loss: 2.6867, LR: 0.000905
[11:39:10] Epoch [65/300], Step [20/384], Loss: 2.1589, LR: 0.000905
[11:39:13] Epoch [65/300], Step [40/384], Loss: 2.3937, LR: 0.000905
[11:39:15] Epoch [65/300], Step [60/384], Loss: 2.3559, LR: 0.000905
[11:39:17] Epoch [65/300], Step [80/384], Loss: 2.1979, LR: 0.000905
[11:39:20] Epoch [65/300], Step [100/384], Loss: 2.3297, LR: 0.000905
[11:39:22] Epoch [65/300], Step [120/384], Loss: 2.6145, LR: 0.000905
[11:39:24] Epoch [65/300], Step [140/384], Loss: 1.8003, LR: 0.000905
[11:39:26] Epoch [65/300], Step [160/384], Loss: 2.8943, LR: 0.000905
[11:39:28] Epoch [65/300], Step [180/384], Loss: 1.9917, LR: 0.000905
[11:39:30] Epoch [65/300], Step [200/384], Loss: 2.4545, LR: 0.000905
[11:39:32] Epoch [65/300], Step [220/384], Loss: 1.9560, LR: 0.000905
[11:39:34] Epoch [65/300], Step [240/384], Loss: 2.6109, LR: 0.000905
[11:39:37] Epoch [65/300], Step [260/384], Loss: 2.9224, LR: 0.000905
[11:39:39] Epoch [65/300], Step [280/384], Loss: 2.1613, LR: 0.000905
[11:39:41] Epoch [65/300], Step [300/384], Loss: 1.8583, LR: 0.000905
[11:39:43] Epoch [65/300], Step [320/384], Loss: 2.8060, LR: 0.000905
[11:39:45] Epoch [65/300], Step [340/384], Loss: 3.2486, LR: 0.000905
[11:39:47] Epoch [65/300], Step [360/384], Loss: 2.0120, LR: 0.000905
[11:39:50] Epoch [65/300], Step [380/384], Loss: 2.9452, LR: 0.000905
[11:39:50] Epoch 65 Complete. Avg Loss: 2.3800, LR: 0.000905
  -> New best model saved (loss: 2.3800)
[11:39:50] Epoch [66/300], Step [0/384], Loss: 2.5659, LR: 0.000902
[11:39:52] Epoch [66/300], Step [20/384], Loss: 2.0397, LR: 0.000902
[11:39:54] Epoch [66/300], Step [40/384], Loss: 2.3967, LR: 0.000902
[11:39:57] Epoch [66/300], Step [60/384], Loss: 2.0953, LR: 0.000902
[11:39:59] Epoch [66/300], Step [80/384], Loss: 2.2933, LR: 0.000902
[11:40:01] Epoch [66/300], Step [100/384], Loss: 2.3695, LR: 0.000902
[11:40:04] Epoch [66/300], Step [120/384], Loss: 2.4190, LR: 0.000902
[11:40:06] Epoch [66/300], Step [140/384], Loss: 2.8134, LR: 0.000902
[11:40:08] Epoch [66/300], Step [160/384], Loss: 3.1664, LR: 0.000902
[11:40:10] Epoch [66/300], Step [180/384], Loss: 2.5206, LR: 0.000902
[11:40:12] Epoch [66/300], Step [200/384], Loss: 2.4068, LR: 0.000902
[11:40:14] Epoch [66/300], Step [220/384], Loss: 2.5532, LR: 0.000902
[11:40:16] Epoch [66/300], Step [240/384], Loss: 2.0490, LR: 0.000902
[11:40:19] Epoch [66/300], Step [260/384], Loss: 2.2760, LR: 0.000902
[11:40:21] Epoch [66/300], Step [280/384], Loss: 2.4641, LR: 0.000902
[11:40:23] Epoch [66/300], Step [300/384], Loss: 2.6168, LR: 0.000902
[11:40:25] Epoch [66/300], Step [320/384], Loss: 2.5912, LR: 0.000902
[11:40:27] Epoch [66/300], Step [340/384], Loss: 3.1506, LR: 0.000902
[11:40:29] Epoch [66/300], Step [360/384], Loss: 3.1745, LR: 0.000902
[11:40:31] Epoch [66/300], Step [380/384], Loss: 2.2188, LR: 0.000902
[11:40:31] Epoch 66 Complete. Avg Loss: 2.3774, LR: 0.000902
  -> New best model saved (loss: 2.3774)
[11:40:32] Epoch [67/300], Step [0/384], Loss: 2.7694, LR: 0.000899
[11:40:34] Epoch [67/300], Step [20/384], Loss: 2.3738, LR: 0.000899
[11:40:36] Epoch [67/300], Step [40/384], Loss: 1.9444, LR: 0.000899
[11:40:38] Epoch [67/300], Step [60/384], Loss: 2.4939, LR: 0.000899
[11:40:40] Epoch [67/300], Step [80/384], Loss: 3.2033, LR: 0.000899
[11:40:43] Epoch [67/300], Step [100/384], Loss: 2.2687, LR: 0.000899
[11:40:45] Epoch [67/300], Step [120/384], Loss: 2.7022, LR: 0.000899
[11:40:47] Epoch [67/300], Step [140/384], Loss: 2.0193, LR: 0.000899
[11:40:49] Epoch [67/300], Step [160/384], Loss: 2.8217, LR: 0.000899
[11:40:51] Epoch [67/300], Step [180/384], Loss: 2.3057, LR: 0.000899
[11:40:53] Epoch [67/300], Step [200/384], Loss: 2.4778, LR: 0.000899
[11:40:56] Epoch [67/300], Step [220/384], Loss: 2.5024, LR: 0.000899
[11:40:58] Epoch [67/300], Step [240/384], Loss: 3.0566, LR: 0.000899
[11:41:00] Epoch [67/300], Step [260/384], Loss: 2.4498, LR: 0.000899
[11:41:02] Epoch [67/300], Step [280/384], Loss: 1.8408, LR: 0.000899
[11:41:04] Epoch [67/300], Step [300/384], Loss: 2.0401, LR: 0.000899
[11:41:07] Epoch [67/300], Step [320/384], Loss: 1.7875, LR: 0.000899
[11:41:09] Epoch [67/300], Step [340/384], Loss: 2.5769, LR: 0.000899
[11:41:11] Epoch [67/300], Step [360/384], Loss: 3.3535, LR: 0.000899
[11:41:13] Epoch [67/300], Step [380/384], Loss: 2.0691, LR: 0.000899
[11:41:13] Epoch 67 Complete. Avg Loss: 2.3805, LR: 0.000899
[11:41:14] Epoch [68/300], Step [0/384], Loss: 2.2005, LR: 0.000896
[11:41:16] Epoch [68/300], Step [20/384], Loss: 2.2050, LR: 0.000896
[11:41:18] Epoch [68/300], Step [40/384], Loss: 2.0948, LR: 0.000896
[11:41:20] Epoch [68/300], Step [60/384], Loss: 2.0545, LR: 0.000896
[11:41:22] Epoch [68/300], Step [80/384], Loss: 2.4661, LR: 0.000896
[11:41:25] Epoch [68/300], Step [100/384], Loss: 2.5631, LR: 0.000896
[11:41:27] Epoch [68/300], Step [120/384], Loss: 2.8426, LR: 0.000896
[11:41:29] Epoch [68/300], Step [140/384], Loss: 2.3031, LR: 0.000896
[11:41:31] Epoch [68/300], Step [160/384], Loss: 2.1275, LR: 0.000896
[11:41:33] Epoch [68/300], Step [180/384], Loss: 2.6715, LR: 0.000896
[11:41:36] Epoch [68/300], Step [200/384], Loss: 2.2858, LR: 0.000896
[11:41:37] Epoch [68/300], Step [220/384], Loss: 2.2006, LR: 0.000896
[11:41:40] Epoch [68/300], Step [240/384], Loss: 2.3576, LR: 0.000896
[11:41:42] Epoch [68/300], Step [260/384], Loss: 2.3788, LR: 0.000896
[11:41:44] Epoch [68/300], Step [280/384], Loss: 2.2587, LR: 0.000896
[11:41:46] Epoch [68/300], Step [300/384], Loss: 2.2329, LR: 0.000896
[11:41:48] Epoch [68/300], Step [320/384], Loss: 2.3427, LR: 0.000896
[11:41:50] Epoch [68/300], Step [340/384], Loss: 2.0925, LR: 0.000896
[11:41:53] Epoch [68/300], Step [360/384], Loss: 1.9197, LR: 0.000896
[11:41:55] Epoch [68/300], Step [380/384], Loss: 2.0864, LR: 0.000896
[11:41:55] Epoch 68 Complete. Avg Loss: 2.3545, LR: 0.000896
  -> New best model saved (loss: 2.3545)
[11:41:55] Epoch [69/300], Step [0/384], Loss: 1.8812, LR: 0.000893
[11:41:57] Epoch [69/300], Step [20/384], Loss: 2.2783, LR: 0.000893
[11:42:00] Epoch [69/300], Step [40/384], Loss: 2.4637, LR: 0.000893
[11:42:02] Epoch [69/300], Step [60/384], Loss: 2.3898, LR: 0.000893
[11:42:04] Epoch [69/300], Step [80/384], Loss: 1.7997, LR: 0.000893
[11:42:06] Epoch [69/300], Step [100/384], Loss: 1.8011, LR: 0.000893
[11:42:08] Epoch [69/300], Step [120/384], Loss: 2.3207, LR: 0.000893
[11:42:11] Epoch [69/300], Step [140/384], Loss: 2.0897, LR: 0.000893
[11:42:13] Epoch [69/300], Step [160/384], Loss: 2.2971, LR: 0.000893
[11:42:15] Epoch [69/300], Step [180/384], Loss: 2.1021, LR: 0.000893
[11:42:17] Epoch [69/300], Step [200/384], Loss: 2.2289, LR: 0.000893
[11:42:19] Epoch [69/300], Step [220/384], Loss: 2.4354, LR: 0.000893
[11:42:21] Epoch [69/300], Step [240/384], Loss: 2.5927, LR: 0.000893
[11:42:24] Epoch [69/300], Step [260/384], Loss: 2.2244, LR: 0.000893
[11:42:26] Epoch [69/300], Step [280/384], Loss: 1.9720, LR: 0.000893
[11:42:28] Epoch [69/300], Step [300/384], Loss: 2.5041, LR: 0.000893
[11:42:30] Epoch [69/300], Step [320/384], Loss: 1.8986, LR: 0.000893
[11:42:32] Epoch [69/300], Step [340/384], Loss: 2.5530, LR: 0.000893
[11:42:34] Epoch [69/300], Step [360/384], Loss: 2.7463, LR: 0.000893
[11:42:36] Epoch [69/300], Step [380/384], Loss: 2.0895, LR: 0.000893
[11:42:36] Epoch 69 Complete. Avg Loss: 2.3706, LR: 0.000893
[11:42:37] Epoch [70/300], Step [0/384], Loss: 1.8092, LR: 0.000889
[11:42:39] Epoch [70/300], Step [20/384], Loss: 2.4842, LR: 0.000889
[11:42:41] Epoch [70/300], Step [40/384], Loss: 2.2735, LR: 0.000889
[11:42:43] Epoch [70/300], Step [60/384], Loss: 2.8168, LR: 0.000889
[11:42:45] Epoch [70/300], Step [80/384], Loss: 2.2966, LR: 0.000889
[11:42:47] Epoch [70/300], Step [100/384], Loss: 2.0433, LR: 0.000889
[11:42:50] Epoch [70/300], Step [120/384], Loss: 2.4770, LR: 0.000889
[11:42:52] Epoch [70/300], Step [140/384], Loss: 2.1484, LR: 0.000889
[11:42:54] Epoch [70/300], Step [160/384], Loss: 2.1155, LR: 0.000889
[11:42:56] Epoch [70/300], Step [180/384], Loss: 2.2402, LR: 0.000889
[11:42:58] Epoch [70/300], Step [200/384], Loss: 1.8470, LR: 0.000889
[11:43:01] Epoch [70/300], Step [220/384], Loss: 2.3268, LR: 0.000889
[11:43:03] Epoch [70/300], Step [240/384], Loss: 2.0630, LR: 0.000889
[11:43:05] Epoch [70/300], Step [260/384], Loss: 2.1318, LR: 0.000889
[11:43:07] Epoch [70/300], Step [280/384], Loss: 2.3402, LR: 0.000889
[11:43:09] Epoch [70/300], Step [300/384], Loss: 2.1977, LR: 0.000889
[11:43:11] Epoch [70/300], Step [320/384], Loss: 2.9747, LR: 0.000889
[11:43:13] Epoch [70/300], Step [340/384], Loss: 2.2686, LR: 0.000889
[11:43:15] Epoch [70/300], Step [360/384], Loss: 2.0344, LR: 0.000889
[11:43:18] Epoch [70/300], Step [380/384], Loss: 2.2540, LR: 0.000889
[11:43:18] Epoch 70 Complete. Avg Loss: 2.3508, LR: 0.000889
  -> New best model saved (loss: 2.3508)
[11:43:18] Epoch [71/300], Step [0/384], Loss: 2.4560, LR: 0.000886
[11:43:20] Epoch [71/300], Step [20/384], Loss: 2.4253, LR: 0.000886
[11:43:22] Epoch [71/300], Step [40/384], Loss: 3.2480, LR: 0.000886
[11:43:24] Epoch [71/300], Step [60/384], Loss: 2.7606, LR: 0.000886
[11:43:27] Epoch [71/300], Step [80/384], Loss: 2.0078, LR: 0.000886
[11:43:29] Epoch [71/300], Step [100/384], Loss: 2.2827, LR: 0.000886
[11:43:31] Epoch [71/300], Step [120/384], Loss: 2.3085, LR: 0.000886
[11:43:33] Epoch [71/300], Step [140/384], Loss: 2.1710, LR: 0.000886
[11:43:36] Epoch [71/300], Step [160/384], Loss: 2.0620, LR: 0.000886
[11:43:38] Epoch [71/300], Step [180/384], Loss: 2.3741, LR: 0.000886
[11:43:40] Epoch [71/300], Step [200/384], Loss: 2.5620, LR: 0.000886
[11:43:42] Epoch [71/300], Step [220/384], Loss: 2.1709, LR: 0.000886
[11:43:44] Epoch [71/300], Step [240/384], Loss: 2.5126, LR: 0.000886
[11:43:47] Epoch [71/300], Step [260/384], Loss: 2.1735, LR: 0.000886
[11:43:49] Epoch [71/300], Step [280/384], Loss: 2.1620, LR: 0.000886
[11:43:51] Epoch [71/300], Step [300/384], Loss: 2.7149, LR: 0.000886
[11:43:53] Epoch [71/300], Step [320/384], Loss: 1.9512, LR: 0.000886
[11:43:55] Epoch [71/300], Step [340/384], Loss: 1.9837, LR: 0.000886
[11:43:57] Epoch [71/300], Step [360/384], Loss: 2.0608, LR: 0.000886
[11:43:59] Epoch [71/300], Step [380/384], Loss: 2.1397, LR: 0.000886
[11:43:59] Epoch 71 Complete. Avg Loss: 2.3481, LR: 0.000886
  -> New best model saved (loss: 2.3481)
[11:44:00] Epoch [72/300], Step [0/384], Loss: 2.1290, LR: 0.000883
[11:44:02] Epoch [72/300], Step [20/384], Loss: 2.2184, LR: 0.000883
[11:44:04] Epoch [72/300], Step [40/384], Loss: 1.9586, LR: 0.000883
[11:44:06] Epoch [72/300], Step [60/384], Loss: 2.9934, LR: 0.000883
[11:44:08] Epoch [72/300], Step [80/384], Loss: 2.6296, LR: 0.000883
[11:44:10] Epoch [72/300], Step [100/384], Loss: 2.7222, LR: 0.000883
[11:44:12] Epoch [72/300], Step [120/384], Loss: 2.8627, LR: 0.000883
[11:44:15] Epoch [72/300], Step [140/384], Loss: 2.1087, LR: 0.000883
[11:44:17] Epoch [72/300], Step [160/384], Loss: 3.1628, LR: 0.000883
[11:44:19] Epoch [72/300], Step [180/384], Loss: 2.5123, LR: 0.000883
[11:44:21] Epoch [72/300], Step [200/384], Loss: 2.3468, LR: 0.000883
[11:44:23] Epoch [72/300], Step [220/384], Loss: 2.6296, LR: 0.000883
[11:44:25] Epoch [72/300], Step [240/384], Loss: 2.9860, LR: 0.000883
[11:44:27] Epoch [72/300], Step [260/384], Loss: 2.1416, LR: 0.000883
[11:44:30] Epoch [72/300], Step [280/384], Loss: 2.0559, LR: 0.000883
[11:44:32] Epoch [72/300], Step [300/384], Loss: 2.7671, LR: 0.000883
[11:44:34] Epoch [72/300], Step [320/384], Loss: 2.7152, LR: 0.000883
[11:44:36] Epoch [72/300], Step [340/384], Loss: 2.6334, LR: 0.000883
[11:44:38] Epoch [72/300], Step [360/384], Loss: 1.6455, LR: 0.000883
[11:44:41] Epoch [72/300], Step [380/384], Loss: 1.7740, LR: 0.000883
[11:44:41] Epoch 72 Complete. Avg Loss: 2.3269, LR: 0.000883
  -> New best model saved (loss: 2.3269)
[11:44:41] Epoch [73/300], Step [0/384], Loss: 2.5576, LR: 0.000879
[11:44:43] Epoch [73/300], Step [20/384], Loss: 1.9650, LR: 0.000879
[11:44:46] Epoch [73/300], Step [40/384], Loss: 2.6054, LR: 0.000879
[11:44:48] Epoch [73/300], Step [60/384], Loss: 2.2821, LR: 0.000879
[11:44:50] Epoch [73/300], Step [80/384], Loss: 2.5773, LR: 0.000879
[11:44:52] Epoch [73/300], Step [100/384], Loss: 2.3295, LR: 0.000879
[11:44:54] Epoch [73/300], Step [120/384], Loss: 2.1373, LR: 0.000879
[11:44:57] Epoch [73/300], Step [140/384], Loss: 1.9442, LR: 0.000879
[11:44:59] Epoch [73/300], Step [160/384], Loss: 2.5665, LR: 0.000879
[11:45:01] Epoch [73/300], Step [180/384], Loss: 2.1759, LR: 0.000879
[11:45:03] Epoch [73/300], Step [200/384], Loss: 2.2346, LR: 0.000879
[11:45:05] Epoch [73/300], Step [220/384], Loss: 1.9270, LR: 0.000879
[11:45:07] Epoch [73/300], Step [240/384], Loss: 2.3524, LR: 0.000879
[11:45:09] Epoch [73/300], Step [260/384], Loss: 2.3229, LR: 0.000879
[11:45:12] Epoch [73/300], Step [280/384], Loss: 1.6598, LR: 0.000879
[11:45:14] Epoch [73/300], Step [300/384], Loss: 2.2304, LR: 0.000879
[11:45:16] Epoch [73/300], Step [320/384], Loss: 2.2352, LR: 0.000879
[11:45:18] Epoch [73/300], Step [340/384], Loss: 2.9042, LR: 0.000879
[11:45:20] Epoch [73/300], Step [360/384], Loss: 2.1345, LR: 0.000879
[11:45:22] Epoch [73/300], Step [380/384], Loss: 2.1711, LR: 0.000879
[11:45:22] Epoch 73 Complete. Avg Loss: 2.3331, LR: 0.000879
[11:45:23] Epoch [74/300], Step [0/384], Loss: 2.5654, LR: 0.000876
[11:45:25] Epoch [74/300], Step [20/384], Loss: 2.2928, LR: 0.000876
[11:45:27] Epoch [74/300], Step [40/384], Loss: 2.0610, LR: 0.000876
[11:45:29] Epoch [74/300], Step [60/384], Loss: 2.5993, LR: 0.000876
[11:45:31] Epoch [74/300], Step [80/384], Loss: 2.3817, LR: 0.000876
[11:45:34] Epoch [74/300], Step [100/384], Loss: 2.1336, LR: 0.000876
[11:45:36] Epoch [74/300], Step [120/384], Loss: 2.6412, LR: 0.000876
[11:45:38] Epoch [74/300], Step [140/384], Loss: 1.9419, LR: 0.000876
[11:45:40] Epoch [74/300], Step [160/384], Loss: 2.1531, LR: 0.000876
[11:45:42] Epoch [74/300], Step [180/384], Loss: 2.6869, LR: 0.000876
[11:45:45] Epoch [74/300], Step [200/384], Loss: 2.6247, LR: 0.000876
[11:45:47] Epoch [74/300], Step [220/384], Loss: 2.2724, LR: 0.000876
[11:45:49] Epoch [74/300], Step [240/384], Loss: 2.0171, LR: 0.000876
[11:45:51] Epoch [74/300], Step [260/384], Loss: 2.6420, LR: 0.000876
[11:45:53] Epoch [74/300], Step [280/384], Loss: 2.5876, LR: 0.000876
[11:45:55] Epoch [74/300], Step [300/384], Loss: 3.1406, LR: 0.000876
[11:45:57] Epoch [74/300], Step [320/384], Loss: 2.0472, LR: 0.000876
[11:45:59] Epoch [74/300], Step [340/384], Loss: 2.1535, LR: 0.000876
[11:46:01] Epoch [74/300], Step [360/384], Loss: 2.6160, LR: 0.000876
[11:46:04] Epoch [74/300], Step [380/384], Loss: 1.8170, LR: 0.000876
[11:46:04] Epoch 74 Complete. Avg Loss: 2.3224, LR: 0.000876
  -> New best model saved (loss: 2.3224)
[11:46:04] Epoch [75/300], Step [0/384], Loss: 1.9076, LR: 0.000872
[11:46:06] Epoch [75/300], Step [20/384], Loss: 2.6804, LR: 0.000872
[11:46:08] Epoch [75/300], Step [40/384], Loss: 2.6835, LR: 0.000872
[11:46:11] Epoch [75/300], Step [60/384], Loss: 2.0216, LR: 0.000872
[11:46:13] Epoch [75/300], Step [80/384], Loss: 2.2700, LR: 0.000872
[11:46:15] Epoch [75/300], Step [100/384], Loss: 2.1307, LR: 0.000872
[11:46:17] Epoch [75/300], Step [120/384], Loss: 2.3276, LR: 0.000872
[11:46:19] Epoch [75/300], Step [140/384], Loss: 2.6793, LR: 0.000872
[11:46:22] Epoch [75/300], Step [160/384], Loss: 2.2074, LR: 0.000872
[11:46:24] Epoch [75/300], Step [180/384], Loss: 2.1000, LR: 0.000872
[11:46:26] Epoch [75/300], Step [200/384], Loss: 1.8200, LR: 0.000872
[11:46:28] Epoch [75/300], Step [220/384], Loss: 1.8663, LR: 0.000872
[11:46:30] Epoch [75/300], Step [240/384], Loss: 1.8205, LR: 0.000872
[11:46:32] Epoch [75/300], Step [260/384], Loss: 1.8370, LR: 0.000872
[11:46:35] Epoch [75/300], Step [280/384], Loss: 2.3842, LR: 0.000872
[11:46:37] Epoch [75/300], Step [300/384], Loss: 2.2310, LR: 0.000872
[11:46:39] Epoch [75/300], Step [320/384], Loss: 2.6578, LR: 0.000872
[11:46:41] Epoch [75/300], Step [340/384], Loss: 2.4900, LR: 0.000872
[11:46:43] Epoch [75/300], Step [360/384], Loss: 2.4042, LR: 0.000872
[11:46:45] Epoch [75/300], Step [380/384], Loss: 2.6886, LR: 0.000872
[11:46:46] Epoch 75 Complete. Avg Loss: 2.3169, LR: 0.000872
  -> New best model saved (loss: 2.3169)
[11:46:46] Epoch [76/300], Step [0/384], Loss: 2.1756, LR: 0.000869
[11:46:48] Epoch [76/300], Step [20/384], Loss: 2.2464, LR: 0.000869
[11:46:50] Epoch [76/300], Step [40/384], Loss: 2.1761, LR: 0.000869
[11:46:52] Epoch [76/300], Step [60/384], Loss: 3.0558, LR: 0.000869
[11:46:54] Epoch [76/300], Step [80/384], Loss: 2.2175, LR: 0.000869
[11:46:57] Epoch [76/300], Step [100/384], Loss: 3.1032, LR: 0.000869
[11:46:59] Epoch [76/300], Step [120/384], Loss: 2.2853, LR: 0.000869
[11:47:01] Epoch [76/300], Step [140/384], Loss: 2.1586, LR: 0.000869
[11:47:03] Epoch [76/300], Step [160/384], Loss: 2.0492, LR: 0.000869
[11:47:05] Epoch [76/300], Step [180/384], Loss: 1.8284, LR: 0.000869
[11:47:07] Epoch [76/300], Step [200/384], Loss: 2.1171, LR: 0.000869
[11:47:09] Epoch [76/300], Step [220/384], Loss: 3.0813, LR: 0.000869
[11:47:11] Epoch [76/300], Step [240/384], Loss: 2.8673, LR: 0.000869
[11:47:14] Epoch [76/300], Step [260/384], Loss: 2.5423, LR: 0.000869
[11:47:16] Epoch [76/300], Step [280/384], Loss: 2.4921, LR: 0.000869
[11:47:18] Epoch [76/300], Step [300/384], Loss: 1.7168, LR: 0.000869
[11:47:20] Epoch [76/300], Step [320/384], Loss: 1.7214, LR: 0.000869
[11:47:22] Epoch [76/300], Step [340/384], Loss: 1.8739, LR: 0.000869
[11:47:24] Epoch [76/300], Step [360/384], Loss: 2.7131, LR: 0.000869
[11:47:27] Epoch [76/300], Step [380/384], Loss: 2.3070, LR: 0.000869
[11:47:27] Epoch 76 Complete. Avg Loss: 2.3084, LR: 0.000869
  -> New best model saved (loss: 2.3084)
[11:47:27] Epoch [77/300], Step [0/384], Loss: 2.5681, LR: 0.000865
[11:47:29] Epoch [77/300], Step [20/384], Loss: 1.8412, LR: 0.000865
[11:47:32] Epoch [77/300], Step [40/384], Loss: 2.3410, LR: 0.000865
[11:47:34] Epoch [77/300], Step [60/384], Loss: 2.2406, LR: 0.000865
[11:47:36] Epoch [77/300], Step [80/384], Loss: 2.3751, LR: 0.000865
[11:47:38] Epoch [77/300], Step [100/384], Loss: 1.9387, LR: 0.000865
[11:47:40] Epoch [77/300], Step [120/384], Loss: 2.3574, LR: 0.000865
[11:47:42] Epoch [77/300], Step [140/384], Loss: 1.7873, LR: 0.000865
[11:47:45] Epoch [77/300], Step [160/384], Loss: 2.0403, LR: 0.000865
[11:47:47] Epoch [77/300], Step [180/384], Loss: 1.8143, LR: 0.000865
[11:47:49] Epoch [77/300], Step [200/384], Loss: 2.2583, LR: 0.000865
[11:47:51] Epoch [77/300], Step [220/384], Loss: 1.9629, LR: 0.000865
[11:47:53] Epoch [77/300], Step [240/384], Loss: 3.0377, LR: 0.000865
[11:47:55] Epoch [77/300], Step [260/384], Loss: 2.3653, LR: 0.000865
[11:47:58] Epoch [77/300], Step [280/384], Loss: 1.9356, LR: 0.000865
[11:48:00] Epoch [77/300], Step [300/384], Loss: 2.5958, LR: 0.000865
[11:48:02] Epoch [77/300], Step [320/384], Loss: 2.9478, LR: 0.000865
[11:48:04] Epoch [77/300], Step [340/384], Loss: 2.5680, LR: 0.000865
[11:48:07] Epoch [77/300], Step [360/384], Loss: 2.3718, LR: 0.000865
[11:48:08] Epoch [77/300], Step [380/384], Loss: 2.2480, LR: 0.000865
[11:48:09] Epoch 77 Complete. Avg Loss: 2.2907, LR: 0.000865
  -> New best model saved (loss: 2.2907)
[11:48:09] Epoch [78/300], Step [0/384], Loss: 1.9630, LR: 0.000861
[11:48:11] Epoch [78/300], Step [20/384], Loss: 1.8378, LR: 0.000861
[11:48:13] Epoch [78/300], Step [40/384], Loss: 3.0166, LR: 0.000861
[11:48:15] Epoch [78/300], Step [60/384], Loss: 2.2070, LR: 0.000861
[11:48:18] Epoch [78/300], Step [80/384], Loss: 1.7921, LR: 0.000861
[11:48:20] Epoch [78/300], Step [100/384], Loss: 2.1098, LR: 0.000861
[11:48:22] Epoch [78/300], Step [120/384], Loss: 3.0386, LR: 0.000861
[11:48:24] Epoch [78/300], Step [140/384], Loss: 2.6487, LR: 0.000861
[11:48:26] Epoch [78/300], Step [160/384], Loss: 2.4418, LR: 0.000861
[11:48:28] Epoch [78/300], Step [180/384], Loss: 2.1764, LR: 0.000861
[11:48:30] Epoch [78/300], Step [200/384], Loss: 2.0710, LR: 0.000861
[11:48:33] Epoch [78/300], Step [220/384], Loss: 2.3262, LR: 0.000861
[11:48:35] Epoch [78/300], Step [240/384], Loss: 2.1873, LR: 0.000861
[11:48:37] Epoch [78/300], Step [260/384], Loss: 2.2172, LR: 0.000861
[11:48:39] Epoch [78/300], Step [280/384], Loss: 2.4745, LR: 0.000861
[11:48:41] Epoch [78/300], Step [300/384], Loss: 2.7029, LR: 0.000861
[11:48:44] Epoch [78/300], Step [320/384], Loss: 3.1834, LR: 0.000861
[11:48:46] Epoch [78/300], Step [340/384], Loss: 2.6054, LR: 0.000861
[11:48:48] Epoch [78/300], Step [360/384], Loss: 2.6087, LR: 0.000861
[11:48:50] Epoch [78/300], Step [380/384], Loss: 2.3775, LR: 0.000861
[11:48:50] Epoch 78 Complete. Avg Loss: 2.3014, LR: 0.000861
[11:48:51] Epoch [79/300], Step [0/384], Loss: 1.7198, LR: 0.000858
[11:48:53] Epoch [79/300], Step [20/384], Loss: 2.3246, LR: 0.000858
[11:48:55] Epoch [79/300], Step [40/384], Loss: 1.7376, LR: 0.000858
[11:48:57] Epoch [79/300], Step [60/384], Loss: 2.6250, LR: 0.000858
[11:48:59] Epoch [79/300], Step [80/384], Loss: 2.3902, LR: 0.000858
[11:49:01] Epoch [79/300], Step [100/384], Loss: 2.3814, LR: 0.000858
[11:49:04] Epoch [79/300], Step [120/384], Loss: 1.8896, LR: 0.000858
[11:49:06] Epoch [79/300], Step [140/384], Loss: 2.3716, LR: 0.000858
[11:49:08] Epoch [79/300], Step [160/384], Loss: 2.3967, LR: 0.000858
[11:49:10] Epoch [79/300], Step [180/384], Loss: 2.1667, LR: 0.000858
[11:49:13] Epoch [79/300], Step [200/384], Loss: 1.8784, LR: 0.000858
[11:49:15] Epoch [79/300], Step [220/384], Loss: 1.8507, LR: 0.000858
[11:49:17] Epoch [79/300], Step [240/384], Loss: 2.0112, LR: 0.000858
[11:49:19] Epoch [79/300], Step [260/384], Loss: 1.8946, LR: 0.000858
[11:49:21] Epoch [79/300], Step [280/384], Loss: 2.0004, LR: 0.000858
[11:49:23] Epoch [79/300], Step [300/384], Loss: 2.0584, LR: 0.000858
[11:49:25] Epoch [79/300], Step [320/384], Loss: 2.0042, LR: 0.000858
[11:49:27] Epoch [79/300], Step [340/384], Loss: 2.1782, LR: 0.000858
[11:49:30] Epoch [79/300], Step [360/384], Loss: 2.5186, LR: 0.000858
[11:49:32] Epoch [79/300], Step [380/384], Loss: 1.8877, LR: 0.000858
[11:49:32] Epoch 79 Complete. Avg Loss: 2.2955, LR: 0.000858
[11:49:32] Epoch [80/300], Step [0/384], Loss: 1.8428, LR: 0.000854
[11:49:34] Epoch [80/300], Step [20/384], Loss: 2.1183, LR: 0.000854
[11:49:36] Epoch [80/300], Step [40/384], Loss: 2.2430, LR: 0.000854
[11:49:38] Epoch [80/300], Step [60/384], Loss: 2.1981, LR: 0.000854
[11:49:41] Epoch [80/300], Step [80/384], Loss: 2.4095, LR: 0.000854
[11:49:43] Epoch [80/300], Step [100/384], Loss: 2.5974, LR: 0.000854
[11:49:45] Epoch [80/300], Step [120/384], Loss: 2.2754, LR: 0.000854
[11:49:47] Epoch [80/300], Step [140/384], Loss: 1.9538, LR: 0.000854
[11:49:49] Epoch [80/300], Step [160/384], Loss: 2.0879, LR: 0.000854
[11:49:51] Epoch [80/300], Step [180/384], Loss: 2.9416, LR: 0.000854
[11:49:54] Epoch [80/300], Step [200/384], Loss: 2.1649, LR: 0.000854
[11:49:56] Epoch [80/300], Step [220/384], Loss: 2.7668, LR: 0.000854
[11:49:58] Epoch [80/300], Step [240/384], Loss: 2.7002, LR: 0.000854
[11:50:00] Epoch [80/300], Step [260/384], Loss: 2.4599, LR: 0.000854
[11:50:02] Epoch [80/300], Step [280/384], Loss: 2.4419, LR: 0.000854
[11:50:05] Epoch [80/300], Step [300/384], Loss: 2.3089, LR: 0.000854
[11:50:07] Epoch [80/300], Step [320/384], Loss: 2.2458, LR: 0.000854
[11:50:09] Epoch [80/300], Step [340/384], Loss: 2.7463, LR: 0.000854
[11:50:11] Epoch [80/300], Step [360/384], Loss: 1.9794, LR: 0.000854
[11:50:13] Epoch [80/300], Step [380/384], Loss: 1.8103, LR: 0.000854
[11:50:14] Epoch 80 Complete. Avg Loss: 2.2989, LR: 0.000854
[11:50:14] Epoch [81/300], Step [0/384], Loss: 2.4079, LR: 0.000850
[11:50:16] Epoch [81/300], Step [20/384], Loss: 2.3629, LR: 0.000850
[11:50:18] Epoch [81/300], Step [40/384], Loss: 2.2380, LR: 0.000850
[11:50:20] Epoch [81/300], Step [60/384], Loss: 1.9273, LR: 0.000850
[11:50:22] Epoch [81/300], Step [80/384], Loss: 2.6300, LR: 0.000850
[11:50:24] Epoch [81/300], Step [100/384], Loss: 1.8967, LR: 0.000850
[11:50:27] Epoch [81/300], Step [120/384], Loss: 2.3990, LR: 0.000850
[11:50:29] Epoch [81/300], Step [140/384], Loss: 2.4282, LR: 0.000850
[11:50:31] Epoch [81/300], Step [160/384], Loss: 2.2513, LR: 0.000850
[11:50:33] Epoch [81/300], Step [180/384], Loss: 2.0658, LR: 0.000850
[11:50:35] Epoch [81/300], Step [200/384], Loss: 2.4691, LR: 0.000850
[11:50:37] Epoch [81/300], Step [220/384], Loss: 2.5195, LR: 0.000850
[11:50:39] Epoch [81/300], Step [240/384], Loss: 1.9316, LR: 0.000850
[11:50:41] Epoch [81/300], Step [260/384], Loss: 1.7014, LR: 0.000850
[11:50:44] Epoch [81/300], Step [280/384], Loss: 1.7124, LR: 0.000850
[11:50:46] Epoch [81/300], Step [300/384], Loss: 2.0719, LR: 0.000850
[11:50:48] Epoch [81/300], Step [320/384], Loss: 2.3879, LR: 0.000850
[11:50:51] Epoch [81/300], Step [340/384], Loss: 2.1516, LR: 0.000850
[11:50:53] Epoch [81/300], Step [360/384], Loss: 1.9113, LR: 0.000850
[11:50:55] Epoch [81/300], Step [380/384], Loss: 2.4759, LR: 0.000850
[11:50:55] Epoch 81 Complete. Avg Loss: 2.2884, LR: 0.000850
  -> New best model saved (loss: 2.2884)
[11:50:55] Epoch [82/300], Step [0/384], Loss: 2.4177, LR: 0.000847
[11:50:57] Epoch [82/300], Step [20/384], Loss: 2.2609, LR: 0.000847
[11:51:00] Epoch [82/300], Step [40/384], Loss: 1.7526, LR: 0.000847
[11:51:02] Epoch [82/300], Step [60/384], Loss: 2.5125, LR: 0.000847
[11:51:04] Epoch [82/300], Step [80/384], Loss: 2.9756, LR: 0.000847
[11:51:06] Epoch [82/300], Step [100/384], Loss: 1.5643, LR: 0.000847
[11:51:08] Epoch [82/300], Step [120/384], Loss: 1.7606, LR: 0.000847
[11:51:11] Epoch [82/300], Step [140/384], Loss: 2.4623, LR: 0.000847
[11:51:13] Epoch [82/300], Step [160/384], Loss: 2.2086, LR: 0.000847
[11:51:15] Epoch [82/300], Step [180/384], Loss: 1.5526, LR: 0.000847
[11:51:17] Epoch [82/300], Step [200/384], Loss: 2.2512, LR: 0.000847
[11:51:19] Epoch [82/300], Step [220/384], Loss: 1.8226, LR: 0.000847
[11:51:21] Epoch [82/300], Step [240/384], Loss: 2.1504, LR: 0.000847
[11:51:23] Epoch [82/300], Step [260/384], Loss: 2.0564, LR: 0.000847
[11:51:26] Epoch [82/300], Step [280/384], Loss: 2.9015, LR: 0.000847
[11:51:28] Epoch [82/300], Step [300/384], Loss: 1.6595, LR: 0.000847
[11:51:30] Epoch [82/300], Step [320/384], Loss: 2.0180, LR: 0.000847
[11:51:32] Epoch [82/300], Step [340/384], Loss: 2.5116, LR: 0.000847
[11:51:34] Epoch [82/300], Step [360/384], Loss: 2.2563, LR: 0.000847
[11:51:36] Epoch [82/300], Step [380/384], Loss: 2.1523, LR: 0.000847
[11:51:37] Epoch 82 Complete. Avg Loss: 2.2802, LR: 0.000847
  -> New best model saved (loss: 2.2802)
[11:51:37] Epoch [83/300], Step [0/384], Loss: 2.4029, LR: 0.000843
[11:51:39] Epoch [83/300], Step [20/384], Loss: 2.1527, LR: 0.000843
[11:51:41] Epoch [83/300], Step [40/384], Loss: 2.1680, LR: 0.000843
[11:51:43] Epoch [83/300], Step [60/384], Loss: 2.5424, LR: 0.000843
[11:51:45] Epoch [83/300], Step [80/384], Loss: 2.1996, LR: 0.000843
[11:51:48] Epoch [83/300], Step [100/384], Loss: 2.5330, LR: 0.000843
[11:51:50] Epoch [83/300], Step [120/384], Loss: 2.4540, LR: 0.000843
[11:51:52] Epoch [83/300], Step [140/384], Loss: 2.2023, LR: 0.000843
[11:51:54] Epoch [83/300], Step [160/384], Loss: 2.1202, LR: 0.000843
[11:51:56] Epoch [83/300], Step [180/384], Loss: 2.3197, LR: 0.000843
[11:51:58] Epoch [83/300], Step [200/384], Loss: 2.4013, LR: 0.000843
[11:52:01] Epoch [83/300], Step [220/384], Loss: 2.1285, LR: 0.000843
[11:52:03] Epoch [83/300], Step [240/384], Loss: 2.4452, LR: 0.000843
[11:52:05] Epoch [83/300], Step [260/384], Loss: 2.2360, LR: 0.000843
[11:52:07] Epoch [83/300], Step [280/384], Loss: 2.0660, LR: 0.000843
[11:52:09] Epoch [83/300], Step [300/384], Loss: 2.1078, LR: 0.000843
[11:52:11] Epoch [83/300], Step [320/384], Loss: 2.6937, LR: 0.000843
[11:52:13] Epoch [83/300], Step [340/384], Loss: 2.7650, LR: 0.000843
[11:52:16] Epoch [83/300], Step [360/384], Loss: 2.2938, LR: 0.000843
[11:52:18] Epoch [83/300], Step [380/384], Loss: 3.1005, LR: 0.000843
[11:52:18] Epoch 83 Complete. Avg Loss: 2.2831, LR: 0.000843
[11:52:18] Epoch [84/300], Step [0/384], Loss: 2.3520, LR: 0.000839
[11:52:21] Epoch [84/300], Step [20/384], Loss: 2.1494, LR: 0.000839
[11:52:23] Epoch [84/300], Step [40/384], Loss: 2.5968, LR: 0.000839
[11:52:25] Epoch [84/300], Step [60/384], Loss: 2.2680, LR: 0.000839
[11:52:27] Epoch [84/300], Step [80/384], Loss: 2.7358, LR: 0.000839
[11:52:29] Epoch [84/300], Step [100/384], Loss: 2.0479, LR: 0.000839
[11:52:32] Epoch [84/300], Step [120/384], Loss: 1.8580, LR: 0.000839
[11:52:34] Epoch [84/300], Step [140/384], Loss: 2.2205, LR: 0.000839
[11:52:36] Epoch [84/300], Step [160/384], Loss: 2.3627, LR: 0.000839
[11:52:38] Epoch [84/300], Step [180/384], Loss: 2.4921, LR: 0.000839
[11:52:40] Epoch [84/300], Step [200/384], Loss: 2.2245, LR: 0.000839
[11:52:42] Epoch [84/300], Step [220/384], Loss: 2.3531, LR: 0.000839
[11:52:44] Epoch [84/300], Step [240/384], Loss: 2.5414, LR: 0.000839
[11:52:46] Epoch [84/300], Step [260/384], Loss: 1.9255, LR: 0.000839
[11:52:49] Epoch [84/300], Step [280/384], Loss: 2.1743, LR: 0.000839
[11:52:51] Epoch [84/300], Step [300/384], Loss: 2.5279, LR: 0.000839
[11:52:53] Epoch [84/300], Step [320/384], Loss: 2.5599, LR: 0.000839
[11:52:55] Epoch [84/300], Step [340/384], Loss: 2.8013, LR: 0.000839
[11:52:57] Epoch [84/300], Step [360/384], Loss: 2.0844, LR: 0.000839
[11:52:59] Epoch [84/300], Step [380/384], Loss: 2.2696, LR: 0.000839
[11:53:00] Epoch 84 Complete. Avg Loss: 2.2440, LR: 0.000839
  -> New best model saved (loss: 2.2440)
[11:53:00] Epoch [85/300], Step [0/384], Loss: 2.6188, LR: 0.000835
[11:53:02] Epoch [85/300], Step [20/384], Loss: 2.5765, LR: 0.000835
[11:53:04] Epoch [85/300], Step [40/384], Loss: 2.3206, LR: 0.000835
[11:53:07] Epoch [85/300], Step [60/384], Loss: 2.4331, LR: 0.000835
[11:53:09] Epoch [85/300], Step [80/384], Loss: 2.6443, LR: 0.000835
[11:53:11] Epoch [85/300], Step [100/384], Loss: 2.1193, LR: 0.000835
[11:53:13] Epoch [85/300], Step [120/384], Loss: 2.4073, LR: 0.000835
[11:53:15] Epoch [85/300], Step [140/384], Loss: 2.4364, LR: 0.000835
[11:53:17] Epoch [85/300], Step [160/384], Loss: 2.1652, LR: 0.000835
[11:53:20] Epoch [85/300], Step [180/384], Loss: 2.1949, LR: 0.000835
[11:53:21] Epoch [85/300], Step [200/384], Loss: 2.1832, LR: 0.000835
[11:53:24] Epoch [85/300], Step [220/384], Loss: 2.3430, LR: 0.000835
[11:53:26] Epoch [85/300], Step [240/384], Loss: 1.8372, LR: 0.000835
[11:53:28] Epoch [85/300], Step [260/384], Loss: 2.4923, LR: 0.000835
[11:53:30] Epoch [85/300], Step [280/384], Loss: 2.2281, LR: 0.000835
[11:53:32] Epoch [85/300], Step [300/384], Loss: 2.0966, LR: 0.000835
[11:53:34] Epoch [85/300], Step [320/384], Loss: 2.1629, LR: 0.000835
[11:53:36] Epoch [85/300], Step [340/384], Loss: 2.3422, LR: 0.000835
[11:53:39] Epoch [85/300], Step [360/384], Loss: 2.2923, LR: 0.000835
[11:53:41] Epoch [85/300], Step [380/384], Loss: 2.8893, LR: 0.000835
[11:53:41] Epoch 85 Complete. Avg Loss: 2.2471, LR: 0.000835
[11:53:41] Epoch [86/300], Step [0/384], Loss: 2.1993, LR: 0.000831
[11:53:44] Epoch [86/300], Step [20/384], Loss: 2.5945, LR: 0.000831
[11:53:46] Epoch [86/300], Step [40/384], Loss: 2.1575, LR: 0.000831
[11:53:48] Epoch [86/300], Step [60/384], Loss: 1.9472, LR: 0.000831
[11:53:50] Epoch [86/300], Step [80/384], Loss: 2.2499, LR: 0.000831
[11:53:52] Epoch [86/300], Step [100/384], Loss: 2.2349, LR: 0.000831
[11:53:54] Epoch [86/300], Step [120/384], Loss: 2.2476, LR: 0.000831
[11:53:56] Epoch [86/300], Step [140/384], Loss: 3.2102, LR: 0.000831
[11:53:59] Epoch [86/300], Step [160/384], Loss: 2.0723, LR: 0.000831
[11:54:01] Epoch [86/300], Step [180/384], Loss: 2.6021, LR: 0.000831
[11:54:03] Epoch [86/300], Step [200/384], Loss: 2.2955, LR: 0.000831
[11:54:05] Epoch [86/300], Step [220/384], Loss: 1.6408, LR: 0.000831
[11:54:07] Epoch [86/300], Step [240/384], Loss: 2.2322, LR: 0.000831
[11:54:09] Epoch [86/300], Step [260/384], Loss: 2.5451, LR: 0.000831
[11:54:11] Epoch [86/300], Step [280/384], Loss: 1.9323, LR: 0.000831
[11:54:13] Epoch [86/300], Step [300/384], Loss: 2.1424, LR: 0.000831
[11:54:16] Epoch [86/300], Step [320/384], Loss: 2.1839, LR: 0.000831
[11:54:18] Epoch [86/300], Step [340/384], Loss: 2.5190, LR: 0.000831
[11:54:20] Epoch [86/300], Step [360/384], Loss: 2.1604, LR: 0.000831
[11:54:22] Epoch [86/300], Step [380/384], Loss: 2.0982, LR: 0.000831
[11:54:23] Epoch 86 Complete. Avg Loss: 2.2479, LR: 0.000831
[11:54:23] Epoch [87/300], Step [0/384], Loss: 2.1248, LR: 0.000827
[11:54:25] Epoch [87/300], Step [20/384], Loss: 2.0594, LR: 0.000827
[11:54:27] Epoch [87/300], Step [40/384], Loss: 2.5774, LR: 0.000827
[11:54:29] Epoch [87/300], Step [60/384], Loss: 2.5227, LR: 0.000827
[11:54:32] Epoch [87/300], Step [80/384], Loss: 1.6637, LR: 0.000827
[11:54:34] Epoch [87/300], Step [100/384], Loss: 2.3620, LR: 0.000827
[11:54:36] Epoch [87/300], Step [120/384], Loss: 1.6446, LR: 0.000827
[11:54:38] Epoch [87/300], Step [140/384], Loss: 1.8286, LR: 0.000827
[11:54:40] Epoch [87/300], Step [160/384], Loss: 2.0948, LR: 0.000827
[11:54:43] Epoch [87/300], Step [180/384], Loss: 2.3862, LR: 0.000827
[11:54:45] Epoch [87/300], Step [200/384], Loss: 2.6489, LR: 0.000827
[11:54:47] Epoch [87/300], Step [220/384], Loss: 2.4606, LR: 0.000827
[11:54:49] Epoch [87/300], Step [240/384], Loss: 2.1087, LR: 0.000827
[11:54:51] Epoch [87/300], Step [260/384], Loss: 1.9024, LR: 0.000827
[11:54:53] Epoch [87/300], Step [280/384], Loss: 2.0567, LR: 0.000827
[11:54:55] Epoch [87/300], Step [300/384], Loss: 2.1532, LR: 0.000827
[11:54:58] Epoch [87/300], Step [320/384], Loss: 2.7672, LR: 0.000827
[11:55:00] Epoch [87/300], Step [340/384], Loss: 2.2972, LR: 0.000827
[11:55:02] Epoch [87/300], Step [360/384], Loss: 2.0429, LR: 0.000827
[11:55:04] Epoch [87/300], Step [380/384], Loss: 1.9617, LR: 0.000827
[11:55:04] Epoch 87 Complete. Avg Loss: 2.2343, LR: 0.000827
  -> New best model saved (loss: 2.2343)
[11:55:05] Epoch [88/300], Step [0/384], Loss: 2.4018, LR: 0.000823
[11:55:07] Epoch [88/300], Step [20/384], Loss: 2.1823, LR: 0.000823
[11:55:09] Epoch [88/300], Step [40/384], Loss: 2.1657, LR: 0.000823
[11:55:11] Epoch [88/300], Step [60/384], Loss: 2.8882, LR: 0.000823
[11:55:13] Epoch [88/300], Step [80/384], Loss: 3.0484, LR: 0.000823
[11:55:15] Epoch [88/300], Step [100/384], Loss: 2.0799, LR: 0.000823
[11:55:18] Epoch [88/300], Step [120/384], Loss: 1.9926, LR: 0.000823
[11:55:20] Epoch [88/300], Step [140/384], Loss: 2.0976, LR: 0.000823
[11:55:22] Epoch [88/300], Step [160/384], Loss: 2.7877, LR: 0.000823
[11:55:24] Epoch [88/300], Step [180/384], Loss: 2.1278, LR: 0.000823
[11:55:26] Epoch [88/300], Step [200/384], Loss: 2.1070, LR: 0.000823
[11:55:28] Epoch [88/300], Step [220/384], Loss: 2.6468, LR: 0.000823
[11:55:30] Epoch [88/300], Step [240/384], Loss: 2.6523, LR: 0.000823
[11:55:32] Epoch [88/300], Step [260/384], Loss: 2.5166, LR: 0.000823
[11:55:34] Epoch [88/300], Step [280/384], Loss: 1.9713, LR: 0.000823
[11:55:37] Epoch [88/300], Step [300/384], Loss: 2.0918, LR: 0.000823
[11:55:39] Epoch [88/300], Step [320/384], Loss: 2.4613, LR: 0.000823
[11:55:41] Epoch [88/300], Step [340/384], Loss: 2.8780, LR: 0.000823
[11:55:43] Epoch [88/300], Step [360/384], Loss: 2.0490, LR: 0.000823
[11:55:45] Epoch [88/300], Step [380/384], Loss: 2.2509, LR: 0.000823
[11:55:46] Epoch 88 Complete. Avg Loss: 2.2362, LR: 0.000823
[11:55:46] Epoch [89/300], Step [0/384], Loss: 1.7345, LR: 0.000819
[11:55:48] Epoch [89/300], Step [20/384], Loss: 1.6909, LR: 0.000819
[11:55:51] Epoch [89/300], Step [40/384], Loss: 2.1826, LR: 0.000819
[11:55:53] Epoch [89/300], Step [60/384], Loss: 2.5172, LR: 0.000819
[11:55:55] Epoch [89/300], Step [80/384], Loss: 2.1891, LR: 0.000819
[11:55:57] Epoch [89/300], Step [100/384], Loss: 2.1661, LR: 0.000819
[11:55:59] Epoch [89/300], Step [120/384], Loss: 1.9921, LR: 0.000819
[11:56:01] Epoch [89/300], Step [140/384], Loss: 2.1497, LR: 0.000819
[11:56:04] Epoch [89/300], Step [160/384], Loss: 1.9836, LR: 0.000819
[11:56:06] Epoch [89/300], Step [180/384], Loss: 2.5242, LR: 0.000819
[11:56:08] Epoch [89/300], Step [200/384], Loss: 2.1754, LR: 0.000819
[11:56:10] Epoch [89/300], Step [220/384], Loss: 2.3200, LR: 0.000819
[11:56:12] Epoch [89/300], Step [240/384], Loss: 2.2188, LR: 0.000819
[11:56:14] Epoch [89/300], Step [260/384], Loss: 1.9618, LR: 0.000819
[11:56:16] Epoch [89/300], Step [280/384], Loss: 2.4424, LR: 0.000819
[11:56:19] Epoch [89/300], Step [300/384], Loss: 2.5510, LR: 0.000819
[11:56:21] Epoch [89/300], Step [320/384], Loss: 1.6078, LR: 0.000819
[11:56:23] Epoch [89/300], Step [340/384], Loss: 2.0039, LR: 0.000819
[11:56:25] Epoch [89/300], Step [360/384], Loss: 2.1024, LR: 0.000819
[11:56:27] Epoch [89/300], Step [380/384], Loss: 2.1193, LR: 0.000819
[11:56:27] Epoch 89 Complete. Avg Loss: 2.2103, LR: 0.000819
  -> New best model saved (loss: 2.2103)
[11:56:27] Epoch [90/300], Step [0/384], Loss: 1.8232, LR: 0.000815
[11:56:29] Epoch [90/300], Step [20/384], Loss: 2.2364, LR: 0.000815
[11:56:32] Epoch [90/300], Step [40/384], Loss: 2.1598, LR: 0.000815
[11:56:34] Epoch [90/300], Step [60/384], Loss: 2.8386, LR: 0.000815
[11:56:36] Epoch [90/300], Step [80/384], Loss: 1.8121, LR: 0.000815
[11:56:38] Epoch [90/300], Step [100/384], Loss: 2.4290, LR: 0.000815
[11:56:40] Epoch [90/300], Step [120/384], Loss: 2.2048, LR: 0.000815
[11:56:42] Epoch [90/300], Step [140/384], Loss: 1.8485, LR: 0.000815
[11:56:44] Epoch [90/300], Step [160/384], Loss: 2.2492, LR: 0.000815
[11:56:47] Epoch [90/300], Step [180/384], Loss: 2.9120, LR: 0.000815
[11:56:49] Epoch [90/300], Step [200/384], Loss: 2.1738, LR: 0.000815
[11:56:51] Epoch [90/300], Step [220/384], Loss: 2.2129, LR: 0.000815
[11:56:53] Epoch [90/300], Step [240/384], Loss: 2.3271, LR: 0.000815
[11:56:55] Epoch [90/300], Step [260/384], Loss: 1.9135, LR: 0.000815
[11:56:57] Epoch [90/300], Step [280/384], Loss: 1.9964, LR: 0.000815
[11:57:00] Epoch [90/300], Step [300/384], Loss: 2.1985, LR: 0.000815
[11:57:02] Epoch [90/300], Step [320/384], Loss: 2.6450, LR: 0.000815
[11:57:04] Epoch [90/300], Step [340/384], Loss: 2.3702, LR: 0.000815
[11:57:06] Epoch [90/300], Step [360/384], Loss: 2.8772, LR: 0.000815
[11:57:09] Epoch [90/300], Step [380/384], Loss: 2.5749, LR: 0.000815
[11:57:09] Epoch 90 Complete. Avg Loss: 2.2213, LR: 0.000815
[11:57:09] Epoch [91/300], Step [0/384], Loss: 2.2822, LR: 0.000811
[11:57:11] Epoch [91/300], Step [20/384], Loss: 2.0553, LR: 0.000811
[11:57:13] Epoch [91/300], Step [40/384], Loss: 2.1187, LR: 0.000811
[11:57:16] Epoch [91/300], Step [60/384], Loss: 2.2686, LR: 0.000811
[11:57:18] Epoch [91/300], Step [80/384], Loss: 2.4908, LR: 0.000811
[11:57:20] Epoch [91/300], Step [100/384], Loss: 1.9202, LR: 0.000811
[11:57:22] Epoch [91/300], Step [120/384], Loss: 2.1874, LR: 0.000811
[11:57:24] Epoch [91/300], Step [140/384], Loss: 1.9341, LR: 0.000811
[11:57:26] Epoch [91/300], Step [160/384], Loss: 2.2736, LR: 0.000811
[11:57:29] Epoch [91/300], Step [180/384], Loss: 2.3261, LR: 0.000811
[11:57:31] Epoch [91/300], Step [200/384], Loss: 2.3759, LR: 0.000811
[11:57:33] Epoch [91/300], Step [220/384], Loss: 1.8824, LR: 0.000811
[11:57:35] Epoch [91/300], Step [240/384], Loss: 1.9843, LR: 0.000811
[11:57:37] Epoch [91/300], Step [260/384], Loss: 1.8386, LR: 0.000811
[11:57:39] Epoch [91/300], Step [280/384], Loss: 1.7927, LR: 0.000811
[11:57:41] Epoch [91/300], Step [300/384], Loss: 1.9326, LR: 0.000811
[11:57:43] Epoch [91/300], Step [320/384], Loss: 2.0841, LR: 0.000811
[11:57:46] Epoch [91/300], Step [340/384], Loss: 2.4095, LR: 0.000811
[11:57:48] Epoch [91/300], Step [360/384], Loss: 2.4064, LR: 0.000811
[11:57:50] Epoch [91/300], Step [380/384], Loss: 2.2577, LR: 0.000811
[11:57:50] Epoch 91 Complete. Avg Loss: 2.2252, LR: 0.000811
[11:57:51] Epoch [92/300], Step [0/384], Loss: 2.0441, LR: 0.000807
[11:57:53] Epoch [92/300], Step [20/384], Loss: 1.7150, LR: 0.000807
[11:57:55] Epoch [92/300], Step [40/384], Loss: 2.1776, LR: 0.000807
[11:57:57] Epoch [92/300], Step [60/384], Loss: 1.8383, LR: 0.000807
[11:58:00] Epoch [92/300], Step [80/384], Loss: 1.9234, LR: 0.000807
[11:58:02] Epoch [92/300], Step [100/384], Loss: 2.0525, LR: 0.000807
[11:58:04] Epoch [92/300], Step [120/384], Loss: 2.4315, LR: 0.000807
[11:58:06] Epoch [92/300], Step [140/384], Loss: 1.9297, LR: 0.000807
[11:58:08] Epoch [92/300], Step [160/384], Loss: 2.0501, LR: 0.000807
[11:58:10] Epoch [92/300], Step [180/384], Loss: 2.3108, LR: 0.000807
[11:58:12] Epoch [92/300], Step [200/384], Loss: 3.0687, LR: 0.000807
[11:58:14] Epoch [92/300], Step [220/384], Loss: 2.2170, LR: 0.000807
[11:58:16] Epoch [92/300], Step [240/384], Loss: 1.9865, LR: 0.000807
[11:58:19] Epoch [92/300], Step [260/384], Loss: 2.0559, LR: 0.000807
[11:58:21] Epoch [92/300], Step [280/384], Loss: 2.6925, LR: 0.000807
[11:58:23] Epoch [92/300], Step [300/384], Loss: 2.1421, LR: 0.000807
[11:58:26] Epoch [92/300], Step [320/384], Loss: 2.0234, LR: 0.000807
[11:58:28] Epoch [92/300], Step [340/384], Loss: 1.6922, LR: 0.000807
[11:58:30] Epoch [92/300], Step [360/384], Loss: 1.9105, LR: 0.000807
[11:58:32] Epoch [92/300], Step [380/384], Loss: 2.5038, LR: 0.000807
[11:58:32] Epoch 92 Complete. Avg Loss: 2.1945, LR: 0.000807
  -> New best model saved (loss: 2.1945)
[11:58:32] Epoch [93/300], Step [0/384], Loss: 2.0749, LR: 0.000802
[11:58:34] Epoch [93/300], Step [20/384], Loss: 1.8227, LR: 0.000802
[11:58:36] Epoch [93/300], Step [40/384], Loss: 2.3576, LR: 0.000802
[11:58:38] Epoch [93/300], Step [60/384], Loss: 1.6782, LR: 0.000802
[11:58:41] Epoch [93/300], Step [80/384], Loss: 2.4925, LR: 0.000802
[11:58:43] Epoch [93/300], Step [100/384], Loss: 2.5246, LR: 0.000802
[11:58:45] Epoch [93/300], Step [120/384], Loss: 2.3210, LR: 0.000802
[11:58:47] Epoch [93/300], Step [140/384], Loss: 2.0328, LR: 0.000802
[11:58:50] Epoch [93/300], Step [160/384], Loss: 2.1192, LR: 0.000802
[11:58:52] Epoch [93/300], Step [180/384], Loss: 2.1952, LR: 0.000802
[11:58:54] Epoch [93/300], Step [200/384], Loss: 2.4031, LR: 0.000802
[11:58:56] Epoch [93/300], Step [220/384], Loss: 1.7819, LR: 0.000802
[11:58:58] Epoch [93/300], Step [240/384], Loss: 2.2723, LR: 0.000802
[11:59:00] Epoch [93/300], Step [260/384], Loss: 2.1565, LR: 0.000802
[11:59:03] Epoch [93/300], Step [280/384], Loss: 2.4389, LR: 0.000802
[11:59:05] Epoch [93/300], Step [300/384], Loss: 1.9738, LR: 0.000802
[11:59:07] Epoch [93/300], Step [320/384], Loss: 1.8913, LR: 0.000802
[11:59:09] Epoch [93/300], Step [340/384], Loss: 1.6406, LR: 0.000802
[11:59:11] Epoch [93/300], Step [360/384], Loss: 1.9625, LR: 0.000802
[11:59:13] Epoch [93/300], Step [380/384], Loss: 2.9141, LR: 0.000802
[11:59:13] Epoch 93 Complete. Avg Loss: 2.1956, LR: 0.000802
[11:59:14] Epoch [94/300], Step [0/384], Loss: 2.3642, LR: 0.000798
[11:59:16] Epoch [94/300], Step [20/384], Loss: 2.3125, LR: 0.000798
[11:59:18] Epoch [94/300], Step [40/384], Loss: 1.5127, LR: 0.000798
[11:59:20] Epoch [94/300], Step [60/384], Loss: 2.6996, LR: 0.000798
[11:59:22] Epoch [94/300], Step [80/384], Loss: 1.9285, LR: 0.000798
[11:59:25] Epoch [94/300], Step [100/384], Loss: 2.1619, LR: 0.000798
[11:59:27] Epoch [94/300], Step [120/384], Loss: 1.7044, LR: 0.000798
[11:59:29] Epoch [94/300], Step [140/384], Loss: 2.1321, LR: 0.000798
[11:59:31] Epoch [94/300], Step [160/384], Loss: 2.4629, LR: 0.000798
[11:59:34] Epoch [94/300], Step [180/384], Loss: 1.7149, LR: 0.000798
[11:59:36] Epoch [94/300], Step [200/384], Loss: 2.2472, LR: 0.000798
[11:59:38] Epoch [94/300], Step [220/384], Loss: 1.6447, LR: 0.000798
[11:59:40] Epoch [94/300], Step [240/384], Loss: 2.1979, LR: 0.000798
[11:59:42] Epoch [94/300], Step [260/384], Loss: 3.2005, LR: 0.000798
[11:59:44] Epoch [94/300], Step [280/384], Loss: 1.9865, LR: 0.000798
[11:59:46] Epoch [94/300], Step [300/384], Loss: 2.3811, LR: 0.000798
[11:59:48] Epoch [94/300], Step [320/384], Loss: 2.3620, LR: 0.000798
[11:59:50] Epoch [94/300], Step [340/384], Loss: 1.9391, LR: 0.000798
[11:59:53] Epoch [94/300], Step [360/384], Loss: 2.0863, LR: 0.000798
[11:59:55] Epoch [94/300], Step [380/384], Loss: 2.1219, LR: 0.000798
[11:59:55] Epoch 94 Complete. Avg Loss: 2.1789, LR: 0.000798
  -> New best model saved (loss: 2.1789)
[11:59:55] Epoch [95/300], Step [0/384], Loss: 2.4265, LR: 0.000794
[11:59:57] Epoch [95/300], Step [20/384], Loss: 1.7262, LR: 0.000794
[12:00:00] Epoch [95/300], Step [40/384], Loss: 2.4813, LR: 0.000794
[12:00:02] Epoch [95/300], Step [60/384], Loss: 2.1605, LR: 0.000794
[12:00:04] Epoch [95/300], Step [80/384], Loss: 2.2684, LR: 0.000794
[12:00:06] Epoch [95/300], Step [100/384], Loss: 2.0348, LR: 0.000794
[12:00:08] Epoch [95/300], Step [120/384], Loss: 2.3399, LR: 0.000794
[12:00:10] Epoch [95/300], Step [140/384], Loss: 2.3306, LR: 0.000794
[12:00:12] Epoch [95/300], Step [160/384], Loss: 2.8999, LR: 0.000794
[12:00:15] Epoch [95/300], Step [180/384], Loss: 1.8211, LR: 0.000794
[12:00:17] Epoch [95/300], Step [200/384], Loss: 1.8019, LR: 0.000794
[12:00:19] Epoch [95/300], Step [220/384], Loss: 2.0425, LR: 0.000794
[12:00:21] Epoch [95/300], Step [240/384], Loss: 2.3495, LR: 0.000794
[12:00:24] Epoch [95/300], Step [260/384], Loss: 2.7371, LR: 0.000794
[12:00:26] Epoch [95/300], Step [280/384], Loss: 2.2469, LR: 0.000794
[12:00:28] Epoch [95/300], Step [300/384], Loss: 2.7427, LR: 0.000794
[12:00:30] Epoch [95/300], Step [320/384], Loss: 1.8741, LR: 0.000794
[12:00:32] Epoch [95/300], Step [340/384], Loss: 2.0258, LR: 0.000794
[12:00:34] Epoch [95/300], Step [360/384], Loss: 2.4564, LR: 0.000794
[12:00:36] Epoch [95/300], Step [380/384], Loss: 1.8847, LR: 0.000794
[12:00:37] Epoch 95 Complete. Avg Loss: 2.1852, LR: 0.000794
[12:00:37] Epoch [96/300], Step [0/384], Loss: 1.6430, LR: 0.000790
[12:00:39] Epoch [96/300], Step [20/384], Loss: 2.2951, LR: 0.000790
[12:00:41] Epoch [96/300], Step [40/384], Loss: 2.0295, LR: 0.000790
[12:00:43] Epoch [96/300], Step [60/384], Loss: 2.7879, LR: 0.000790
[12:00:45] Epoch [96/300], Step [80/384], Loss: 2.4145, LR: 0.000790
[12:00:48] Epoch [96/300], Step [100/384], Loss: 2.1793, LR: 0.000790
[12:00:50] Epoch [96/300], Step [120/384], Loss: 2.2536, LR: 0.000790
[12:00:52] Epoch [96/300], Step [140/384], Loss: 1.8919, LR: 0.000790
[12:00:54] Epoch [96/300], Step [160/384], Loss: 1.9473, LR: 0.000790
[12:00:56] Epoch [96/300], Step [180/384], Loss: 2.6540, LR: 0.000790
[12:00:58] Epoch [96/300], Step [200/384], Loss: 2.6717, LR: 0.000790
[12:01:01] Epoch [96/300], Step [220/384], Loss: 1.8906, LR: 0.000790
[12:01:03] Epoch [96/300], Step [240/384], Loss: 1.5378, LR: 0.000790
[12:01:05] Epoch [96/300], Step [260/384], Loss: 2.4504, LR: 0.000790
[12:01:07] Epoch [96/300], Step [280/384], Loss: 1.9589, LR: 0.000790
[12:01:09] Epoch [96/300], Step [300/384], Loss: 2.3938, LR: 0.000790
[12:01:11] Epoch [96/300], Step [320/384], Loss: 2.3333, LR: 0.000790
[12:01:13] Epoch [96/300], Step [340/384], Loss: 1.7842, LR: 0.000790
[12:01:16] Epoch [96/300], Step [360/384], Loss: 2.1060, LR: 0.000790
[12:01:18] Epoch [96/300], Step [380/384], Loss: 2.5388, LR: 0.000790
[12:01:18] Epoch 96 Complete. Avg Loss: 2.1624, LR: 0.000790
  -> New best model saved (loss: 2.1624)
[12:01:18] Epoch [97/300], Step [0/384], Loss: 2.6903, LR: 0.000785
[12:01:21] Epoch [97/300], Step [20/384], Loss: 2.9181, LR: 0.000785
[12:01:23] Epoch [97/300], Step [40/384], Loss: 2.2584, LR: 0.000785
[12:01:25] Epoch [97/300], Step [60/384], Loss: 1.9847, LR: 0.000785
[12:01:27] Epoch [97/300], Step [80/384], Loss: 2.8362, LR: 0.000785
[12:01:29] Epoch [97/300], Step [100/384], Loss: 2.1010, LR: 0.000785
[12:01:31] Epoch [97/300], Step [120/384], Loss: 1.8341, LR: 0.000785
[12:01:33] Epoch [97/300], Step [140/384], Loss: 1.8252, LR: 0.000785
[12:01:36] Epoch [97/300], Step [160/384], Loss: 2.1907, LR: 0.000785
[12:01:38] Epoch [97/300], Step [180/384], Loss: 2.3824, LR: 0.000785
[12:01:40] Epoch [97/300], Step [200/384], Loss: 1.5908, LR: 0.000785
[12:01:42] Epoch [97/300], Step [220/384], Loss: 2.2758, LR: 0.000785
[12:01:45] Epoch [97/300], Step [240/384], Loss: 3.5513, LR: 0.000785
[12:01:47] Epoch [97/300], Step [260/384], Loss: 2.0670, LR: 0.000785
[12:01:49] Epoch [97/300], Step [280/384], Loss: 2.2645, LR: 0.000785
[12:01:51] Epoch [97/300], Step [300/384], Loss: 2.0160, LR: 0.000785
[12:01:53] Epoch [97/300], Step [320/384], Loss: 2.1618, LR: 0.000785
[12:01:55] Epoch [97/300], Step [340/384], Loss: 2.4856, LR: 0.000785
[12:01:58] Epoch [97/300], Step [360/384], Loss: 1.9845, LR: 0.000785
[12:02:00] Epoch [97/300], Step [380/384], Loss: 2.0289, LR: 0.000785
[12:02:00] Epoch 97 Complete. Avg Loss: 2.1750, LR: 0.000785
[12:02:00] Epoch [98/300], Step [0/384], Loss: 1.9969, LR: 0.000781
[12:02:02] Epoch [98/300], Step [20/384], Loss: 2.4822, LR: 0.000781
[12:02:04] Epoch [98/300], Step [40/384], Loss: 2.9035, LR: 0.000781
[12:02:07] Epoch [98/300], Step [60/384], Loss: 2.0421, LR: 0.000781
[12:02:09] Epoch [98/300], Step [80/384], Loss: 2.3270, LR: 0.000781
[12:02:11] Epoch [98/300], Step [100/384], Loss: 1.9977, LR: 0.000781
[12:02:13] Epoch [98/300], Step [120/384], Loss: 2.1718, LR: 0.000781
[12:02:15] Epoch [98/300], Step [140/384], Loss: 2.4970, LR: 0.000781
[12:02:18] Epoch [98/300], Step [160/384], Loss: 2.0559, LR: 0.000781
[12:02:20] Epoch [98/300], Step [180/384], Loss: 2.2534, LR: 0.000781
[12:02:22] Epoch [98/300], Step [200/384], Loss: 1.7088, LR: 0.000781
[12:02:24] Epoch [98/300], Step [220/384], Loss: 2.5361, LR: 0.000781
[12:02:26] Epoch [98/300], Step [240/384], Loss: 1.8797, LR: 0.000781
[12:02:28] Epoch [98/300], Step [260/384], Loss: 1.8432, LR: 0.000781
[12:02:30] Epoch [98/300], Step [280/384], Loss: 2.2295, LR: 0.000781
[12:02:33] Epoch [98/300], Step [300/384], Loss: 1.9087, LR: 0.000781
[12:02:35] Epoch [98/300], Step [320/384], Loss: 2.2122, LR: 0.000781
[12:02:37] Epoch [98/300], Step [340/384], Loss: 2.3267, LR: 0.000781
[12:02:39] Epoch [98/300], Step [360/384], Loss: 1.9150, LR: 0.000781
[12:02:41] Epoch [98/300], Step [380/384], Loss: 1.5735, LR: 0.000781
[12:02:42] Epoch 98 Complete. Avg Loss: 2.1716, LR: 0.000781
[12:02:42] Epoch [99/300], Step [0/384], Loss: 2.4147, LR: 0.000776
[12:02:44] Epoch [99/300], Step [20/384], Loss: 1.9873, LR: 0.000776
[12:02:46] Epoch [99/300], Step [40/384], Loss: 2.2238, LR: 0.000776
[12:02:49] Epoch [99/300], Step [60/384], Loss: 1.9503, LR: 0.000776
[12:02:50] Epoch [99/300], Step [80/384], Loss: 2.0004, LR: 0.000776
[12:02:52] Epoch [99/300], Step [100/384], Loss: 2.3108, LR: 0.000776
[12:02:55] Epoch [99/300], Step [120/384], Loss: 2.4003, LR: 0.000776
[12:02:57] Epoch [99/300], Step [140/384], Loss: 2.0411, LR: 0.000776
[12:02:59] Epoch [99/300], Step [160/384], Loss: 2.6999, LR: 0.000776
[12:03:01] Epoch [99/300], Step [180/384], Loss: 1.9035, LR: 0.000776
[12:03:04] Epoch [99/300], Step [200/384], Loss: 2.2437, LR: 0.000776
[12:03:06] Epoch [99/300], Step [220/384], Loss: 1.8887, LR: 0.000776
[12:03:08] Epoch [99/300], Step [240/384], Loss: 2.5941, LR: 0.000776
[12:03:10] Epoch [99/300], Step [260/384], Loss: 2.1237, LR: 0.000776
[12:03:12] Epoch [99/300], Step [280/384], Loss: 2.4069, LR: 0.000776
[12:03:14] Epoch [99/300], Step [300/384], Loss: 2.1424, LR: 0.000776
[12:03:16] Epoch [99/300], Step [320/384], Loss: 2.5684, LR: 0.000776
[12:03:19] Epoch [99/300], Step [340/384], Loss: 1.9679, LR: 0.000776
[12:03:21] Epoch [99/300], Step [360/384], Loss: 1.9537, LR: 0.000776
[12:03:23] Epoch [99/300], Step [380/384], Loss: 2.1662, LR: 0.000776
[12:03:23] Epoch 99 Complete. Avg Loss: 2.1719, LR: 0.000776
[12:03:24] Epoch [100/300], Step [0/384], Loss: 1.9445, LR: 0.000772
[12:03:26] Epoch [100/300], Step [20/384], Loss: 1.6318, LR: 0.000772
[12:03:28] Epoch [100/300], Step [40/384], Loss: 1.8035, LR: 0.000772
[12:03:30] Epoch [100/300], Step [60/384], Loss: 1.9705, LR: 0.000772
[12:03:32] Epoch [100/300], Step [80/384], Loss: 2.3177, LR: 0.000772
[12:03:35] Epoch [100/300], Step [100/384], Loss: 1.8043, LR: 0.000772
[12:03:37] Epoch [100/300], Step [120/384], Loss: 2.4194, LR: 0.000772
[12:03:39] Epoch [100/300], Step [140/384], Loss: 2.3431, LR: 0.000772
[12:03:41] Epoch [100/300], Step [160/384], Loss: 2.0306, LR: 0.000772
[12:03:43] Epoch [100/300], Step [180/384], Loss: 2.1097, LR: 0.000772
[12:03:45] Epoch [100/300], Step [200/384], Loss: 1.8793, LR: 0.000772
[12:03:48] Epoch [100/300], Step [220/384], Loss: 2.1025, LR: 0.000772
[12:03:50] Epoch [100/300], Step [240/384], Loss: 2.3696, LR: 0.000772
[12:03:52] Epoch [100/300], Step [260/384], Loss: 2.2979, LR: 0.000772
[12:03:54] Epoch [100/300], Step [280/384], Loss: 2.0508, LR: 0.000772
[12:03:56] Epoch [100/300], Step [300/384], Loss: 1.8478, LR: 0.000772
[12:03:58] Epoch [100/300], Step [320/384], Loss: 2.2697, LR: 0.000772
[12:04:01] Epoch [100/300], Step [340/384], Loss: 1.9543, LR: 0.000772
[12:04:03] Epoch [100/300], Step [360/384], Loss: 2.1109, LR: 0.000772
[12:04:05] Epoch [100/300], Step [380/384], Loss: 1.6966, LR: 0.000772
[12:04:05] Epoch 100 Complete. Avg Loss: 2.1572, LR: 0.000772
  -> New best model saved (loss: 2.1572)
[12:04:05] Epoch [101/300], Step [0/384], Loss: 2.1003, LR: 0.000768
[12:04:08] Epoch [101/300], Step [20/384], Loss: 2.7683, LR: 0.000768
[12:04:10] Epoch [101/300], Step [40/384], Loss: 1.9134, LR: 0.000768
[12:04:12] Epoch [101/300], Step [60/384], Loss: 2.2952, LR: 0.000768
[12:04:14] Epoch [101/300], Step [80/384], Loss: 1.8395, LR: 0.000768
[12:04:16] Epoch [101/300], Step [100/384], Loss: 1.7367, LR: 0.000768
[12:04:19] Epoch [101/300], Step [120/384], Loss: 2.2075, LR: 0.000768
[12:04:21] Epoch [101/300], Step [140/384], Loss: 1.8886, LR: 0.000768
[12:04:23] Epoch [101/300], Step [160/384], Loss: 2.4024, LR: 0.000768
[12:04:25] Epoch [101/300], Step [180/384], Loss: 2.5280, LR: 0.000768
[12:04:27] Epoch [101/300], Step [200/384], Loss: 1.8324, LR: 0.000768
[12:04:29] Epoch [101/300], Step [220/384], Loss: 1.9007, LR: 0.000768
[12:04:31] Epoch [101/300], Step [240/384], Loss: 2.5923, LR: 0.000768
[12:04:34] Epoch [101/300], Step [260/384], Loss: 2.5333, LR: 0.000768
[12:04:36] Epoch [101/300], Step [280/384], Loss: 1.9301, LR: 0.000768
[12:04:38] Epoch [101/300], Step [300/384], Loss: 1.8354, LR: 0.000768
[12:04:40] Epoch [101/300], Step [320/384], Loss: 1.9866, LR: 0.000768
[12:04:42] Epoch [101/300], Step [340/384], Loss: 2.0609, LR: 0.000768
[12:04:44] Epoch [101/300], Step [360/384], Loss: 1.8109, LR: 0.000768
[12:04:47] Epoch [101/300], Step [380/384], Loss: 2.4358, LR: 0.000768
[12:04:47] Epoch 101 Complete. Avg Loss: 2.1406, LR: 0.000768
  -> New best model saved (loss: 2.1406)
[12:04:47] Epoch [102/300], Step [0/384], Loss: 2.1773, LR: 0.000763
[12:04:49] Epoch [102/300], Step [20/384], Loss: 1.7525, LR: 0.000763
[12:04:51] Epoch [102/300], Step [40/384], Loss: 1.7759, LR: 0.000763
[12:04:53] Epoch [102/300], Step [60/384], Loss: 2.1875, LR: 0.000763
[12:04:56] Epoch [102/300], Step [80/384], Loss: 2.1445, LR: 0.000763
[12:04:58] Epoch [102/300], Step [100/384], Loss: 2.1326, LR: 0.000763
[12:05:00] Epoch [102/300], Step [120/384], Loss: 2.6513, LR: 0.000763
[12:05:02] Epoch [102/300], Step [140/384], Loss: 2.3633, LR: 0.000763
[12:05:05] Epoch [102/300], Step [160/384], Loss: 1.8148, LR: 0.000763
[12:05:07] Epoch [102/300], Step [180/384], Loss: 1.9324, LR: 0.000763
[12:05:09] Epoch [102/300], Step [200/384], Loss: 1.7883, LR: 0.000763
[12:05:11] Epoch [102/300], Step [220/384], Loss: 1.7450, LR: 0.000763
[12:05:13] Epoch [102/300], Step [240/384], Loss: 1.7009, LR: 0.000763
[12:05:16] Epoch [102/300], Step [260/384], Loss: 2.1159, LR: 0.000763
[12:05:18] Epoch [102/300], Step [280/384], Loss: 2.3405, LR: 0.000763
[12:05:20] Epoch [102/300], Step [300/384], Loss: 2.5630, LR: 0.000763
[12:05:22] Epoch [102/300], Step [320/384], Loss: 1.8980, LR: 0.000763
[12:05:24] Epoch [102/300], Step [340/384], Loss: 1.9268, LR: 0.000763
[12:05:26] Epoch [102/300], Step [360/384], Loss: 2.3898, LR: 0.000763
[12:05:28] Epoch [102/300], Step [380/384], Loss: 2.1622, LR: 0.000763
[12:05:29] Epoch 102 Complete. Avg Loss: 2.1404, LR: 0.000763
  -> New best model saved (loss: 2.1404)
[12:05:29] Epoch [103/300], Step [0/384], Loss: 2.3996, LR: 0.000759
[12:05:31] Epoch [103/300], Step [20/384], Loss: 2.5749, LR: 0.000759
[12:05:33] Epoch [103/300], Step [40/384], Loss: 2.0957, LR: 0.000759
[12:05:35] Epoch [103/300], Step [60/384], Loss: 2.4020, LR: 0.000759
[12:05:37] Epoch [103/300], Step [80/384], Loss: 2.3609, LR: 0.000759
[12:05:39] Epoch [103/300], Step [100/384], Loss: 1.7524, LR: 0.000759
[12:05:41] Epoch [103/300], Step [120/384], Loss: 2.2332, LR: 0.000759
[12:05:44] Epoch [103/300], Step [140/384], Loss: 2.0060, LR: 0.000759
[12:05:46] Epoch [103/300], Step [160/384], Loss: 2.2428, LR: 0.000759
[12:05:48] Epoch [103/300], Step [180/384], Loss: 2.3016, LR: 0.000759
[12:05:51] Epoch [103/300], Step [200/384], Loss: 2.3026, LR: 0.000759
[12:05:53] Epoch [103/300], Step [220/384], Loss: 1.7423, LR: 0.000759
[12:05:55] Epoch [103/300], Step [240/384], Loss: 2.1983, LR: 0.000759
[12:05:57] Epoch [103/300], Step [260/384], Loss: 2.1863, LR: 0.000759
[12:05:59] Epoch [103/300], Step [280/384], Loss: 1.7948, LR: 0.000759
[12:06:01] Epoch [103/300], Step [300/384], Loss: 1.8353, LR: 0.000759
[12:06:04] Epoch [103/300], Step [320/384], Loss: 2.1531, LR: 0.000759
[12:06:06] Epoch [103/300], Step [340/384], Loss: 1.9005, LR: 0.000759
[12:06:08] Epoch [103/300], Step [360/384], Loss: 2.7510, LR: 0.000759
[12:06:10] Epoch [103/300], Step [380/384], Loss: 2.6125, LR: 0.000759
[12:06:10] Epoch 103 Complete. Avg Loss: 2.1354, LR: 0.000759
  -> New best model saved (loss: 2.1354)
[12:06:11] Epoch [104/300], Step [0/384], Loss: 2.2158, LR: 0.000754
[12:06:13] Epoch [104/300], Step [20/384], Loss: 1.9675, LR: 0.000754
[12:06:15] Epoch [104/300], Step [40/384], Loss: 2.1360, LR: 0.000754
[12:06:17] Epoch [104/300], Step [60/384], Loss: 1.8667, LR: 0.000754
[12:06:19] Epoch [104/300], Step [80/384], Loss: 1.9930, LR: 0.000754
[12:06:22] Epoch [104/300], Step [100/384], Loss: 1.5252, LR: 0.000754
[12:06:24] Epoch [104/300], Step [120/384], Loss: 1.7429, LR: 0.000754
[12:06:26] Epoch [104/300], Step [140/384], Loss: 1.8997, LR: 0.000754
[12:06:28] Epoch [104/300], Step [160/384], Loss: 1.8722, LR: 0.000754
[12:06:30] Epoch [104/300], Step [180/384], Loss: 2.4940, LR: 0.000754
[12:06:32] Epoch [104/300], Step [200/384], Loss: 2.3377, LR: 0.000754
[12:06:34] Epoch [104/300], Step [220/384], Loss: 2.2392, LR: 0.000754
[12:06:37] Epoch [104/300], Step [240/384], Loss: 1.8913, LR: 0.000754
[12:06:39] Epoch [104/300], Step [260/384], Loss: 1.8126, LR: 0.000754
[12:06:41] Epoch [104/300], Step [280/384], Loss: 1.7403, LR: 0.000754
[12:06:43] Epoch [104/300], Step [300/384], Loss: 2.3933, LR: 0.000754
[12:06:45] Epoch [104/300], Step [320/384], Loss: 1.7742, LR: 0.000754
[12:06:48] Epoch [104/300], Step [340/384], Loss: 1.8104, LR: 0.000754
[12:06:50] Epoch [104/300], Step [360/384], Loss: 2.2972, LR: 0.000754
[12:06:52] Epoch [104/300], Step [380/384], Loss: 2.5360, LR: 0.000754
[12:06:52] Epoch 104 Complete. Avg Loss: 2.1389, LR: 0.000754
[12:06:52] Epoch [105/300], Step [0/384], Loss: 1.4802, LR: 0.000749
[12:06:55] Epoch [105/300], Step [20/384], Loss: 1.8297, LR: 0.000749
[12:06:57] Epoch [105/300], Step [40/384], Loss: 2.0332, LR: 0.000749
[12:06:59] Epoch [105/300], Step [60/384], Loss: 1.7623, LR: 0.000749
[12:07:01] Epoch [105/300], Step [80/384], Loss: 1.8400, LR: 0.000749
[12:07:03] Epoch [105/300], Step [100/384], Loss: 2.1555, LR: 0.000749
[12:07:05] Epoch [105/300], Step [120/384], Loss: 1.8751, LR: 0.000749
[12:07:08] Epoch [105/300], Step [140/384], Loss: 1.8328, LR: 0.000749
[12:07:10] Epoch [105/300], Step [160/384], Loss: 2.4388, LR: 0.000749
[12:07:12] Epoch [105/300], Step [180/384], Loss: 2.7176, LR: 0.000749
[12:07:14] Epoch [105/300], Step [200/384], Loss: 2.2246, LR: 0.000749
[12:07:16] Epoch [105/300], Step [220/384], Loss: 1.8977, LR: 0.000749
[12:07:19] Epoch [105/300], Step [240/384], Loss: 2.2035, LR: 0.000749
[12:07:21] Epoch [105/300], Step [260/384], Loss: 1.7645, LR: 0.000749
[12:07:23] Epoch [105/300], Step [280/384], Loss: 2.0040, LR: 0.000749
[12:07:25] Epoch [105/300], Step [300/384], Loss: 2.5962, LR: 0.000749
[12:07:27] Epoch [105/300], Step [320/384], Loss: 2.1157, LR: 0.000749
[12:07:30] Epoch [105/300], Step [340/384], Loss: 2.2237, LR: 0.000749
[12:07:32] Epoch [105/300], Step [360/384], Loss: 2.0515, LR: 0.000749
[12:07:34] Epoch [105/300], Step [380/384], Loss: 1.7554, LR: 0.000749
[12:07:34] Epoch 105 Complete. Avg Loss: 2.1139, LR: 0.000749
  -> New best model saved (loss: 2.1139)
[12:07:34] Epoch [106/300], Step [0/384], Loss: 1.6384, LR: 0.000745
[12:07:37] Epoch [106/300], Step [20/384], Loss: 1.6837, LR: 0.000745
[12:07:39] Epoch [106/300], Step [40/384], Loss: 2.2504, LR: 0.000745
[12:07:41] Epoch [106/300], Step [60/384], Loss: 2.5264, LR: 0.000745
[12:07:43] Epoch [106/300], Step [80/384], Loss: 2.2708, LR: 0.000745
[12:07:45] Epoch [106/300], Step [100/384], Loss: 2.2940, LR: 0.000745
[12:07:47] Epoch [106/300], Step [120/384], Loss: 1.6052, LR: 0.000745
[12:07:50] Epoch [106/300], Step [140/384], Loss: 2.0978, LR: 0.000745
[12:07:52] Epoch [106/300], Step [160/384], Loss: 2.0169, LR: 0.000745
[12:07:54] Epoch [106/300], Step [180/384], Loss: 2.0790, LR: 0.000745
[12:07:56] Epoch [106/300], Step [200/384], Loss: 1.9379, LR: 0.000745
[12:07:59] Epoch [106/300], Step [220/384], Loss: 2.0671, LR: 0.000745
[12:08:01] Epoch [106/300], Step [240/384], Loss: 3.0341, LR: 0.000745
[12:08:03] Epoch [106/300], Step [260/384], Loss: 2.6461, LR: 0.000745
[12:08:05] Epoch [106/300], Step [280/384], Loss: 1.9644, LR: 0.000745
[12:08:07] Epoch [106/300], Step [300/384], Loss: 2.2031, LR: 0.000745
[12:08:09] Epoch [106/300], Step [320/384], Loss: 2.1381, LR: 0.000745
[12:08:11] Epoch [106/300], Step [340/384], Loss: 2.3186, LR: 0.000745
[12:08:14] Epoch [106/300], Step [360/384], Loss: 1.8949, LR: 0.000745
[12:08:16] Epoch [106/300], Step [380/384], Loss: 1.9476, LR: 0.000745
[12:08:16] Epoch 106 Complete. Avg Loss: 2.1359, LR: 0.000745
[12:08:16] Epoch [107/300], Step [0/384], Loss: 2.1087, LR: 0.000740
[12:08:18] Epoch [107/300], Step [20/384], Loss: 1.8734, LR: 0.000740
[12:08:21] Epoch [107/300], Step [40/384], Loss: 1.9433, LR: 0.000740
[12:08:23] Epoch [107/300], Step [60/384], Loss: 1.9854, LR: 0.000740
[12:08:25] Epoch [107/300], Step [80/384], Loss: 1.7473, LR: 0.000740
[12:08:27] Epoch [107/300], Step [100/384], Loss: 1.6555, LR: 0.000740
[12:08:29] Epoch [107/300], Step [120/384], Loss: 2.0367, LR: 0.000740
[12:08:31] Epoch [107/300], Step [140/384], Loss: 2.5168, LR: 0.000740
[12:08:34] Epoch [107/300], Step [160/384], Loss: 2.6276, LR: 0.000740
[12:08:36] Epoch [107/300], Step [180/384], Loss: 2.0723, LR: 0.000740
[12:08:38] Epoch [107/300], Step [200/384], Loss: 1.8801, LR: 0.000740
[12:08:40] Epoch [107/300], Step [220/384], Loss: 1.7620, LR: 0.000740
[12:08:42] Epoch [107/300], Step [240/384], Loss: 2.1277, LR: 0.000740
[12:08:44] Epoch [107/300], Step [260/384], Loss: 1.9467, LR: 0.000740
[12:08:46] Epoch [107/300], Step [280/384], Loss: 2.4909, LR: 0.000740
[12:08:49] Epoch [107/300], Step [300/384], Loss: 2.6740, LR: 0.000740
[12:08:51] Epoch [107/300], Step [320/384], Loss: 1.8906, LR: 0.000740
[12:08:53] Epoch [107/300], Step [340/384], Loss: 1.8840, LR: 0.000740
[12:08:55] Epoch [107/300], Step [360/384], Loss: 2.5428, LR: 0.000740
[12:08:57] Epoch [107/300], Step [380/384], Loss: 1.8202, LR: 0.000740
[12:08:58] Epoch 107 Complete. Avg Loss: 2.1296, LR: 0.000740
[12:08:58] Epoch [108/300], Step [0/384], Loss: 1.9854, LR: 0.000736
[12:09:00] Epoch [108/300], Step [20/384], Loss: 1.8394, LR: 0.000736
[12:09:02] Epoch [108/300], Step [40/384], Loss: 1.9038, LR: 0.000736
[12:09:04] Epoch [108/300], Step [60/384], Loss: 2.1843, LR: 0.000736
[12:09:07] Epoch [108/300], Step [80/384], Loss: 1.8329, LR: 0.000736
[12:09:09] Epoch [108/300], Step [100/384], Loss: 1.9036, LR: 0.000736
[12:09:11] Epoch [108/300], Step [120/384], Loss: 1.8232, LR: 0.000736
[12:09:13] Epoch [108/300], Step [140/384], Loss: 2.5080, LR: 0.000736
[12:09:16] Epoch [108/300], Step [160/384], Loss: 1.6432, LR: 0.000736
[12:09:18] Epoch [108/300], Step [180/384], Loss: 1.9186, LR: 0.000736
[12:09:20] Epoch [108/300], Step [200/384], Loss: 2.0462, LR: 0.000736
[12:09:22] Epoch [108/300], Step [220/384], Loss: 2.3063, LR: 0.000736
[12:09:24] Epoch [108/300], Step [240/384], Loss: 1.8716, LR: 0.000736
[12:09:27] Epoch [108/300], Step [260/384], Loss: 1.8898, LR: 0.000736
[12:09:29] Epoch [108/300], Step [280/384], Loss: 1.7743, LR: 0.000736
[12:09:31] Epoch [108/300], Step [300/384], Loss: 2.4536, LR: 0.000736
[12:09:33] Epoch [108/300], Step [320/384], Loss: 2.2985, LR: 0.000736
[12:09:35] Epoch [108/300], Step [340/384], Loss: 1.4961, LR: 0.000736
[12:09:37] Epoch [108/300], Step [360/384], Loss: 2.5901, LR: 0.000736
[12:09:39] Epoch [108/300], Step [380/384], Loss: 1.7781, LR: 0.000736
[12:09:40] Epoch 108 Complete. Avg Loss: 2.1171, LR: 0.000736
[12:09:40] Epoch [109/300], Step [0/384], Loss: 2.4484, LR: 0.000731
[12:09:42] Epoch [109/300], Step [20/384], Loss: 1.8185, LR: 0.000731
[12:09:44] Epoch [109/300], Step [40/384], Loss: 1.8922, LR: 0.000731
[12:09:46] Epoch [109/300], Step [60/384], Loss: 2.1541, LR: 0.000731
[12:09:49] Epoch [109/300], Step [80/384], Loss: 2.1725, LR: 0.000731
[12:09:51] Epoch [109/300], Step [100/384], Loss: 2.0324, LR: 0.000731
[12:09:53] Epoch [109/300], Step [120/384], Loss: 2.2908, LR: 0.000731
[12:09:55] Epoch [109/300], Step [140/384], Loss: 2.0257, LR: 0.000731
[12:09:57] Epoch [109/300], Step [160/384], Loss: 2.4110, LR: 0.000731
[12:10:00] Epoch [109/300], Step [180/384], Loss: 2.0919, LR: 0.000731
[12:10:02] Epoch [109/300], Step [200/384], Loss: 2.5410, LR: 0.000731
[12:10:04] Epoch [109/300], Step [220/384], Loss: 1.9539, LR: 0.000731
[12:10:06] Epoch [109/300], Step [240/384], Loss: 2.8751, LR: 0.000731
[12:10:08] Epoch [109/300], Step [260/384], Loss: 2.4683, LR: 0.000731
[12:10:11] Epoch [109/300], Step [280/384], Loss: 1.9014, LR: 0.000731
[12:10:13] Epoch [109/300], Step [300/384], Loss: 1.3066, LR: 0.000731
[12:10:15] Epoch [109/300], Step [320/384], Loss: 1.7221, LR: 0.000731
[12:10:17] Epoch [109/300], Step [340/384], Loss: 2.2046, LR: 0.000731
[12:10:19] Epoch [109/300], Step [360/384], Loss: 2.5986, LR: 0.000731
[12:10:22] Epoch [109/300], Step [380/384], Loss: 1.8289, LR: 0.000731
[12:10:22] Epoch 109 Complete. Avg Loss: 2.1055, LR: 0.000731
  -> New best model saved (loss: 2.1055)
[12:10:22] Epoch [110/300], Step [0/384], Loss: 1.6264, LR: 0.000726
[12:10:24] Epoch [110/300], Step [20/384], Loss: 1.6773, LR: 0.000726
[12:10:27] Epoch [110/300], Step [40/384], Loss: 1.7559, LR: 0.000726
[12:10:29] Epoch [110/300], Step [60/384], Loss: 2.6724, LR: 0.000726
[12:10:31] Epoch [110/300], Step [80/384], Loss: 2.4194, LR: 0.000726
[12:10:33] Epoch [110/300], Step [100/384], Loss: 2.0037, LR: 0.000726
[12:10:35] Epoch [110/300], Step [120/384], Loss: 2.0216, LR: 0.000726
[12:10:38] Epoch [110/300], Step [140/384], Loss: 2.2637, LR: 0.000726
[12:10:40] Epoch [110/300], Step [160/384], Loss: 2.0179, LR: 0.000726
[12:10:42] Epoch [110/300], Step [180/384], Loss: 2.0313, LR: 0.000726
[12:10:44] Epoch [110/300], Step [200/384], Loss: 2.3443, LR: 0.000726
[12:10:46] Epoch [110/300], Step [220/384], Loss: 1.8795, LR: 0.000726
[12:10:48] Epoch [110/300], Step [240/384], Loss: 2.0344, LR: 0.000726
[12:10:50] Epoch [110/300], Step [260/384], Loss: 2.5854, LR: 0.000726
[12:10:53] Epoch [110/300], Step [280/384], Loss: 3.1010, LR: 0.000726
[12:10:55] Epoch [110/300], Step [300/384], Loss: 2.3513, LR: 0.000726
[12:10:57] Epoch [110/300], Step [320/384], Loss: 2.1887, LR: 0.000726
[12:10:59] Epoch [110/300], Step [340/384], Loss: 1.4371, LR: 0.000726
[12:11:01] Epoch [110/300], Step [360/384], Loss: 2.3178, LR: 0.000726
[12:11:03] Epoch [110/300], Step [380/384], Loss: 2.3503, LR: 0.000726
[12:11:04] Epoch 110 Complete. Avg Loss: 2.0919, LR: 0.000726
  -> New best model saved (loss: 2.0919)
[12:11:04] Epoch [111/300], Step [0/384], Loss: 1.6906, LR: 0.000721
[12:11:06] Epoch [111/300], Step [20/384], Loss: 1.6644, LR: 0.000721
[12:11:08] Epoch [111/300], Step [40/384], Loss: 1.6111, LR: 0.000721
[12:11:10] Epoch [111/300], Step [60/384], Loss: 2.0026, LR: 0.000721
[12:11:13] Epoch [111/300], Step [80/384], Loss: 2.3666, LR: 0.000721
[12:11:15] Epoch [111/300], Step [100/384], Loss: 2.0210, LR: 0.000721
[12:11:17] Epoch [111/300], Step [120/384], Loss: 2.0093, LR: 0.000721
[12:11:19] Epoch [111/300], Step [140/384], Loss: 1.7545, LR: 0.000721
[12:11:21] Epoch [111/300], Step [160/384], Loss: 2.0597, LR: 0.000721
[12:11:23] Epoch [111/300], Step [180/384], Loss: 1.9087, LR: 0.000721
[12:11:25] Epoch [111/300], Step [200/384], Loss: 2.1584, LR: 0.000721
[12:11:28] Epoch [111/300], Step [220/384], Loss: 1.9190, LR: 0.000721
[12:11:30] Epoch [111/300], Step [240/384], Loss: 2.1925, LR: 0.000721
[12:11:32] Epoch [111/300], Step [260/384], Loss: 2.3803, LR: 0.000721
[12:11:35] Epoch [111/300], Step [280/384], Loss: 1.9544, LR: 0.000721
[12:11:37] Epoch [111/300], Step [300/384], Loss: 2.1627, LR: 0.000721
[12:11:39] Epoch [111/300], Step [320/384], Loss: 1.8655, LR: 0.000721
[12:11:41] Epoch [111/300], Step [340/384], Loss: 2.2755, LR: 0.000721
[12:11:43] Epoch [111/300], Step [360/384], Loss: 2.1047, LR: 0.000721
[12:11:45] Epoch [111/300], Step [380/384], Loss: 2.0923, LR: 0.000721
[12:11:45] Epoch 111 Complete. Avg Loss: 2.1067, LR: 0.000721
[12:11:46] Epoch [112/300], Step [0/384], Loss: 2.0773, LR: 0.000717
[12:11:48] Epoch [112/300], Step [20/384], Loss: 2.0034, LR: 0.000717
[12:11:50] Epoch [112/300], Step [40/384], Loss: 1.8499, LR: 0.000717
[12:11:52] Epoch [112/300], Step [60/384], Loss: 2.9008, LR: 0.000717
[12:11:54] Epoch [112/300], Step [80/384], Loss: 2.3708, LR: 0.000717
[12:11:56] Epoch [112/300], Step [100/384], Loss: 2.0299, LR: 0.000717
[12:11:59] Epoch [112/300], Step [120/384], Loss: 2.3391, LR: 0.000717
[12:12:01] Epoch [112/300], Step [140/384], Loss: 2.4465, LR: 0.000717
[12:12:03] Epoch [112/300], Step [160/384], Loss: 1.8975, LR: 0.000717
[12:12:05] Epoch [112/300], Step [180/384], Loss: 2.0124, LR: 0.000717
[12:12:07] Epoch [112/300], Step [200/384], Loss: 2.4553, LR: 0.000717
[12:12:09] Epoch [112/300], Step [220/384], Loss: 2.0545, LR: 0.000717
[12:12:12] Epoch [112/300], Step [240/384], Loss: 1.8011, LR: 0.000717
[12:12:14] Epoch [112/300], Step [260/384], Loss: 1.7014, LR: 0.000717
[12:12:16] Epoch [112/300], Step [280/384], Loss: 1.5285, LR: 0.000717
[12:12:18] Epoch [112/300], Step [300/384], Loss: 1.6567, LR: 0.000717
[12:12:20] Epoch [112/300], Step [320/384], Loss: 1.8266, LR: 0.000717
[12:12:23] Epoch [112/300], Step [340/384], Loss: 2.3618, LR: 0.000717
[12:12:25] Epoch [112/300], Step [360/384], Loss: 2.0036, LR: 0.000717
[12:12:28] Epoch [112/300], Step [380/384], Loss: 2.1055, LR: 0.000717
[12:12:28] Epoch 112 Complete. Avg Loss: 2.1115, LR: 0.000717
[12:12:28] Epoch [113/300], Step [0/384], Loss: 1.4896, LR: 0.000712
[12:12:30] Epoch [113/300], Step [20/384], Loss: 1.9449, LR: 0.000712
[12:12:32] Epoch [113/300], Step [40/384], Loss: 2.1460, LR: 0.000712
[12:12:35] Epoch [113/300], Step [60/384], Loss: 1.9120, LR: 0.000712
[12:12:37] Epoch [113/300], Step [80/384], Loss: 2.0227, LR: 0.000712
[12:12:39] Epoch [113/300], Step [100/384], Loss: 1.5383, LR: 0.000712
[12:12:41] Epoch [113/300], Step [120/384], Loss: 1.5364, LR: 0.000712
[12:12:44] Epoch [113/300], Step [140/384], Loss: 1.7784, LR: 0.000712
[12:12:46] Epoch [113/300], Step [160/384], Loss: 2.2886, LR: 0.000712
[12:12:48] Epoch [113/300], Step [180/384], Loss: 1.9781, LR: 0.000712
[12:12:50] Epoch [113/300], Step [200/384], Loss: 2.0679, LR: 0.000712
[12:12:52] Epoch [113/300], Step [220/384], Loss: 1.9088, LR: 0.000712
[12:12:55] Epoch [113/300], Step [240/384], Loss: 2.7256, LR: 0.000712
[12:12:57] Epoch [113/300], Step [260/384], Loss: 2.2982, LR: 0.000712
[12:12:59] Epoch [113/300], Step [280/384], Loss: 1.7931, LR: 0.000712
[12:13:01] Epoch [113/300], Step [300/384], Loss: 1.8541, LR: 0.000712
[12:13:03] Epoch [113/300], Step [320/384], Loss: 2.0172, LR: 0.000712
[12:13:05] Epoch [113/300], Step [340/384], Loss: 2.0128, LR: 0.000712
[12:13:08] Epoch [113/300], Step [360/384], Loss: 1.9612, LR: 0.000712
[12:13:10] Epoch [113/300], Step [380/384], Loss: 2.0485, LR: 0.000712
[12:13:10] Epoch 113 Complete. Avg Loss: 2.0834, LR: 0.000712
  -> New best model saved (loss: 2.0834)
[12:13:10] Epoch [114/300], Step [0/384], Loss: 1.6583, LR: 0.000707
[12:13:13] Epoch [114/300], Step [20/384], Loss: 2.0628, LR: 0.000707
[12:13:15] Epoch [114/300], Step [40/384], Loss: 1.8430, LR: 0.000707
[12:13:17] Epoch [114/300], Step [60/384], Loss: 1.6993, LR: 0.000707
[12:13:19] Epoch [114/300], Step [80/384], Loss: 2.1106, LR: 0.000707
[12:13:22] Epoch [114/300], Step [100/384], Loss: 2.0677, LR: 0.000707
[12:13:24] Epoch [114/300], Step [120/384], Loss: 1.7341, LR: 0.000707
[12:13:26] Epoch [114/300], Step [140/384], Loss: 1.8932, LR: 0.000707
[12:13:28] Epoch [114/300], Step [160/384], Loss: 1.9116, LR: 0.000707
[12:13:31] Epoch [114/300], Step [180/384], Loss: 1.9320, LR: 0.000707
[12:13:33] Epoch [114/300], Step [200/384], Loss: 2.3505, LR: 0.000707
[12:13:35] Epoch [114/300], Step [220/384], Loss: 1.8817, LR: 0.000707
[12:13:37] Epoch [114/300], Step [240/384], Loss: 1.7178, LR: 0.000707
[12:13:39] Epoch [114/300], Step [260/384], Loss: 1.8669, LR: 0.000707
[12:13:41] Epoch [114/300], Step [280/384], Loss: 1.8406, LR: 0.000707
[12:13:43] Epoch [114/300], Step [300/384], Loss: 1.8775, LR: 0.000707
[12:13:46] Epoch [114/300], Step [320/384], Loss: 1.8938, LR: 0.000707
[12:13:48] Epoch [114/300], Step [340/384], Loss: 2.5919, LR: 0.000707
[12:13:50] Epoch [114/300], Step [360/384], Loss: 2.3026, LR: 0.000707
[12:13:52] Epoch [114/300], Step [380/384], Loss: 2.0645, LR: 0.000707
[12:13:53] Epoch 114 Complete. Avg Loss: 2.0805, LR: 0.000707
  -> New best model saved (loss: 2.0805)
[12:13:53] Epoch [115/300], Step [0/384], Loss: 2.3310, LR: 0.000702
[12:13:55] Epoch [115/300], Step [20/384], Loss: 1.5573, LR: 0.000702
[12:13:57] Epoch [115/300], Step [40/384], Loss: 1.7851, LR: 0.000702
[12:13:59] Epoch [115/300], Step [60/384], Loss: 2.5371, LR: 0.000702
[12:14:02] Epoch [115/300], Step [80/384], Loss: 2.8212, LR: 0.000702
[12:14:04] Epoch [115/300], Step [100/384], Loss: 1.8086, LR: 0.000702
[12:14:06] Epoch [115/300], Step [120/384], Loss: 1.9045, LR: 0.000702
[12:14:08] Epoch [115/300], Step [140/384], Loss: 2.2507, LR: 0.000702
[12:14:10] Epoch [115/300], Step [160/384], Loss: 1.5765, LR: 0.000702
[12:14:13] Epoch [115/300], Step [180/384], Loss: 2.2228, LR: 0.000702
[12:14:15] Epoch [115/300], Step [200/384], Loss: 2.2728, LR: 0.000702
[12:14:17] Epoch [115/300], Step [220/384], Loss: 2.4687, LR: 0.000702
[12:14:19] Epoch [115/300], Step [240/384], Loss: 1.8576, LR: 0.000702
[12:14:21] Epoch [115/300], Step [260/384], Loss: 2.0520, LR: 0.000702
[12:14:23] Epoch [115/300], Step [280/384], Loss: 2.5453, LR: 0.000702
[12:14:26] Epoch [115/300], Step [300/384], Loss: 2.1046, LR: 0.000702
[12:14:28] Epoch [115/300], Step [320/384], Loss: 1.6760, LR: 0.000702
[12:14:30] Epoch [115/300], Step [340/384], Loss: 2.5042, LR: 0.000702
[12:14:32] Epoch [115/300], Step [360/384], Loss: 1.8247, LR: 0.000702
[12:14:35] Epoch [115/300], Step [380/384], Loss: 1.7001, LR: 0.000702
[12:14:35] Epoch 115 Complete. Avg Loss: 2.0676, LR: 0.000702
  -> New best model saved (loss: 2.0676)
[12:14:35] Epoch [116/300], Step [0/384], Loss: 1.9089, LR: 0.000697
[12:14:37] Epoch [116/300], Step [20/384], Loss: 2.2462, LR: 0.000697
[12:14:40] Epoch [116/300], Step [40/384], Loss: 2.2292, LR: 0.000697
[12:14:42] Epoch [116/300], Step [60/384], Loss: 2.7745, LR: 0.000697
[12:14:44] Epoch [116/300], Step [80/384], Loss: 1.8571, LR: 0.000697
[12:14:46] Epoch [116/300], Step [100/384], Loss: 2.3354, LR: 0.000697
[12:14:49] Epoch [116/300], Step [120/384], Loss: 2.4151, LR: 0.000697
[12:14:51] Epoch [116/300], Step [140/384], Loss: 2.3137, LR: 0.000697
[12:14:53] Epoch [116/300], Step [160/384], Loss: 1.9225, LR: 0.000697
[12:14:55] Epoch [116/300], Step [180/384], Loss: 2.2884, LR: 0.000697
[12:14:57] Epoch [116/300], Step [200/384], Loss: 2.3193, LR: 0.000697
[12:14:59] Epoch [116/300], Step [220/384], Loss: 2.2888, LR: 0.000697
[12:15:01] Epoch [116/300], Step [240/384], Loss: 1.9592, LR: 0.000697
[12:15:04] Epoch [116/300], Step [260/384], Loss: 1.7883, LR: 0.000697
[12:15:06] Epoch [116/300], Step [280/384], Loss: 2.4042, LR: 0.000697
[12:15:08] Epoch [116/300], Step [300/384], Loss: 1.6813, LR: 0.000697
[12:15:10] Epoch [116/300], Step [320/384], Loss: 2.3733, LR: 0.000697
[12:15:12] Epoch [116/300], Step [340/384], Loss: 2.0107, LR: 0.000697
[12:15:14] Epoch [116/300], Step [360/384], Loss: 2.0978, LR: 0.000697
[12:15:17] Epoch [116/300], Step [380/384], Loss: 1.8298, LR: 0.000697
[12:15:17] Epoch 116 Complete. Avg Loss: 2.0794, LR: 0.000697
[12:15:17] Epoch [117/300], Step [0/384], Loss: 1.5404, LR: 0.000693
[12:15:19] Epoch [117/300], Step [20/384], Loss: 2.0458, LR: 0.000693
[12:15:21] Epoch [117/300], Step [40/384], Loss: 2.4937, LR: 0.000693
[12:15:23] Epoch [117/300], Step [60/384], Loss: 2.2131, LR: 0.000693
[12:15:26] Epoch [117/300], Step [80/384], Loss: 1.9161, LR: 0.000693
[12:15:28] Epoch [117/300], Step [100/384], Loss: 1.9034, LR: 0.000693
[12:15:30] Epoch [117/300], Step [120/384], Loss: 2.7732, LR: 0.000693
[12:15:32] Epoch [117/300], Step [140/384], Loss: 2.7065, LR: 0.000693
[12:15:34] Epoch [117/300], Step [160/384], Loss: 2.6617, LR: 0.000693
[12:15:37] Epoch [117/300], Step [180/384], Loss: 1.6066, LR: 0.000693
[12:15:39] Epoch [117/300], Step [200/384], Loss: 1.8142, LR: 0.000693
[12:15:41] Epoch [117/300], Step [220/384], Loss: 1.7395, LR: 0.000693
[12:15:43] Epoch [117/300], Step [240/384], Loss: 2.1272, LR: 0.000693
[12:15:45] Epoch [117/300], Step [260/384], Loss: 1.7637, LR: 0.000693
[12:15:48] Epoch [117/300], Step [280/384], Loss: 2.6280, LR: 0.000693
[12:15:50] Epoch [117/300], Step [300/384], Loss: 2.4806, LR: 0.000693
[12:15:52] Epoch [117/300], Step [320/384], Loss: 1.8149, LR: 0.000693
[12:15:54] Epoch [117/300], Step [340/384], Loss: 2.1797, LR: 0.000693
[12:15:57] Epoch [117/300], Step [360/384], Loss: 2.2175, LR: 0.000693
[12:15:59] Epoch [117/300], Step [380/384], Loss: 2.2268, LR: 0.000693
[12:15:59] Epoch 117 Complete. Avg Loss: 2.0565, LR: 0.000693
  -> New best model saved (loss: 2.0565)
[12:15:59] Epoch [118/300], Step [0/384], Loss: 2.2095, LR: 0.000688
[12:16:02] Epoch [118/300], Step [20/384], Loss: 2.6426, LR: 0.000688
[12:16:04] Epoch [118/300], Step [40/384], Loss: 2.0875, LR: 0.000688
[12:16:06] Epoch [118/300], Step [60/384], Loss: 1.8442, LR: 0.000688
[12:16:08] Epoch [118/300], Step [80/384], Loss: 1.7648, LR: 0.000688
[12:16:10] Epoch [118/300], Step [100/384], Loss: 2.3327, LR: 0.000688
[12:16:13] Epoch [118/300], Step [120/384], Loss: 2.1951, LR: 0.000688
[12:16:15] Epoch [118/300], Step [140/384], Loss: 2.0504, LR: 0.000688
[12:16:17] Epoch [118/300], Step [160/384], Loss: 2.1429, LR: 0.000688
[12:16:19] Epoch [118/300], Step [180/384], Loss: 1.6425, LR: 0.000688
[12:16:21] Epoch [118/300], Step [200/384], Loss: 2.2717, LR: 0.000688
[12:16:23] Epoch [118/300], Step [220/384], Loss: 2.2920, LR: 0.000688
[12:16:25] Epoch [118/300], Step [240/384], Loss: 2.0376, LR: 0.000688
[12:16:27] Epoch [118/300], Step [260/384], Loss: 2.8803, LR: 0.000688
[12:16:30] Epoch [118/300], Step [280/384], Loss: 1.9758, LR: 0.000688
[12:16:32] Epoch [118/300], Step [300/384], Loss: 1.6944, LR: 0.000688
[12:16:34] Epoch [118/300], Step [320/384], Loss: 2.3340, LR: 0.000688
[12:16:37] Epoch [118/300], Step [340/384], Loss: 1.9121, LR: 0.000688
[12:16:39] Epoch [118/300], Step [360/384], Loss: 1.6130, LR: 0.000688
[12:16:41] Epoch [118/300], Step [380/384], Loss: 2.1635, LR: 0.000688
[12:16:41] Epoch 118 Complete. Avg Loss: 2.0583, LR: 0.000688
[12:16:42] Epoch [119/300], Step [0/384], Loss: 1.9630, LR: 0.000683
[12:16:44] Epoch [119/300], Step [20/384], Loss: 2.2561, LR: 0.000683
[12:16:46] Epoch [119/300], Step [40/384], Loss: 2.1626, LR: 0.000683
[12:16:48] Epoch [119/300], Step [60/384], Loss: 2.5344, LR: 0.000683
[12:16:50] Epoch [119/300], Step [80/384], Loss: 1.8097, LR: 0.000683
[12:16:52] Epoch [119/300], Step [100/384], Loss: 1.9029, LR: 0.000683
[12:16:55] Epoch [119/300], Step [120/384], Loss: 2.0954, LR: 0.000683
[12:16:57] Epoch [119/300], Step [140/384], Loss: 2.1246, LR: 0.000683
[12:16:59] Epoch [119/300], Step [160/384], Loss: 1.7193, LR: 0.000683
[12:17:02] Epoch [119/300], Step [180/384], Loss: 1.9577, LR: 0.000683
[12:17:04] Epoch [119/300], Step [200/384], Loss: 1.8977, LR: 0.000683
[12:17:06] Epoch [119/300], Step [220/384], Loss: 2.1124, LR: 0.000683
[12:17:08] Epoch [119/300], Step [240/384], Loss: 2.5575, LR: 0.000683
[12:17:10] Epoch [119/300], Step [260/384], Loss: 1.8853, LR: 0.000683
[12:17:12] Epoch [119/300], Step [280/384], Loss: 2.1763, LR: 0.000683
[12:17:14] Epoch [119/300], Step [300/384], Loss: 1.8997, LR: 0.000683
[12:17:17] Epoch [119/300], Step [320/384], Loss: 1.8284, LR: 0.000683
[12:17:19] Epoch [119/300], Step [340/384], Loss: 2.2335, LR: 0.000683
[12:17:21] Epoch [119/300], Step [360/384], Loss: 2.3057, LR: 0.000683
[12:17:23] Epoch [119/300], Step [380/384], Loss: 1.5442, LR: 0.000683
[12:17:23] Epoch 119 Complete. Avg Loss: 2.0485, LR: 0.000683
  -> New best model saved (loss: 2.0485)
[12:17:24] Epoch [120/300], Step [0/384], Loss: 1.8878, LR: 0.000678
[12:17:26] Epoch [120/300], Step [20/384], Loss: 2.4283, LR: 0.000678
[12:17:28] Epoch [120/300], Step [40/384], Loss: 1.8394, LR: 0.000678
[12:17:30] Epoch [120/300], Step [60/384], Loss: 1.4721, LR: 0.000678
[12:17:33] Epoch [120/300], Step [80/384], Loss: 2.0518, LR: 0.000678
[12:17:35] Epoch [120/300], Step [100/384], Loss: 2.6199, LR: 0.000678
[12:17:37] Epoch [120/300], Step [120/384], Loss: 2.6229, LR: 0.000678
[12:17:39] Epoch [120/300], Step [140/384], Loss: 2.1665, LR: 0.000678
[12:17:42] Epoch [120/300], Step [160/384], Loss: 1.4516, LR: 0.000678
[12:17:44] Epoch [120/300], Step [180/384], Loss: 2.2496, LR: 0.000678
[12:17:46] Epoch [120/300], Step [200/384], Loss: 2.3920, LR: 0.000678
[12:17:48] Epoch [120/300], Step [220/384], Loss: 1.9021, LR: 0.000678
[12:17:50] Epoch [120/300], Step [240/384], Loss: 1.7144, LR: 0.000678
[12:17:52] Epoch [120/300], Step [260/384], Loss: 3.2227, LR: 0.000678
[12:17:54] Epoch [120/300], Step [280/384], Loss: 2.0778, LR: 0.000678
[12:17:56] Epoch [120/300], Step [300/384], Loss: 1.8107, LR: 0.000678
[12:17:59] Epoch [120/300], Step [320/384], Loss: 2.4003, LR: 0.000678
[12:18:01] Epoch [120/300], Step [340/384], Loss: 2.4140, LR: 0.000678
[12:18:03] Epoch [120/300], Step [360/384], Loss: 1.8322, LR: 0.000678
[12:18:05] Epoch [120/300], Step [380/384], Loss: 2.1778, LR: 0.000678
[12:18:06] Epoch 120 Complete. Avg Loss: 2.0491, LR: 0.000678
[12:18:06] Epoch [121/300], Step [0/384], Loss: 1.5014, LR: 0.000673
[12:18:08] Epoch [121/300], Step [20/384], Loss: 1.8736, LR: 0.000673
[12:18:10] Epoch [121/300], Step [40/384], Loss: 2.2418, LR: 0.000673
[12:18:12] Epoch [121/300], Step [60/384], Loss: 1.9983, LR: 0.000673
[12:18:15] Epoch [121/300], Step [80/384], Loss: 3.4077, LR: 0.000673
[12:18:17] Epoch [121/300], Step [100/384], Loss: 1.4522, LR: 0.000673
[12:18:19] Epoch [121/300], Step [120/384], Loss: 1.6353, LR: 0.000673
[12:18:21] Epoch [121/300], Step [140/384], Loss: 2.6477, LR: 0.000673
[12:18:23] Epoch [121/300], Step [160/384], Loss: 1.7972, LR: 0.000673
[12:18:25] Epoch [121/300], Step [180/384], Loss: 2.4114, LR: 0.000673
[12:18:27] Epoch [121/300], Step [200/384], Loss: 1.9818, LR: 0.000673
[12:18:30] Epoch [121/300], Step [220/384], Loss: 1.8766, LR: 0.000673
[12:18:32] Epoch [121/300], Step [240/384], Loss: 2.0920, LR: 0.000673
[12:18:34] Epoch [121/300], Step [260/384], Loss: 2.7830, LR: 0.000673
[12:18:36] Epoch [121/300], Step [280/384], Loss: 2.0157, LR: 0.000673
[12:18:39] Epoch [121/300], Step [300/384], Loss: 1.9199, LR: 0.000673
[12:18:41] Epoch [121/300], Step [320/384], Loss: 1.7394, LR: 0.000673
[12:18:43] Epoch [121/300], Step [340/384], Loss: 2.2082, LR: 0.000673
[12:18:45] Epoch [121/300], Step [360/384], Loss: 1.6155, LR: 0.000673
[12:18:47] Epoch [121/300], Step [380/384], Loss: 1.5154, LR: 0.000673
[12:18:47] Epoch 121 Complete. Avg Loss: 2.0466, LR: 0.000673
  -> New best model saved (loss: 2.0466)
[12:18:48] Epoch [122/300], Step [0/384], Loss: 2.6078, LR: 0.000668
[12:18:50] Epoch [122/300], Step [20/384], Loss: 2.2074, LR: 0.000668
[12:18:52] Epoch [122/300], Step [40/384], Loss: 1.5080, LR: 0.000668
[12:18:54] Epoch [122/300], Step [60/384], Loss: 2.1221, LR: 0.000668
[12:18:57] Epoch [122/300], Step [80/384], Loss: 2.0248, LR: 0.000668
[12:18:59] Epoch [122/300], Step [100/384], Loss: 1.6670, LR: 0.000668
[12:19:01] Epoch [122/300], Step [120/384], Loss: 2.2182, LR: 0.000668
[12:19:03] Epoch [122/300], Step [140/384], Loss: 1.7566, LR: 0.000668
[12:19:05] Epoch [122/300], Step [160/384], Loss: 1.9269, LR: 0.000668
[12:19:08] Epoch [122/300], Step [180/384], Loss: 2.4785, LR: 0.000668
[12:19:10] Epoch [122/300], Step [200/384], Loss: 2.0189, LR: 0.000668
[12:19:12] Epoch [122/300], Step [220/384], Loss: 1.5682, LR: 0.000668
[12:19:14] Epoch [122/300], Step [240/384], Loss: 1.9605, LR: 0.000668
[12:19:16] Epoch [122/300], Step [260/384], Loss: 1.8148, LR: 0.000668
[12:19:18] Epoch [122/300], Step [280/384], Loss: 2.0904, LR: 0.000668
[12:19:21] Epoch [122/300], Step [300/384], Loss: 1.2420, LR: 0.000668
[12:19:23] Epoch [122/300], Step [320/384], Loss: 1.7642, LR: 0.000668
[12:19:25] Epoch [122/300], Step [340/384], Loss: 2.1815, LR: 0.000668
[12:19:27] Epoch [122/300], Step [360/384], Loss: 1.7516, LR: 0.000668
[12:19:29] Epoch [122/300], Step [380/384], Loss: 1.8545, LR: 0.000668
[12:19:30] Epoch 122 Complete. Avg Loss: 2.0433, LR: 0.000668
  -> New best model saved (loss: 2.0433)
[12:19:30] Epoch [123/300], Step [0/384], Loss: 2.0035, LR: 0.000663
[12:19:32] Epoch [123/300], Step [20/384], Loss: 1.8396, LR: 0.000663
[12:19:34] Epoch [123/300], Step [40/384], Loss: 1.4733, LR: 0.000663
[12:19:36] Epoch [123/300], Step [60/384], Loss: 1.9603, LR: 0.000663
[12:19:38] Epoch [123/300], Step [80/384], Loss: 1.7574, LR: 0.000663
[12:19:40] Epoch [123/300], Step [100/384], Loss: 2.0699, LR: 0.000663
[12:19:43] Epoch [123/300], Step [120/384], Loss: 1.7581, LR: 0.000663
[12:19:45] Epoch [123/300], Step [140/384], Loss: 2.4377, LR: 0.000663
[12:19:47] Epoch [123/300], Step [160/384], Loss: 2.1373, LR: 0.000663
[12:19:50] Epoch [123/300], Step [180/384], Loss: 1.7882, LR: 0.000663
[12:19:52] Epoch [123/300], Step [200/384], Loss: 2.0511, LR: 0.000663
[12:19:54] Epoch [123/300], Step [220/384], Loss: 2.6944, LR: 0.000663
[12:19:56] Epoch [123/300], Step [240/384], Loss: 2.0350, LR: 0.000663
[12:19:58] Epoch [123/300], Step [260/384], Loss: 2.2331, LR: 0.000663
[12:20:01] Epoch [123/300], Step [280/384], Loss: 1.7020, LR: 0.000663
[12:20:03] Epoch [123/300], Step [300/384], Loss: 1.9594, LR: 0.000663
[12:20:05] Epoch [123/300], Step [320/384], Loss: 1.7478, LR: 0.000663
[12:20:07] Epoch [123/300], Step [340/384], Loss: 1.7321, LR: 0.000663
[12:20:10] Epoch [123/300], Step [360/384], Loss: 2.0533, LR: 0.000663
[12:20:12] Epoch [123/300], Step [380/384], Loss: 2.4576, LR: 0.000663
[12:20:12] Epoch 123 Complete. Avg Loss: 2.0360, LR: 0.000663
  -> New best model saved (loss: 2.0360)
[12:20:12] Epoch [124/300], Step [0/384], Loss: 2.2503, LR: 0.000658
[12:20:14] Epoch [124/300], Step [20/384], Loss: 2.1050, LR: 0.000658
[12:20:17] Epoch [124/300], Step [40/384], Loss: 1.9254, LR: 0.000658
[12:20:19] Epoch [124/300], Step [60/384], Loss: 2.1255, LR: 0.000658
[12:20:21] Epoch [124/300], Step [80/384], Loss: 2.5488, LR: 0.000658
[12:20:23] Epoch [124/300], Step [100/384], Loss: 1.7244, LR: 0.000658
[12:20:25] Epoch [124/300], Step [120/384], Loss: 1.8845, LR: 0.000658
[12:20:27] Epoch [124/300], Step [140/384], Loss: 2.4578, LR: 0.000658
[12:20:29] Epoch [124/300], Step [160/384], Loss: 2.0944, LR: 0.000658
[12:20:31] Epoch [124/300], Step [180/384], Loss: 2.2117, LR: 0.000658
[12:20:34] Epoch [124/300], Step [200/384], Loss: 1.5902, LR: 0.000658
[12:20:36] Epoch [124/300], Step [220/384], Loss: 1.4629, LR: 0.000658
[12:20:38] Epoch [124/300], Step [240/384], Loss: 2.0218, LR: 0.000658
[12:20:40] Epoch [124/300], Step [260/384], Loss: 2.1184, LR: 0.000658
[12:20:42] Epoch [124/300], Step [280/384], Loss: 2.3955, LR: 0.000658
[12:20:45] Epoch [124/300], Step [300/384], Loss: 1.7685, LR: 0.000658
[12:20:47] Epoch [124/300], Step [320/384], Loss: 1.9471, LR: 0.000658
[12:20:49] Epoch [124/300], Step [340/384], Loss: 2.0742, LR: 0.000658
[12:20:51] Epoch [124/300], Step [360/384], Loss: 2.2787, LR: 0.000658
[12:20:54] Epoch [124/300], Step [380/384], Loss: 2.2815, LR: 0.000658
[12:20:54] Epoch 124 Complete. Avg Loss: 2.0179, LR: 0.000658
  -> New best model saved (loss: 2.0179)
[12:20:54] Epoch [125/300], Step [0/384], Loss: 1.9872, LR: 0.000653
[12:20:56] Epoch [125/300], Step [20/384], Loss: 1.9655, LR: 0.000653
[12:20:59] Epoch [125/300], Step [40/384], Loss: 2.1863, LR: 0.000653
[12:21:01] Epoch [125/300], Step [60/384], Loss: 1.9533, LR: 0.000653
[12:21:03] Epoch [125/300], Step [80/384], Loss: 2.0391, LR: 0.000653
[12:21:05] Epoch [125/300], Step [100/384], Loss: 2.1102, LR: 0.000653
[12:21:07] Epoch [125/300], Step [120/384], Loss: 1.9496, LR: 0.000653
[12:21:09] Epoch [125/300], Step [140/384], Loss: 1.9395, LR: 0.000653
[12:21:11] Epoch [125/300], Step [160/384], Loss: 2.4572, LR: 0.000653
[12:21:14] Epoch [125/300], Step [180/384], Loss: 2.4148, LR: 0.000653
[12:21:16] Epoch [125/300], Step [200/384], Loss: 2.2029, LR: 0.000653
[12:21:18] Epoch [125/300], Step [220/384], Loss: 1.9223, LR: 0.000653
[12:21:21] Epoch [125/300], Step [240/384], Loss: 1.8518, LR: 0.000653
[12:21:23] Epoch [125/300], Step [260/384], Loss: 2.1323, LR: 0.000653
[12:21:25] Epoch [125/300], Step [280/384], Loss: 1.8317, LR: 0.000653
[12:21:27] Epoch [125/300], Step [300/384], Loss: 1.6365, LR: 0.000653
[12:21:30] Epoch [125/300], Step [320/384], Loss: 2.3123, LR: 0.000653
[12:21:32] Epoch [125/300], Step [340/384], Loss: 1.9556, LR: 0.000653
[12:21:34] Epoch [125/300], Step [360/384], Loss: 2.1782, LR: 0.000653
[12:21:36] Epoch [125/300], Step [380/384], Loss: 2.7669, LR: 0.000653
[12:21:36] Epoch 125 Complete. Avg Loss: 2.0100, LR: 0.000653
  -> New best model saved (loss: 2.0100)
[12:21:37] Epoch [126/300], Step [0/384], Loss: 2.0279, LR: 0.000648
[12:21:39] Epoch [126/300], Step [20/384], Loss: 1.8704, LR: 0.000648
[12:21:41] Epoch [126/300], Step [40/384], Loss: 1.9593, LR: 0.000648
[12:21:43] Epoch [126/300], Step [60/384], Loss: 2.4725, LR: 0.000648
[12:21:45] Epoch [126/300], Step [80/384], Loss: 1.9346, LR: 0.000648
[12:21:48] Epoch [126/300], Step [100/384], Loss: 2.0484, LR: 0.000648
[12:21:50] Epoch [126/300], Step [120/384], Loss: 2.2335, LR: 0.000648
[12:21:52] Epoch [126/300], Step [140/384], Loss: 1.9820, LR: 0.000648
[12:21:54] Epoch [126/300], Step [160/384], Loss: 1.7145, LR: 0.000648
[12:21:57] Epoch [126/300], Step [180/384], Loss: 1.9687, LR: 0.000648
[12:21:59] Epoch [126/300], Step [200/384], Loss: 2.3879, LR: 0.000648
[12:22:01] Epoch [126/300], Step [220/384], Loss: 1.7345, LR: 0.000648
[12:22:03] Epoch [126/300], Step [240/384], Loss: 2.7428, LR: 0.000648
[12:22:05] Epoch [126/300], Step [260/384], Loss: 1.7794, LR: 0.000648
[12:22:08] Epoch [126/300], Step [280/384], Loss: 2.0759, LR: 0.000648
[12:22:10] Epoch [126/300], Step [300/384], Loss: 1.7206, LR: 0.000648
[12:22:12] Epoch [126/300], Step [320/384], Loss: 1.5504, LR: 0.000648
[12:22:14] Epoch [126/300], Step [340/384], Loss: 1.6423, LR: 0.000648
[12:22:16] Epoch [126/300], Step [360/384], Loss: 1.6623, LR: 0.000648
[12:22:19] Epoch [126/300], Step [380/384], Loss: 2.0829, LR: 0.000648
[12:22:19] Epoch 126 Complete. Avg Loss: 2.0097, LR: 0.000648
  -> New best model saved (loss: 2.0097)
[12:22:19] Epoch [127/300], Step [0/384], Loss: 1.8815, LR: 0.000643
[12:22:21] Epoch [127/300], Step [20/384], Loss: 1.8635, LR: 0.000643
[12:22:24] Epoch [127/300], Step [40/384], Loss: 1.8856, LR: 0.000643
[12:22:26] Epoch [127/300], Step [60/384], Loss: 1.8044, LR: 0.000643
[12:22:28] Epoch [127/300], Step [80/384], Loss: 1.6995, LR: 0.000643
[12:22:31] Epoch [127/300], Step [100/384], Loss: 2.1562, LR: 0.000643
[12:22:33] Epoch [127/300], Step [120/384], Loss: 2.1208, LR: 0.000643
[12:22:35] Epoch [127/300], Step [140/384], Loss: 2.1753, LR: 0.000643
[12:22:37] Epoch [127/300], Step [160/384], Loss: 2.1803, LR: 0.000643
[12:22:39] Epoch [127/300], Step [180/384], Loss: 2.0427, LR: 0.000643
[12:22:42] Epoch [127/300], Step [200/384], Loss: 1.8272, LR: 0.000643
[12:22:44] Epoch [127/300], Step [220/384], Loss: 2.1307, LR: 0.000643
[12:22:46] Epoch [127/300], Step [240/384], Loss: 2.3153, LR: 0.000643
[12:22:48] Epoch [127/300], Step [260/384], Loss: 2.5131, LR: 0.000643
[12:22:50] Epoch [127/300], Step [280/384], Loss: 2.2905, LR: 0.000643
[12:22:52] Epoch [127/300], Step [300/384], Loss: 1.7953, LR: 0.000643
[12:22:54] Epoch [127/300], Step [320/384], Loss: 3.1724, LR: 0.000643
[12:22:57] Epoch [127/300], Step [340/384], Loss: 2.1444, LR: 0.000643
[12:22:59] Epoch [127/300], Step [360/384], Loss: 1.7284, LR: 0.000643
[12:23:01] Epoch [127/300], Step [380/384], Loss: 2.3721, LR: 0.000643
[12:23:01] Epoch 127 Complete. Avg Loss: 2.0106, LR: 0.000643
[12:23:01] Epoch [128/300], Step [0/384], Loss: 2.2855, LR: 0.000638
[12:23:04] Epoch [128/300], Step [20/384], Loss: 1.9941, LR: 0.000638
[12:23:06] Epoch [128/300], Step [40/384], Loss: 1.8919, LR: 0.000638
[12:23:08] Epoch [128/300], Step [60/384], Loss: 2.1996, LR: 0.000638
[12:23:10] Epoch [128/300], Step [80/384], Loss: 2.0446, LR: 0.000638
[12:23:12] Epoch [128/300], Step [100/384], Loss: 2.9682, LR: 0.000638
[12:23:15] Epoch [128/300], Step [120/384], Loss: 2.2319, LR: 0.000638
[12:23:17] Epoch [128/300], Step [140/384], Loss: 2.0293, LR: 0.000638
[12:23:19] Epoch [128/300], Step [160/384], Loss: 1.3238, LR: 0.000638
[12:23:21] Epoch [128/300], Step [180/384], Loss: 2.5957, LR: 0.000638
[12:23:23] Epoch [128/300], Step [200/384], Loss: 2.3017, LR: 0.000638
[12:23:26] Epoch [128/300], Step [220/384], Loss: 1.9872, LR: 0.000638
[12:23:28] Epoch [128/300], Step [240/384], Loss: 2.2431, LR: 0.000638
[12:23:30] Epoch [128/300], Step [260/384], Loss: 2.1322, LR: 0.000638
[12:23:32] Epoch [128/300], Step [280/384], Loss: 2.4545, LR: 0.000638
[12:23:35] Epoch [128/300], Step [300/384], Loss: 1.3787, LR: 0.000638
[12:23:37] Epoch [128/300], Step [320/384], Loss: 2.0708, LR: 0.000638
[12:23:39] Epoch [128/300], Step [340/384], Loss: 2.2368, LR: 0.000638
[12:23:41] Epoch [128/300], Step [360/384], Loss: 2.2152, LR: 0.000638
[12:23:43] Epoch [128/300], Step [380/384], Loss: 2.1058, LR: 0.000638
[12:23:43] Epoch 128 Complete. Avg Loss: 1.9934, LR: 0.000638
  -> New best model saved (loss: 1.9934)
[12:23:44] Epoch [129/300], Step [0/384], Loss: 1.7409, LR: 0.000633
[12:23:46] Epoch [129/300], Step [20/384], Loss: 2.3585, LR: 0.000633
[12:23:48] Epoch [129/300], Step [40/384], Loss: 1.6285, LR: 0.000633
[12:23:50] Epoch [129/300], Step [60/384], Loss: 1.5839, LR: 0.000633
[12:23:52] Epoch [129/300], Step [80/384], Loss: 1.8816, LR: 0.000633
[12:23:55] Epoch [129/300], Step [100/384], Loss: 1.9478, LR: 0.000633
[12:23:57] Epoch [129/300], Step [120/384], Loss: 1.6060, LR: 0.000633
[12:23:59] Epoch [129/300], Step [140/384], Loss: 2.1815, LR: 0.000633
[12:24:01] Epoch [129/300], Step [160/384], Loss: 2.3253, LR: 0.000633
[12:24:03] Epoch [129/300], Step [180/384], Loss: 1.8650, LR: 0.000633
[12:24:05] Epoch [129/300], Step [200/384], Loss: 2.6391, LR: 0.000633
[12:24:08] Epoch [129/300], Step [220/384], Loss: 1.6375, LR: 0.000633
[12:24:10] Epoch [129/300], Step [240/384], Loss: 1.9903, LR: 0.000633
[12:24:12] Epoch [129/300], Step [260/384], Loss: 2.3014, LR: 0.000633
[12:24:14] Epoch [129/300], Step [280/384], Loss: 1.7612, LR: 0.000633
[12:24:16] Epoch [129/300], Step [300/384], Loss: 2.1135, LR: 0.000633
[12:24:19] Epoch [129/300], Step [320/384], Loss: 1.3790, LR: 0.000633
[12:24:21] Epoch [129/300], Step [340/384], Loss: 1.7236, LR: 0.000633
[12:24:23] Epoch [129/300], Step [360/384], Loss: 1.8734, LR: 0.000633
[12:24:25] Epoch [129/300], Step [380/384], Loss: 1.5629, LR: 0.000633
[12:24:26] Epoch 129 Complete. Avg Loss: 1.9952, LR: 0.000633
[12:24:26] Epoch [130/300], Step [0/384], Loss: 1.9892, LR: 0.000628
[12:24:28] Epoch [130/300], Step [20/384], Loss: 2.3910, LR: 0.000628
[12:24:30] Epoch [130/300], Step [40/384], Loss: 1.6577, LR: 0.000628
[12:24:32] Epoch [130/300], Step [60/384], Loss: 2.4444, LR: 0.000628
[12:24:35] Epoch [130/300], Step [80/384], Loss: 1.4774, LR: 0.000628
[12:24:37] Epoch [130/300], Step [100/384], Loss: 2.2218, LR: 0.000628
[12:24:39] Epoch [130/300], Step [120/384], Loss: 2.2177, LR: 0.000628
[12:24:41] Epoch [130/300], Step [140/384], Loss: 1.8239, LR: 0.000628
[12:24:44] Epoch [130/300], Step [160/384], Loss: 1.7363, LR: 0.000628
[12:24:46] Epoch [130/300], Step [180/384], Loss: 1.9268, LR: 0.000628
[12:24:48] Epoch [130/300], Step [200/384], Loss: 2.0890, LR: 0.000628
[12:24:50] Epoch [130/300], Step [220/384], Loss: 2.0082, LR: 0.000628
[12:24:52] Epoch [130/300], Step [240/384], Loss: 1.9312, LR: 0.000628
[12:24:54] Epoch [130/300], Step [260/384], Loss: 2.0921, LR: 0.000628
[12:24:56] Epoch [130/300], Step [280/384], Loss: 2.0890, LR: 0.000628
[12:24:58] Epoch [130/300], Step [300/384], Loss: 1.5898, LR: 0.000628
[12:25:00] Epoch [130/300], Step [320/384], Loss: 2.1081, LR: 0.000628
[12:25:03] Epoch [130/300], Step [340/384], Loss: 2.0293, LR: 0.000628
[12:25:05] Epoch [130/300], Step [360/384], Loss: 2.0310, LR: 0.000628
[12:25:07] Epoch [130/300], Step [380/384], Loss: 2.2112, LR: 0.000628
[12:25:07] Epoch 130 Complete. Avg Loss: 1.9791, LR: 0.000628
  -> New best model saved (loss: 1.9791)
[12:25:07] Epoch [131/300], Step [0/384], Loss: 1.8383, LR: 0.000622
[12:25:10] Epoch [131/300], Step [20/384], Loss: 1.5956, LR: 0.000622
[12:25:12] Epoch [131/300], Step [40/384], Loss: 2.2462, LR: 0.000622
[12:25:14] Epoch [131/300], Step [60/384], Loss: 2.1498, LR: 0.000622
[12:25:16] Epoch [131/300], Step [80/384], Loss: 1.8239, LR: 0.000622
[12:25:18] Epoch [131/300], Step [100/384], Loss: 1.8766, LR: 0.000622
[12:25:21] Epoch [131/300], Step [120/384], Loss: 1.5797, LR: 0.000622
[12:25:23] Epoch [131/300], Step [140/384], Loss: 1.8841, LR: 0.000622
[12:25:25] Epoch [131/300], Step [160/384], Loss: 2.6638, LR: 0.000622
[12:25:27] Epoch [131/300], Step [180/384], Loss: 1.4824, LR: 0.000622
[12:25:30] Epoch [131/300], Step [200/384], Loss: 1.9304, LR: 0.000622
[12:25:32] Epoch [131/300], Step [220/384], Loss: 1.9130, LR: 0.000622
[12:25:34] Epoch [131/300], Step [240/384], Loss: 1.7540, LR: 0.000622
[12:25:36] Epoch [131/300], Step [260/384], Loss: 2.1414, LR: 0.000622
[12:25:38] Epoch [131/300], Step [280/384], Loss: 2.2003, LR: 0.000622
[12:25:40] Epoch [131/300], Step [300/384], Loss: 1.7214, LR: 0.000622
[12:25:42] Epoch [131/300], Step [320/384], Loss: 1.8788, LR: 0.000622
[12:25:45] Epoch [131/300], Step [340/384], Loss: 1.5626, LR: 0.000622
[12:25:47] Epoch [131/300], Step [360/384], Loss: 1.8656, LR: 0.000622
[12:25:49] Epoch [131/300], Step [380/384], Loss: 1.5966, LR: 0.000622
[12:25:49] Epoch 131 Complete. Avg Loss: 1.9819, LR: 0.000622
[12:25:49] Epoch [132/300], Step [0/384], Loss: 1.8352, LR: 0.000617
[12:25:51] Epoch [132/300], Step [20/384], Loss: 1.3752, LR: 0.000617
[12:25:54] Epoch [132/300], Step [40/384], Loss: 2.4542, LR: 0.000617
[12:25:56] Epoch [132/300], Step [60/384], Loss: 1.8364, LR: 0.000617
[12:25:58] Epoch [132/300], Step [80/384], Loss: 1.5835, LR: 0.000617
[12:26:00] Epoch [132/300], Step [100/384], Loss: 2.2772, LR: 0.000617
[12:26:02] Epoch [132/300], Step [120/384], Loss: 2.1646, LR: 0.000617
[12:26:05] Epoch [132/300], Step [140/384], Loss: 2.1882, LR: 0.000617
[12:26:07] Epoch [132/300], Step [160/384], Loss: 2.0095, LR: 0.000617
[12:26:09] Epoch [132/300], Step [180/384], Loss: 2.9896, LR: 0.000617
[12:26:11] Epoch [132/300], Step [200/384], Loss: 2.0667, LR: 0.000617
[12:26:13] Epoch [132/300], Step [220/384], Loss: 1.9945, LR: 0.000617
[12:26:15] Epoch [132/300], Step [240/384], Loss: 2.1125, LR: 0.000617
[12:26:17] Epoch [132/300], Step [260/384], Loss: 2.0425, LR: 0.000617
[12:26:20] Epoch [132/300], Step [280/384], Loss: 1.9905, LR: 0.000617
[12:26:22] Epoch [132/300], Step [300/384], Loss: 1.8966, LR: 0.000617
[12:26:24] Epoch [132/300], Step [320/384], Loss: 1.3719, LR: 0.000617
[12:26:27] Epoch [132/300], Step [340/384], Loss: 2.2678, LR: 0.000617
[12:26:29] Epoch [132/300], Step [360/384], Loss: 1.7034, LR: 0.000617
[12:26:31] Epoch [132/300], Step [380/384], Loss: 1.7048, LR: 0.000617
[12:26:31] Epoch 132 Complete. Avg Loss: 1.9789, LR: 0.000617
  -> New best model saved (loss: 1.9789)
[12:26:31] Epoch [133/300], Step [0/384], Loss: 2.2206, LR: 0.000612
[12:26:33] Epoch [133/300], Step [20/384], Loss: 1.7950, LR: 0.000612
[12:26:35] Epoch [133/300], Step [40/384], Loss: 1.7568, LR: 0.000612
[12:26:38] Epoch [133/300], Step [60/384], Loss: 2.0167, LR: 0.000612
[12:26:40] Epoch [133/300], Step [80/384], Loss: 1.8650, LR: 0.000612
[12:26:42] Epoch [133/300], Step [100/384], Loss: 2.2538, LR: 0.000612
[12:26:44] Epoch [133/300], Step [120/384], Loss: 1.9171, LR: 0.000612
[12:26:46] Epoch [133/300], Step [140/384], Loss: 1.3922, LR: 0.000612
[12:26:48] Epoch [133/300], Step [160/384], Loss: 2.1074, LR: 0.000612
[12:26:50] Epoch [133/300], Step [180/384], Loss: 2.1707, LR: 0.000612
[12:26:53] Epoch [133/300], Step [200/384], Loss: 1.6926, LR: 0.000612
[12:26:55] Epoch [133/300], Step [220/384], Loss: 2.0922, LR: 0.000612
[12:26:57] Epoch [133/300], Step [240/384], Loss: 1.8304, LR: 0.000612
[12:27:00] Epoch [133/300], Step [260/384], Loss: 1.7048, LR: 0.000612
[12:27:02] Epoch [133/300], Step [280/384], Loss: 1.8097, LR: 0.000612
[12:27:04] Epoch [133/300], Step [300/384], Loss: 2.1446, LR: 0.000612
[12:27:07] Epoch [133/300], Step [320/384], Loss: 1.5576, LR: 0.000612
[12:27:09] Epoch [133/300], Step [340/384], Loss: 1.8351, LR: 0.000612
[12:27:11] Epoch [133/300], Step [360/384], Loss: 1.6266, LR: 0.000612
[12:27:14] Epoch [133/300], Step [380/384], Loss: 1.7208, LR: 0.000612
[12:27:14] Epoch 133 Complete. Avg Loss: 1.9824, LR: 0.000612
[12:27:14] Epoch [134/300], Step [0/384], Loss: 1.6465, LR: 0.000607
[12:27:16] Epoch [134/300], Step [20/384], Loss: 1.6203, LR: 0.000607
[12:27:19] Epoch [134/300], Step [40/384], Loss: 1.8089, LR: 0.000607
[12:27:21] Epoch [134/300], Step [60/384], Loss: 1.7361, LR: 0.000607
[12:27:23] Epoch [134/300], Step [80/384], Loss: 1.7796, LR: 0.000607
[12:27:25] Epoch [134/300], Step [100/384], Loss: 1.5906, LR: 0.000607
[12:27:27] Epoch [134/300], Step [120/384], Loss: 2.4094, LR: 0.000607
[12:27:30] Epoch [134/300], Step [140/384], Loss: 2.4243, LR: 0.000607
[12:27:32] Epoch [134/300], Step [160/384], Loss: 1.8426, LR: 0.000607
[12:27:34] Epoch [134/300], Step [180/384], Loss: 1.5840, LR: 0.000607
[12:27:36] Epoch [134/300], Step [200/384], Loss: 1.9810, LR: 0.000607
[12:27:38] Epoch [134/300], Step [220/384], Loss: 1.9349, LR: 0.000607
[12:27:40] Epoch [134/300], Step [240/384], Loss: 2.0529, LR: 0.000607
[12:27:42] Epoch [134/300], Step [260/384], Loss: 2.3371, LR: 0.000607
[12:27:44] Epoch [134/300], Step [280/384], Loss: 1.8399, LR: 0.000607
[12:27:47] Epoch [134/300], Step [300/384], Loss: 2.4037, LR: 0.000607
[12:27:49] Epoch [134/300], Step [320/384], Loss: 1.4183, LR: 0.000607
[12:27:51] Epoch [134/300], Step [340/384], Loss: 1.7335, LR: 0.000607
[12:27:53] Epoch [134/300], Step [360/384], Loss: 2.3424, LR: 0.000607
[12:27:56] Epoch [134/300], Step [380/384], Loss: 1.5994, LR: 0.000607
[12:27:56] Epoch 134 Complete. Avg Loss: 1.9365, LR: 0.000607
  -> New best model saved (loss: 1.9365)
[12:27:56] Epoch [135/300], Step [0/384], Loss: 2.7529, LR: 0.000602
[12:27:59] Epoch [135/300], Step [20/384], Loss: 1.6511, LR: 0.000602
[12:28:01] Epoch [135/300], Step [40/384], Loss: 1.6927, LR: 0.000602
[12:28:03] Epoch [135/300], Step [60/384], Loss: 2.1310, LR: 0.000602
[12:28:05] Epoch [135/300], Step [80/384], Loss: 1.9739, LR: 0.000602
[12:28:07] Epoch [135/300], Step [100/384], Loss: 2.7279, LR: 0.000602
[12:28:09] Epoch [135/300], Step [120/384], Loss: 1.5625, LR: 0.000602
[12:28:12] Epoch [135/300], Step [140/384], Loss: 2.0056, LR: 0.000602
[12:28:14] Epoch [135/300], Step [160/384], Loss: 1.7835, LR: 0.000602
[12:28:16] Epoch [135/300], Step [180/384], Loss: 1.7112, LR: 0.000602
[12:28:18] Epoch [135/300], Step [200/384], Loss: 1.9736, LR: 0.000602
[12:28:20] Epoch [135/300], Step [220/384], Loss: 2.1810, LR: 0.000602
[12:28:22] Epoch [135/300], Step [240/384], Loss: 1.5234, LR: 0.000602
[12:28:25] Epoch [135/300], Step [260/384], Loss: 2.2626, LR: 0.000602
[12:28:27] Epoch [135/300], Step [280/384], Loss: 1.8342, LR: 0.000602
[12:28:29] Epoch [135/300], Step [300/384], Loss: 2.2162, LR: 0.000602
[12:28:31] Epoch [135/300], Step [320/384], Loss: 1.9860, LR: 0.000602
[12:28:34] Epoch [135/300], Step [340/384], Loss: 2.0964, LR: 0.000602
[12:28:36] Epoch [135/300], Step [360/384], Loss: 1.5269, LR: 0.000602
[12:28:38] Epoch [135/300], Step [380/384], Loss: 2.2763, LR: 0.000602
[12:28:39] Epoch 135 Complete. Avg Loss: 1.9524, LR: 0.000602
[12:28:39] Epoch [136/300], Step [0/384], Loss: 1.4394, LR: 0.000597
[12:28:41] Epoch [136/300], Step [20/384], Loss: 2.2422, LR: 0.000597
[12:28:43] Epoch [136/300], Step [40/384], Loss: 2.1347, LR: 0.000597
[12:28:46] Epoch [136/300], Step [60/384], Loss: 1.8435, LR: 0.000597
[12:28:48] Epoch [136/300], Step [80/384], Loss: 1.9390, LR: 0.000597
[12:28:50] Epoch [136/300], Step [100/384], Loss: 1.8674, LR: 0.000597
[12:28:52] Epoch [136/300], Step [120/384], Loss: 1.9837, LR: 0.000597
[12:28:54] Epoch [136/300], Step [140/384], Loss: 1.6234, LR: 0.000597
[12:28:56] Epoch [136/300], Step [160/384], Loss: 2.3361, LR: 0.000597
[12:28:58] Epoch [136/300], Step [180/384], Loss: 1.5273, LR: 0.000597
[12:29:01] Epoch [136/300], Step [200/384], Loss: 1.7820, LR: 0.000597
[12:29:03] Epoch [136/300], Step [220/384], Loss: 2.1510, LR: 0.000597
[12:29:05] Epoch [136/300], Step [240/384], Loss: 1.8997, LR: 0.000597
[12:29:07] Epoch [136/300], Step [260/384], Loss: 1.8538, LR: 0.000597
[12:29:10] Epoch [136/300], Step [280/384], Loss: 2.0634, LR: 0.000597
[12:29:12] Epoch [136/300], Step [300/384], Loss: 2.2309, LR: 0.000597
[12:29:14] Epoch [136/300], Step [320/384], Loss: 2.5322, LR: 0.000597
[12:29:16] Epoch [136/300], Step [340/384], Loss: 2.1957, LR: 0.000597
[12:29:18] Epoch [136/300], Step [360/384], Loss: 1.6944, LR: 0.000597
[12:29:20] Epoch [136/300], Step [380/384], Loss: 2.0335, LR: 0.000597
[12:29:21] Epoch 136 Complete. Avg Loss: 1.9393, LR: 0.000597
[12:29:21] Epoch [137/300], Step [0/384], Loss: 1.9281, LR: 0.000592
[12:29:23] Epoch [137/300], Step [20/384], Loss: 2.2782, LR: 0.000592
[12:29:26] Epoch [137/300], Step [40/384], Loss: 2.0417, LR: 0.000592
[12:29:28] Epoch [137/300], Step [60/384], Loss: 2.0405, LR: 0.000592
[12:29:30] Epoch [137/300], Step [80/384], Loss: 2.0083, LR: 0.000592
[12:29:32] Epoch [137/300], Step [100/384], Loss: 1.8509, LR: 0.000592
[12:29:34] Epoch [137/300], Step [120/384], Loss: 2.1000, LR: 0.000592
[12:29:36] Epoch [137/300], Step [140/384], Loss: 1.5353, LR: 0.000592
[12:29:38] Epoch [137/300], Step [160/384], Loss: 1.7964, LR: 0.000592
[12:29:40] Epoch [137/300], Step [180/384], Loss: 1.5681, LR: 0.000592
[12:29:43] Epoch [137/300], Step [200/384], Loss: 2.1720, LR: 0.000592
[12:29:45] Epoch [137/300], Step [220/384], Loss: 1.9051, LR: 0.000592
[12:29:47] Epoch [137/300], Step [240/384], Loss: 2.1231, LR: 0.000592
[12:29:49] Epoch [137/300], Step [260/384], Loss: 1.9900, LR: 0.000592
[12:29:52] Epoch [137/300], Step [280/384], Loss: 2.0158, LR: 0.000592
[12:29:54] Epoch [137/300], Step [300/384], Loss: 1.6946, LR: 0.000592
[12:29:56] Epoch [137/300], Step [320/384], Loss: 1.5168, LR: 0.000592
[12:29:58] Epoch [137/300], Step [340/384], Loss: 1.9163, LR: 0.000592
[12:30:00] Epoch [137/300], Step [360/384], Loss: 1.7120, LR: 0.000592
[12:30:02] Epoch [137/300], Step [380/384], Loss: 1.3703, LR: 0.000592
[12:30:03] Epoch 137 Complete. Avg Loss: 1.9372, LR: 0.000592
[12:30:03] Epoch [138/300], Step [0/384], Loss: 1.8903, LR: 0.000586
[12:30:05] Epoch [138/300], Step [20/384], Loss: 2.0501, LR: 0.000586
[12:30:07] Epoch [138/300], Step [40/384], Loss: 2.1088, LR: 0.000586
[12:30:09] Epoch [138/300], Step [60/384], Loss: 1.7348, LR: 0.000586
[12:30:11] Epoch [138/300], Step [80/384], Loss: 1.9597, LR: 0.000586
[12:30:14] Epoch [138/300], Step [100/384], Loss: 1.9239, LR: 0.000586
[12:30:16] Epoch [138/300], Step [120/384], Loss: 1.6628, LR: 0.000586
[12:30:19] Epoch [138/300], Step [140/384], Loss: 1.6646, LR: 0.000586
[12:30:21] Epoch [138/300], Step [160/384], Loss: 1.8530, LR: 0.000586
[12:30:23] Epoch [138/300], Step [180/384], Loss: 2.2717, LR: 0.000586
[12:30:25] Epoch [138/300], Step [200/384], Loss: 1.7412, LR: 0.000586
[12:30:27] Epoch [138/300], Step [220/384], Loss: 1.4266, LR: 0.000586
[12:30:29] Epoch [138/300], Step [240/384], Loss: 2.4729, LR: 0.000586
[12:30:31] Epoch [138/300], Step [260/384], Loss: 1.8934, LR: 0.000586
[12:30:33] Epoch [138/300], Step [280/384], Loss: 1.7286, LR: 0.000586
[12:30:35] Epoch [138/300], Step [300/384], Loss: 1.5468, LR: 0.000586
[12:30:38] Epoch [138/300], Step [320/384], Loss: 2.7271, LR: 0.000586
[12:30:40] Epoch [138/300], Step [340/384], Loss: 1.7546, LR: 0.000586
[12:30:42] Epoch [138/300], Step [360/384], Loss: 1.7639, LR: 0.000586
[12:30:44] Epoch [138/300], Step [380/384], Loss: 1.9626, LR: 0.000586
[12:30:44] Epoch 138 Complete. Avg Loss: 1.9330, LR: 0.000586
  -> New best model saved (loss: 1.9330)
[12:30:45] Epoch [139/300], Step [0/384], Loss: 1.8963, LR: 0.000581
[12:30:47] Epoch [139/300], Step [20/384], Loss: 2.2148, LR: 0.000581
[12:30:49] Epoch [139/300], Step [40/384], Loss: 1.7516, LR: 0.000581
[12:30:51] Epoch [139/300], Step [60/384], Loss: 1.6897, LR: 0.000581
[12:30:54] Epoch [139/300], Step [80/384], Loss: 2.0962, LR: 0.000581
[12:30:56] Epoch [139/300], Step [100/384], Loss: 1.6180, LR: 0.000581
[12:30:58] Epoch [139/300], Step [120/384], Loss: 1.3817, LR: 0.000581
[12:31:00] Epoch [139/300], Step [140/384], Loss: 1.9693, LR: 0.000581
[12:31:02] Epoch [139/300], Step [160/384], Loss: 2.2157, LR: 0.000581
[12:31:04] Epoch [139/300], Step [180/384], Loss: 2.2325, LR: 0.000581
[12:31:07] Epoch [139/300], Step [200/384], Loss: 2.2383, LR: 0.000581
[12:31:09] Epoch [139/300], Step [220/384], Loss: 1.8647, LR: 0.000581
[12:31:11] Epoch [139/300], Step [240/384], Loss: 1.7321, LR: 0.000581
[12:31:13] Epoch [139/300], Step [260/384], Loss: 1.5940, LR: 0.000581
[12:31:16] Epoch [139/300], Step [280/384], Loss: 2.4775, LR: 0.000581
[12:31:18] Epoch [139/300], Step [300/384], Loss: 2.0056, LR: 0.000581
[12:31:20] Epoch [139/300], Step [320/384], Loss: 1.5631, LR: 0.000581
[12:31:22] Epoch [139/300], Step [340/384], Loss: 1.6849, LR: 0.000581
[12:31:24] Epoch [139/300], Step [360/384], Loss: 1.5669, LR: 0.000581
[12:31:26] Epoch [139/300], Step [380/384], Loss: 1.8003, LR: 0.000581
[12:31:26] Epoch 139 Complete. Avg Loss: 1.9303, LR: 0.000581
  -> New best model saved (loss: 1.9303)
[12:31:27] Epoch [140/300], Step [0/384], Loss: 2.1191, LR: 0.000576
[12:31:29] Epoch [140/300], Step [20/384], Loss: 2.4569, LR: 0.000576
[12:31:31] Epoch [140/300], Step [40/384], Loss: 1.8013, LR: 0.000576
[12:31:34] Epoch [140/300], Step [60/384], Loss: 1.7119, LR: 0.000576
[12:31:36] Epoch [140/300], Step [80/384], Loss: 1.6630, LR: 0.000576
[12:31:38] Epoch [140/300], Step [100/384], Loss: 2.2713, LR: 0.000576
[12:31:40] Epoch [140/300], Step [120/384], Loss: 2.2584, LR: 0.000576
[12:31:42] Epoch [140/300], Step [140/384], Loss: 1.6378, LR: 0.000576
[12:31:45] Epoch [140/300], Step [160/384], Loss: 2.1006, LR: 0.000576
[12:31:47] Epoch [140/300], Step [180/384], Loss: 1.8856, LR: 0.000576
[12:31:49] Epoch [140/300], Step [200/384], Loss: 1.9421, LR: 0.000576
[12:31:51] Epoch [140/300], Step [220/384], Loss: 1.8666, LR: 0.000576
[12:31:53] Epoch [140/300], Step [240/384], Loss: 1.7877, LR: 0.000576
[12:31:55] Epoch [140/300], Step [260/384], Loss: 2.2400, LR: 0.000576
[12:31:58] Epoch [140/300], Step [280/384], Loss: 2.2493, LR: 0.000576
[12:32:00] Epoch [140/300], Step [300/384], Loss: 2.1067, LR: 0.000576
[12:32:02] Epoch [140/300], Step [320/384], Loss: 1.5463, LR: 0.000576
[12:32:04] Epoch [140/300], Step [340/384], Loss: 1.7200, LR: 0.000576
[12:32:07] Epoch [140/300], Step [360/384], Loss: 1.9200, LR: 0.000576
[12:32:09] Epoch [140/300], Step [380/384], Loss: 2.0400, LR: 0.000576
[12:32:09] Epoch 140 Complete. Avg Loss: 1.9207, LR: 0.000576
  -> New best model saved (loss: 1.9207)
[12:32:09] Epoch [141/300], Step [0/384], Loss: 1.8678, LR: 0.000571
[12:32:12] Epoch [141/300], Step [20/384], Loss: 1.9620, LR: 0.000571
[12:32:14] Epoch [141/300], Step [40/384], Loss: 1.6592, LR: 0.000571
[12:32:16] Epoch [141/300], Step [60/384], Loss: 1.7792, LR: 0.000571
[12:32:18] Epoch [141/300], Step [80/384], Loss: 1.7730, LR: 0.000571
[12:32:20] Epoch [141/300], Step [100/384], Loss: 1.8657, LR: 0.000571
[12:32:23] Epoch [141/300], Step [120/384], Loss: 1.9105, LR: 0.000571
[12:32:25] Epoch [141/300], Step [140/384], Loss: 1.6956, LR: 0.000571
[12:32:27] Epoch [141/300], Step [160/384], Loss: 1.8583, LR: 0.000571
[12:32:29] Epoch [141/300], Step [180/384], Loss: 1.7085, LR: 0.000571
[12:32:32] Epoch [141/300], Step [200/384], Loss: 1.6258, LR: 0.000571
[12:32:34] Epoch [141/300], Step [220/384], Loss: 2.0327, LR: 0.000571
[12:32:36] Epoch [141/300], Step [240/384], Loss: 1.4160, LR: 0.000571
[12:32:38] Epoch [141/300], Step [260/384], Loss: 1.9721, LR: 0.000571
[12:32:41] Epoch [141/300], Step [280/384], Loss: 1.9563, LR: 0.000571
[12:32:43] Epoch [141/300], Step [300/384], Loss: 1.8236, LR: 0.000571
[12:32:45] Epoch [141/300], Step [320/384], Loss: 2.1120, LR: 0.000571
[12:32:47] Epoch [141/300], Step [340/384], Loss: 2.0698, LR: 0.000571
[12:32:49] Epoch [141/300], Step [360/384], Loss: 2.2769, LR: 0.000571
[12:32:51] Epoch [141/300], Step [380/384], Loss: 1.5567, LR: 0.000571
[12:32:52] Epoch 141 Complete. Avg Loss: 1.9092, LR: 0.000571
  -> New best model saved (loss: 1.9092)
[12:32:52] Epoch [142/300], Step [0/384], Loss: 2.0012, LR: 0.000565
[12:32:54] Epoch [142/300], Step [20/384], Loss: 1.9659, LR: 0.000565
[12:32:56] Epoch [142/300], Step [40/384], Loss: 2.1132, LR: 0.000565
[12:32:58] Epoch [142/300], Step [60/384], Loss: 1.7753, LR: 0.000565
[12:33:00] Epoch [142/300], Step [80/384], Loss: 2.1236, LR: 0.000565
[12:33:02] Epoch [142/300], Step [100/384], Loss: 2.4814, LR: 0.000565
[12:33:05] Epoch [142/300], Step [120/384], Loss: 2.8630, LR: 0.000565
[12:33:07] Epoch [142/300], Step [140/384], Loss: 1.9420, LR: 0.000565
[12:33:09] Epoch [142/300], Step [160/384], Loss: 1.5764, LR: 0.000565
[12:33:11] Epoch [142/300], Step [180/384], Loss: 2.0381, LR: 0.000565
[12:33:13] Epoch [142/300], Step [200/384], Loss: 2.1245, LR: 0.000565
[12:33:16] Epoch [142/300], Step [220/384], Loss: 2.0159, LR: 0.000565
[12:33:18] Epoch [142/300], Step [240/384], Loss: 1.6260, LR: 0.000565
[12:33:20] Epoch [142/300], Step [260/384], Loss: 2.6562, LR: 0.000565
[12:33:23] Epoch [142/300], Step [280/384], Loss: 1.8173, LR: 0.000565
[12:33:25] Epoch [142/300], Step [300/384], Loss: 1.7065, LR: 0.000565
[12:33:27] Epoch [142/300], Step [320/384], Loss: 2.0820, LR: 0.000565
[12:33:29] Epoch [142/300], Step [340/384], Loss: 2.8817, LR: 0.000565
[12:33:31] Epoch [142/300], Step [360/384], Loss: 2.4251, LR: 0.000565
[12:33:34] Epoch [142/300], Step [380/384], Loss: 1.8354, LR: 0.000565
[12:33:34] Epoch 142 Complete. Avg Loss: 1.9128, LR: 0.000565
[12:33:34] Epoch [143/300], Step [0/384], Loss: 1.4761, LR: 0.000560
[12:33:36] Epoch [143/300], Step [20/384], Loss: 2.0815, LR: 0.000560
[12:33:39] Epoch [143/300], Step [40/384], Loss: 1.7770, LR: 0.000560
[12:33:41] Epoch [143/300], Step [60/384], Loss: 1.5507, LR: 0.000560
[12:33:43] Epoch [143/300], Step [80/384], Loss: 2.2121, LR: 0.000560
[12:33:45] Epoch [143/300], Step [100/384], Loss: 2.0532, LR: 0.000560
[12:33:47] Epoch [143/300], Step [120/384], Loss: 1.5557, LR: 0.000560
[12:33:50] Epoch [143/300], Step [140/384], Loss: 1.7499, LR: 0.000560
[12:33:52] Epoch [143/300], Step [160/384], Loss: 1.7353, LR: 0.000560
[12:33:54] Epoch [143/300], Step [180/384], Loss: 1.7752, LR: 0.000560
[12:33:56] Epoch [143/300], Step [200/384], Loss: 1.3575, LR: 0.000560
[12:33:58] Epoch [143/300], Step [220/384], Loss: 1.7070, LR: 0.000560
[12:34:00] Epoch [143/300], Step [240/384], Loss: 1.7299, LR: 0.000560
[12:34:02] Epoch [143/300], Step [260/384], Loss: 1.5977, LR: 0.000560
[12:34:05] Epoch [143/300], Step [280/384], Loss: 1.6936, LR: 0.000560
[12:34:07] Epoch [143/300], Step [300/384], Loss: 1.9784, LR: 0.000560
[12:34:09] Epoch [143/300], Step [320/384], Loss: 1.5032, LR: 0.000560
[12:34:11] Epoch [143/300], Step [340/384], Loss: 1.9500, LR: 0.000560
[12:34:13] Epoch [143/300], Step [360/384], Loss: 2.1039, LR: 0.000560
[12:34:16] Epoch [143/300], Step [380/384], Loss: 2.2035, LR: 0.000560
[12:34:16] Epoch 143 Complete. Avg Loss: 1.9064, LR: 0.000560
  -> New best model saved (loss: 1.9064)
[12:34:16] Epoch [144/300], Step [0/384], Loss: 2.0678, LR: 0.000555
[12:34:18] Epoch [144/300], Step [20/384], Loss: 1.7907, LR: 0.000555
[12:34:21] Epoch [144/300], Step [40/384], Loss: 2.2127, LR: 0.000555
[12:34:23] Epoch [144/300], Step [60/384], Loss: 2.1476, LR: 0.000555
[12:34:25] Epoch [144/300], Step [80/384], Loss: 1.9472, LR: 0.000555
[12:34:27] Epoch [144/300], Step [100/384], Loss: 1.9108, LR: 0.000555
[12:34:29] Epoch [144/300], Step [120/384], Loss: 2.0829, LR: 0.000555
[12:34:32] Epoch [144/300], Step [140/384], Loss: 2.0234, LR: 0.000555
[12:34:34] Epoch [144/300], Step [160/384], Loss: 1.6559, LR: 0.000555
[12:34:36] Epoch [144/300], Step [180/384], Loss: 2.2275, LR: 0.000555
[12:34:38] Epoch [144/300], Step [200/384], Loss: 2.0922, LR: 0.000555
[12:34:40] Epoch [144/300], Step [220/384], Loss: 1.8303, LR: 0.000555
[12:34:43] Epoch [144/300], Step [240/384], Loss: 2.1408, LR: 0.000555
[12:34:46] Epoch [144/300], Step [260/384], Loss: 1.6364, LR: 0.000555
[12:34:48] Epoch [144/300], Step [280/384], Loss: 1.9105, LR: 0.000555
[12:34:50] Epoch [144/300], Step [300/384], Loss: 1.8790, LR: 0.000555
[12:34:52] Epoch [144/300], Step [320/384], Loss: 1.9391, LR: 0.000555
[12:34:54] Epoch [144/300], Step [340/384], Loss: 1.9275, LR: 0.000555
[12:34:57] Epoch [144/300], Step [360/384], Loss: 1.8774, LR: 0.000555
[12:34:59] Epoch [144/300], Step [380/384], Loss: 1.8573, LR: 0.000555
[12:35:00] Epoch 144 Complete. Avg Loss: 1.9150, LR: 0.000555
[12:35:00] Epoch [145/300], Step [0/384], Loss: 1.4005, LR: 0.000550
[12:35:02] Epoch [145/300], Step [20/384], Loss: 1.8083, LR: 0.000550
[12:35:04] Epoch [145/300], Step [40/384], Loss: 1.8425, LR: 0.000550
[12:35:07] Epoch [145/300], Step [60/384], Loss: 1.5410, LR: 0.000550
[12:35:09] Epoch [145/300], Step [80/384], Loss: 2.0967, LR: 0.000550
[12:35:11] Epoch [145/300], Step [100/384], Loss: 1.4747, LR: 0.000550
[12:35:13] Epoch [145/300], Step [120/384], Loss: 1.6813, LR: 0.000550
[12:35:15] Epoch [145/300], Step [140/384], Loss: 1.7683, LR: 0.000550
[12:35:18] Epoch [145/300], Step [160/384], Loss: 1.8917, LR: 0.000550
[12:35:20] Epoch [145/300], Step [180/384], Loss: 1.9031, LR: 0.000550
[12:35:22] Epoch [145/300], Step [200/384], Loss: 2.2106, LR: 0.000550
[12:35:24] Epoch [145/300], Step [220/384], Loss: 1.9624, LR: 0.000550
[12:35:26] Epoch [145/300], Step [240/384], Loss: 2.0200, LR: 0.000550
[12:35:29] Epoch [145/300], Step [260/384], Loss: 1.7286, LR: 0.000550
[12:35:31] Epoch [145/300], Step [280/384], Loss: 1.6061, LR: 0.000550
[12:35:33] Epoch [145/300], Step [300/384], Loss: 2.1937, LR: 0.000550
[12:35:35] Epoch [145/300], Step [320/384], Loss: 1.8247, LR: 0.000550
[12:35:38] Epoch [145/300], Step [340/384], Loss: 1.6096, LR: 0.000550
[12:35:40] Epoch [145/300], Step [360/384], Loss: 1.6090, LR: 0.000550
[12:35:43] Epoch [145/300], Step [380/384], Loss: 2.0076, LR: 0.000550
[12:35:43] Epoch 145 Complete. Avg Loss: 1.8842, LR: 0.000550
  -> New best model saved (loss: 1.8842)
[12:35:43] Epoch [146/300], Step [0/384], Loss: 1.7605, LR: 0.000544
[12:35:46] Epoch [146/300], Step [20/384], Loss: 1.7962, LR: 0.000544
[12:35:49] Epoch [146/300], Step [40/384], Loss: 1.5326, LR: 0.000544
[12:35:52] Epoch [146/300], Step [60/384], Loss: 1.6519, LR: 0.000544
[12:35:55] Epoch [146/300], Step [80/384], Loss: 1.5881, LR: 0.000544
[12:35:58] Epoch [146/300], Step [100/384], Loss: 1.8556, LR: 0.000544
[12:36:00] Epoch [146/300], Step [120/384], Loss: 1.6880, LR: 0.000544
[12:36:03] Epoch [146/300], Step [140/384], Loss: 1.6049, LR: 0.000544
[12:36:06] Epoch [146/300], Step [160/384], Loss: 2.1637, LR: 0.000544
[12:36:08] Epoch [146/300], Step [180/384], Loss: 1.9839, LR: 0.000544
[12:36:11] Epoch [146/300], Step [200/384], Loss: 2.1884, LR: 0.000544
[12:36:13] Epoch [146/300], Step [220/384], Loss: 1.8437, LR: 0.000544
[12:36:16] Epoch [146/300], Step [240/384], Loss: 1.6463, LR: 0.000544
[12:36:19] Epoch [146/300], Step [260/384], Loss: 1.9363, LR: 0.000544
[12:36:21] Epoch [146/300], Step [280/384], Loss: 1.8733, LR: 0.000544
[12:36:24] Epoch [146/300], Step [300/384], Loss: 1.7169, LR: 0.000544
[12:36:26] Epoch [146/300], Step [320/384], Loss: 1.6044, LR: 0.000544
[12:36:29] Epoch [146/300], Step [340/384], Loss: 2.7183, LR: 0.000544
[12:36:32] Epoch [146/300], Step [360/384], Loss: 2.2685, LR: 0.000544
[12:36:35] Epoch [146/300], Step [380/384], Loss: 2.0673, LR: 0.000544
[12:36:35] Epoch 146 Complete. Avg Loss: 1.8838, LR: 0.000544
  -> New best model saved (loss: 1.8838)
[12:36:35] Epoch [147/300], Step [0/384], Loss: 1.5269, LR: 0.000539
[12:36:38] Epoch [147/300], Step [20/384], Loss: 2.1717, LR: 0.000539
[12:36:41] Epoch [147/300], Step [40/384], Loss: 1.7017, LR: 0.000539
[12:36:44] Epoch [147/300], Step [60/384], Loss: 1.8407, LR: 0.000539
[12:36:46] Epoch [147/300], Step [80/384], Loss: 1.8927, LR: 0.000539
[12:36:48] Epoch [147/300], Step [100/384], Loss: 1.9592, LR: 0.000539
[12:36:50] Epoch [147/300], Step [120/384], Loss: 1.5014, LR: 0.000539
[12:36:52] Epoch [147/300], Step [140/384], Loss: 1.8352, LR: 0.000539
[12:36:55] Epoch [147/300], Step [160/384], Loss: 1.7410, LR: 0.000539
[12:36:57] Epoch [147/300], Step [180/384], Loss: 2.0957, LR: 0.000539
[12:36:59] Epoch [147/300], Step [200/384], Loss: 2.1660, LR: 0.000539
[12:37:01] Epoch [147/300], Step [220/384], Loss: 1.7599, LR: 0.000539
[12:37:03] Epoch [147/300], Step [240/384], Loss: 1.6137, LR: 0.000539
[12:37:06] Epoch [147/300], Step [260/384], Loss: 1.6742, LR: 0.000539
[12:37:08] Epoch [147/300], Step [280/384], Loss: 2.4256, LR: 0.000539
[12:37:10] Epoch [147/300], Step [300/384], Loss: 1.7327, LR: 0.000539
[12:37:12] Epoch [147/300], Step [320/384], Loss: 1.5506, LR: 0.000539
[12:37:14] Epoch [147/300], Step [340/384], Loss: 1.8079, LR: 0.000539
[12:37:16] Epoch [147/300], Step [360/384], Loss: 1.8064, LR: 0.000539
[12:37:18] Epoch [147/300], Step [380/384], Loss: 1.3649, LR: 0.000539
[12:37:19] Epoch 147 Complete. Avg Loss: 1.8872, LR: 0.000539
[12:37:19] Epoch [148/300], Step [0/384], Loss: 1.7029, LR: 0.000534
[12:37:21] Epoch [148/300], Step [20/384], Loss: 1.5503, LR: 0.000534
[12:37:23] Epoch [148/300], Step [40/384], Loss: 2.0588, LR: 0.000534
[12:37:25] Epoch [148/300], Step [60/384], Loss: 1.9810, LR: 0.000534
[12:37:28] Epoch [148/300], Step [80/384], Loss: 2.2708, LR: 0.000534
[12:37:30] Epoch [148/300], Step [100/384], Loss: 1.7146, LR: 0.000534
[12:37:32] Epoch [148/300], Step [120/384], Loss: 1.5143, LR: 0.000534
[12:37:34] Epoch [148/300], Step [140/384], Loss: 2.2039, LR: 0.000534
[12:37:36] Epoch [148/300], Step [160/384], Loss: 2.1954, LR: 0.000534
[12:37:38] Epoch [148/300], Step [180/384], Loss: 2.0738, LR: 0.000534
[12:37:41] Epoch [148/300], Step [200/384], Loss: 2.1935, LR: 0.000534
[12:37:43] Epoch [148/300], Step [220/384], Loss: 1.7044, LR: 0.000534
[12:37:45] Epoch [148/300], Step [240/384], Loss: 2.6070, LR: 0.000534
[12:37:47] Epoch [148/300], Step [260/384], Loss: 1.9944, LR: 0.000534
[12:37:49] Epoch [148/300], Step [280/384], Loss: 2.4002, LR: 0.000534
[12:37:52] Epoch [148/300], Step [300/384], Loss: 2.2316, LR: 0.000534
[12:37:54] Epoch [148/300], Step [320/384], Loss: 2.1087, LR: 0.000534
[12:37:56] Epoch [148/300], Step [340/384], Loss: 2.2400, LR: 0.000534
[12:37:58] Epoch [148/300], Step [360/384], Loss: 2.8397, LR: 0.000534
[12:38:00] Epoch [148/300], Step [380/384], Loss: 2.1731, LR: 0.000534
[12:38:00] Epoch 148 Complete. Avg Loss: 1.8930, LR: 0.000534
[12:38:01] Epoch [149/300], Step [0/384], Loss: 1.9514, LR: 0.000529
[12:38:02] Epoch [149/300], Step [20/384], Loss: 1.3325, LR: 0.000529
[12:38:05] Epoch [149/300], Step [40/384], Loss: 2.2599, LR: 0.000529
[12:38:07] Epoch [149/300], Step [60/384], Loss: 1.1597, LR: 0.000529
[12:38:09] Epoch [149/300], Step [80/384], Loss: 2.2955, LR: 0.000529
[12:38:11] Epoch [149/300], Step [100/384], Loss: 1.8081, LR: 0.000529
[12:38:13] Epoch [149/300], Step [120/384], Loss: 1.9524, LR: 0.000529
[12:38:16] Epoch [149/300], Step [140/384], Loss: 1.8315, LR: 0.000529
[12:38:18] Epoch [149/300], Step [160/384], Loss: 1.6597, LR: 0.000529
[12:38:20] Epoch [149/300], Step [180/384], Loss: 2.0294, LR: 0.000529
[12:38:22] Epoch [149/300], Step [200/384], Loss: 1.5867, LR: 0.000529
[12:38:24] Epoch [149/300], Step [220/384], Loss: 1.8053, LR: 0.000529
[12:38:26] Epoch [149/300], Step [240/384], Loss: 1.5002, LR: 0.000529
[12:38:29] Epoch [149/300], Step [260/384], Loss: 1.6632, LR: 0.000529
[12:38:31] Epoch [149/300], Step [280/384], Loss: 1.7699, LR: 0.000529
[12:38:33] Epoch [149/300], Step [300/384], Loss: 2.1321, LR: 0.000529
[12:38:35] Epoch [149/300], Step [320/384], Loss: 2.0215, LR: 0.000529
[12:38:38] Epoch [149/300], Step [340/384], Loss: 1.9697, LR: 0.000529
[12:38:40] Epoch [149/300], Step [360/384], Loss: 1.8616, LR: 0.000529
[12:38:42] Epoch [149/300], Step [380/384], Loss: 2.1334, LR: 0.000529
[12:38:42] Epoch 149 Complete. Avg Loss: 1.8611, LR: 0.000529
  -> New best model saved (loss: 1.8611)
[12:38:42] Epoch [150/300], Step [0/384], Loss: 1.7787, LR: 0.000523
[12:38:45] Epoch [150/300], Step [20/384], Loss: 1.8179, LR: 0.000523
[12:38:47] Epoch [150/300], Step [40/384], Loss: 1.6446, LR: 0.000523
[12:38:49] Epoch [150/300], Step [60/384], Loss: 1.5755, LR: 0.000523
[12:38:51] Epoch [150/300], Step [80/384], Loss: 1.9141, LR: 0.000523
[12:38:53] Epoch [150/300], Step [100/384], Loss: 1.9284, LR: 0.000523
[12:38:56] Epoch [150/300], Step [120/384], Loss: 2.0549, LR: 0.000523
[12:38:58] Epoch [150/300], Step [140/384], Loss: 2.3792, LR: 0.000523
[12:39:00] Epoch [150/300], Step [160/384], Loss: 2.1102, LR: 0.000523
[12:39:02] Epoch [150/300], Step [180/384], Loss: 1.5666, LR: 0.000523
[12:39:04] Epoch [150/300], Step [200/384], Loss: 1.6568, LR: 0.000523
[12:39:07] Epoch [150/300], Step [220/384], Loss: 1.6828, LR: 0.000523
[12:39:09] Epoch [150/300], Step [240/384], Loss: 1.8384, LR: 0.000523
[12:39:11] Epoch [150/300], Step [260/384], Loss: 2.5952, LR: 0.000523
[12:39:13] Epoch [150/300], Step [280/384], Loss: 1.3421, LR: 0.000523
[12:39:15] Epoch [150/300], Step [300/384], Loss: 2.0925, LR: 0.000523
[12:39:17] Epoch [150/300], Step [320/384], Loss: 2.6555, LR: 0.000523
[12:39:19] Epoch [150/300], Step [340/384], Loss: 1.9924, LR: 0.000523
[12:39:22] Epoch [150/300], Step [360/384], Loss: 1.6410, LR: 0.000523
[12:39:24] Epoch [150/300], Step [380/384], Loss: 2.3842, LR: 0.000523
[12:39:24] Epoch 150 Complete. Avg Loss: 1.8784, LR: 0.000523
[12:39:24] Epoch [151/300], Step [0/384], Loss: 1.8685, LR: 0.000518
[12:39:26] Epoch [151/300], Step [20/384], Loss: 1.8170, LR: 0.000518
[12:39:28] Epoch [151/300], Step [40/384], Loss: 1.4967, LR: 0.000518
[12:39:31] Epoch [151/300], Step [60/384], Loss: 1.6316, LR: 0.000518
[12:39:33] Epoch [151/300], Step [80/384], Loss: 2.0137, LR: 0.000518
[12:39:35] Epoch [151/300], Step [100/384], Loss: 1.6806, LR: 0.000518
[12:39:37] Epoch [151/300], Step [120/384], Loss: 2.3478, LR: 0.000518
[12:39:39] Epoch [151/300], Step [140/384], Loss: 2.1354, LR: 0.000518
[12:39:41] Epoch [151/300], Step [160/384], Loss: 1.6465, LR: 0.000518
[12:39:44] Epoch [151/300], Step [180/384], Loss: 1.9708, LR: 0.000518
[12:39:46] Epoch [151/300], Step [200/384], Loss: 1.6119, LR: 0.000518
[12:39:48] Epoch [151/300], Step [220/384], Loss: 1.9696, LR: 0.000518
[12:39:50] Epoch [151/300], Step [240/384], Loss: 2.0015, LR: 0.000518
[12:39:52] Epoch [151/300], Step [260/384], Loss: 1.5646, LR: 0.000518
[12:39:54] Epoch [151/300], Step [280/384], Loss: 1.8947, LR: 0.000518
[12:39:57] Epoch [151/300], Step [300/384], Loss: 1.8367, LR: 0.000518
[12:39:59] Epoch [151/300], Step [320/384], Loss: 2.7831, LR: 0.000518
[12:40:01] Epoch [151/300], Step [340/384], Loss: 2.2848, LR: 0.000518
[12:40:03] Epoch [151/300], Step [360/384], Loss: 1.8811, LR: 0.000518
[12:40:05] Epoch [151/300], Step [380/384], Loss: 2.3377, LR: 0.000518
[12:40:06] Epoch 151 Complete. Avg Loss: 1.8581, LR: 0.000518
  -> New best model saved (loss: 1.8581)
[12:40:06] Epoch [152/300], Step [0/384], Loss: 1.4272, LR: 0.000513
[12:40:08] Epoch [152/300], Step [20/384], Loss: 1.6371, LR: 0.000513
[12:40:10] Epoch [152/300], Step [40/384], Loss: 2.7031, LR: 0.000513
[12:40:12] Epoch [152/300], Step [60/384], Loss: 1.8387, LR: 0.000513
[12:40:14] Epoch [152/300], Step [80/384], Loss: 2.0589, LR: 0.000513
[12:40:16] Epoch [152/300], Step [100/384], Loss: 1.4148, LR: 0.000513
[12:40:19] Epoch [152/300], Step [120/384], Loss: 2.1107, LR: 0.000513
[12:40:21] Epoch [152/300], Step [140/384], Loss: 1.6658, LR: 0.000513
[12:40:23] Epoch [152/300], Step [160/384], Loss: 1.8852, LR: 0.000513
[12:40:25] Epoch [152/300], Step [180/384], Loss: 1.9767, LR: 0.000513
[12:40:27] Epoch [152/300], Step [200/384], Loss: 2.3086, LR: 0.000513
[12:40:29] Epoch [152/300], Step [220/384], Loss: 1.5423, LR: 0.000513
[12:40:31] Epoch [152/300], Step [240/384], Loss: 1.9279, LR: 0.000513
[12:40:34] Epoch [152/300], Step [260/384], Loss: 2.0794, LR: 0.000513
[12:40:36] Epoch [152/300], Step [280/384], Loss: 2.1700, LR: 0.000513
[12:40:38] Epoch [152/300], Step [300/384], Loss: 2.2940, LR: 0.000513
[12:40:40] Epoch [152/300], Step [320/384], Loss: 2.1852, LR: 0.000513
[12:40:42] Epoch [152/300], Step [340/384], Loss: 1.7079, LR: 0.000513
[12:40:45] Epoch [152/300], Step [360/384], Loss: 2.6807, LR: 0.000513
[12:40:47] Epoch [152/300], Step [380/384], Loss: 1.5195, LR: 0.000513
[12:40:47] Epoch 152 Complete. Avg Loss: 1.8437, LR: 0.000513
  -> New best model saved (loss: 1.8437)
[12:40:48] Epoch [153/300], Step [0/384], Loss: 1.8307, LR: 0.000508
[12:40:50] Epoch [153/300], Step [20/384], Loss: 1.6955, LR: 0.000508
[12:40:52] Epoch [153/300], Step [40/384], Loss: 1.6879, LR: 0.000508
[12:40:54] Epoch [153/300], Step [60/384], Loss: 2.0640, LR: 0.000508
[12:40:56] Epoch [153/300], Step [80/384], Loss: 2.1607, LR: 0.000508
[12:40:59] Epoch [153/300], Step [100/384], Loss: 1.8039, LR: 0.000508
[12:41:01] Epoch [153/300], Step [120/384], Loss: 2.0144, LR: 0.000508
[12:41:03] Epoch [153/300], Step [140/384], Loss: 2.0657, LR: 0.000508
[12:41:05] Epoch [153/300], Step [160/384], Loss: 1.9988, LR: 0.000508
[12:41:08] Epoch [153/300], Step [180/384], Loss: 1.3724, LR: 0.000508
[12:41:10] Epoch [153/300], Step [200/384], Loss: 1.9970, LR: 0.000508
[12:41:12] Epoch [153/300], Step [220/384], Loss: 1.6407, LR: 0.000508
[12:41:14] Epoch [153/300], Step [240/384], Loss: 1.9440, LR: 0.000508
[12:41:16] Epoch [153/300], Step [260/384], Loss: 1.9958, LR: 0.000508
[12:41:18] Epoch [153/300], Step [280/384], Loss: 1.5626, LR: 0.000508
[12:41:20] Epoch [153/300], Step [300/384], Loss: 1.4651, LR: 0.000508
[12:41:23] Epoch [153/300], Step [320/384], Loss: 1.7727, LR: 0.000508
[12:41:25] Epoch [153/300], Step [340/384], Loss: 2.3172, LR: 0.000508
[12:41:27] Epoch [153/300], Step [360/384], Loss: 2.0592, LR: 0.000508
[12:41:29] Epoch [153/300], Step [380/384], Loss: 2.0380, LR: 0.000508
[12:41:29] Epoch 153 Complete. Avg Loss: 1.8470, LR: 0.000508
[12:41:30] Epoch [154/300], Step [0/384], Loss: 2.0075, LR: 0.000502
[12:41:32] Epoch [154/300], Step [20/384], Loss: 2.2799, LR: 0.000502
[12:41:34] Epoch [154/300], Step [40/384], Loss: 2.3304, LR: 0.000502
[12:41:36] Epoch [154/300], Step [60/384], Loss: 2.0770, LR: 0.000502
[12:41:38] Epoch [154/300], Step [80/384], Loss: 1.8752, LR: 0.000502
[12:41:41] Epoch [154/300], Step [100/384], Loss: 1.6093, LR: 0.000502
[12:41:43] Epoch [154/300], Step [120/384], Loss: 1.9677, LR: 0.000502
[12:41:45] Epoch [154/300], Step [140/384], Loss: 1.5041, LR: 0.000502
[12:41:47] Epoch [154/300], Step [160/384], Loss: 2.0154, LR: 0.000502
[12:41:49] Epoch [154/300], Step [180/384], Loss: 2.2915, LR: 0.000502
[12:41:51] Epoch [154/300], Step [200/384], Loss: 1.2276, LR: 0.000502
[12:41:53] Epoch [154/300], Step [220/384], Loss: 1.8126, LR: 0.000502
[12:41:56] Epoch [154/300], Step [240/384], Loss: 1.9101, LR: 0.000502
[12:41:58] Epoch [154/300], Step [260/384], Loss: 1.6696, LR: 0.000502
[12:42:00] Epoch [154/300], Step [280/384], Loss: 1.7305, LR: 0.000502
[12:42:02] Epoch [154/300], Step [300/384], Loss: 1.3713, LR: 0.000502
[12:42:05] Epoch [154/300], Step [320/384], Loss: 2.1179, LR: 0.000502
[12:42:07] Epoch [154/300], Step [340/384], Loss: 1.6920, LR: 0.000502
[12:42:09] Epoch [154/300], Step [360/384], Loss: 1.4612, LR: 0.000502
[12:42:11] Epoch [154/300], Step [380/384], Loss: 1.7544, LR: 0.000502
[12:42:11] Epoch 154 Complete. Avg Loss: 1.8528, LR: 0.000502
[12:42:12] Epoch [155/300], Step [0/384], Loss: 1.7440, LR: 0.000497
[12:42:14] Epoch [155/300], Step [20/384], Loss: 1.8828, LR: 0.000497
[12:42:16] Epoch [155/300], Step [40/384], Loss: 1.8460, LR: 0.000497
[12:42:18] Epoch [155/300], Step [60/384], Loss: 1.5047, LR: 0.000497
[12:42:20] Epoch [155/300], Step [80/384], Loss: 1.8925, LR: 0.000497
[12:42:22] Epoch [155/300], Step [100/384], Loss: 1.5878, LR: 0.000497
[12:42:24] Epoch [155/300], Step [120/384], Loss: 1.5326, LR: 0.000497
[12:42:27] Epoch [155/300], Step [140/384], Loss: 1.3727, LR: 0.000497
[12:42:29] Epoch [155/300], Step [160/384], Loss: 1.7998, LR: 0.000497
[12:42:31] Epoch [155/300], Step [180/384], Loss: 2.1834, LR: 0.000497
[12:42:33] Epoch [155/300], Step [200/384], Loss: 1.8211, LR: 0.000497
[12:42:36] Epoch [155/300], Step [220/384], Loss: 1.9224, LR: 0.000497
[12:42:38] Epoch [155/300], Step [240/384], Loss: 1.6043, LR: 0.000497
[12:42:40] Epoch [155/300], Step [260/384], Loss: 1.9297, LR: 0.000497
[12:42:42] Epoch [155/300], Step [280/384], Loss: 2.1864, LR: 0.000497
[12:42:44] Epoch [155/300], Step [300/384], Loss: 2.1126, LR: 0.000497
[12:42:46] Epoch [155/300], Step [320/384], Loss: 2.3677, LR: 0.000497
[12:42:48] Epoch [155/300], Step [340/384], Loss: 1.4675, LR: 0.000497
[12:42:51] Epoch [155/300], Step [360/384], Loss: 2.0417, LR: 0.000497
[12:42:53] Epoch [155/300], Step [380/384], Loss: 2.0130, LR: 0.000497
[12:42:53] Epoch 155 Complete. Avg Loss: 1.8282, LR: 0.000497
  -> New best model saved (loss: 1.8282)
[12:42:54] Epoch [156/300], Step [0/384], Loss: 1.7209, LR: 0.000492
[12:42:56] Epoch [156/300], Step [20/384], Loss: 1.9628, LR: 0.000492
[12:42:58] Epoch [156/300], Step [40/384], Loss: 1.8043, LR: 0.000492
[12:43:00] Epoch [156/300], Step [60/384], Loss: 1.9773, LR: 0.000492
[12:43:02] Epoch [156/300], Step [80/384], Loss: 1.9398, LR: 0.000492
[12:43:04] Epoch [156/300], Step [100/384], Loss: 2.1532, LR: 0.000492
[12:43:06] Epoch [156/300], Step [120/384], Loss: 2.1007, LR: 0.000492
[12:43:09] Epoch [156/300], Step [140/384], Loss: 1.2175, LR: 0.000492
[12:43:11] Epoch [156/300], Step [160/384], Loss: 1.3530, LR: 0.000492
[12:43:13] Epoch [156/300], Step [180/384], Loss: 1.8629, LR: 0.000492
[12:43:16] Epoch [156/300], Step [200/384], Loss: 1.9525, LR: 0.000492
[12:43:18] Epoch [156/300], Step [220/384], Loss: 1.5202, LR: 0.000492
[12:43:20] Epoch [156/300], Step [240/384], Loss: 1.9068, LR: 0.000492
[12:43:22] Epoch [156/300], Step [260/384], Loss: 2.1566, LR: 0.000492
[12:43:25] Epoch [156/300], Step [280/384], Loss: 1.7470, LR: 0.000492
[12:43:27] Epoch [156/300], Step [300/384], Loss: 1.8075, LR: 0.000492
[12:43:29] Epoch [156/300], Step [320/384], Loss: 1.7853, LR: 0.000492
[12:43:31] Epoch [156/300], Step [340/384], Loss: 1.9180, LR: 0.000492
[12:43:33] Epoch [156/300], Step [360/384], Loss: 2.2205, LR: 0.000492
[12:43:36] Epoch [156/300], Step [380/384], Loss: 1.6271, LR: 0.000492
[12:43:36] Epoch 156 Complete. Avg Loss: 1.8200, LR: 0.000492
  -> New best model saved (loss: 1.8200)
[12:43:36] Epoch [157/300], Step [0/384], Loss: 1.8329, LR: 0.000487
[12:43:38] Epoch [157/300], Step [20/384], Loss: 1.9045, LR: 0.000487
[12:43:40] Epoch [157/300], Step [40/384], Loss: 1.6872, LR: 0.000487
[12:43:43] Epoch [157/300], Step [60/384], Loss: 1.6825, LR: 0.000487
[12:43:45] Epoch [157/300], Step [80/384], Loss: 1.8406, LR: 0.000487
[12:43:47] Epoch [157/300], Step [100/384], Loss: 1.8548, LR: 0.000487
[12:43:49] Epoch [157/300], Step [120/384], Loss: 1.3773, LR: 0.000487
[12:43:51] Epoch [157/300], Step [140/384], Loss: 1.8116, LR: 0.000487
[12:43:53] Epoch [157/300], Step [160/384], Loss: 1.6035, LR: 0.000487
[12:43:55] Epoch [157/300], Step [180/384], Loss: 1.9006, LR: 0.000487
[12:43:58] Epoch [157/300], Step [200/384], Loss: 1.8704, LR: 0.000487
[12:44:00] Epoch [157/300], Step [220/384], Loss: 1.6662, LR: 0.000487
[12:44:02] Epoch [157/300], Step [240/384], Loss: 1.9289, LR: 0.000487
[12:44:05] Epoch [157/300], Step [260/384], Loss: 1.3490, LR: 0.000487
[12:44:07] Epoch [157/300], Step [280/384], Loss: 1.5735, LR: 0.000487
[12:44:09] Epoch [157/300], Step [300/384], Loss: 2.0292, LR: 0.000487
[12:44:11] Epoch [157/300], Step [320/384], Loss: 1.8905, LR: 0.000487
[12:44:13] Epoch [157/300], Step [340/384], Loss: 1.9082, LR: 0.000487
[12:44:15] Epoch [157/300], Step [360/384], Loss: 1.7061, LR: 0.000487
[12:44:18] Epoch [157/300], Step [380/384], Loss: 1.8307, LR: 0.000487
[12:44:18] Epoch 157 Complete. Avg Loss: 1.8337, LR: 0.000487
[12:44:18] Epoch [158/300], Step [0/384], Loss: 1.4806, LR: 0.000481
[12:44:20] Epoch [158/300], Step [20/384], Loss: 2.1441, LR: 0.000481
[12:44:23] Epoch [158/300], Step [40/384], Loss: 2.3900, LR: 0.000481
[12:44:25] Epoch [158/300], Step [60/384], Loss: 1.9355, LR: 0.000481
[12:44:27] Epoch [158/300], Step [80/384], Loss: 1.4294, LR: 0.000481
[12:44:29] Epoch [158/300], Step [100/384], Loss: 1.8507, LR: 0.000481
[12:44:31] Epoch [158/300], Step [120/384], Loss: 1.7227, LR: 0.000481
[12:44:33] Epoch [158/300], Step [140/384], Loss: 1.7112, LR: 0.000481
[12:44:36] Epoch [158/300], Step [160/384], Loss: 1.6714, LR: 0.000481
[12:44:38] Epoch [158/300], Step [180/384], Loss: 1.6962, LR: 0.000481
[12:44:40] Epoch [158/300], Step [200/384], Loss: 2.0489, LR: 0.000481
[12:44:42] Epoch [158/300], Step [220/384], Loss: 1.8300, LR: 0.000481
[12:44:44] Epoch [158/300], Step [240/384], Loss: 1.7664, LR: 0.000481
[12:44:46] Epoch [158/300], Step [260/384], Loss: 1.8888, LR: 0.000481
[12:44:49] Epoch [158/300], Step [280/384], Loss: 2.0546, LR: 0.000481
[12:44:51] Epoch [158/300], Step [300/384], Loss: 1.8702, LR: 0.000481
[12:44:53] Epoch [158/300], Step [320/384], Loss: 1.4850, LR: 0.000481
[12:44:56] Epoch [158/300], Step [340/384], Loss: 2.0117, LR: 0.000481
[12:44:58] Epoch [158/300], Step [360/384], Loss: 2.3015, LR: 0.000481
[12:45:00] Epoch [158/300], Step [380/384], Loss: 1.6448, LR: 0.000481
[12:45:00] Epoch 158 Complete. Avg Loss: 1.8351, LR: 0.000481
[12:45:00] Epoch [159/300], Step [0/384], Loss: 1.3954, LR: 0.000476
[12:45:03] Epoch [159/300], Step [20/384], Loss: 1.3569, LR: 0.000476
[12:45:05] Epoch [159/300], Step [40/384], Loss: 2.4964, LR: 0.000476
[12:45:07] Epoch [159/300], Step [60/384], Loss: 1.1962, LR: 0.000476
[12:45:09] Epoch [159/300], Step [80/384], Loss: 1.4708, LR: 0.000476
[12:45:11] Epoch [159/300], Step [100/384], Loss: 2.0656, LR: 0.000476
[12:45:13] Epoch [159/300], Step [120/384], Loss: 1.5219, LR: 0.000476
[12:45:16] Epoch [159/300], Step [140/384], Loss: 1.8232, LR: 0.000476
[12:45:18] Epoch [159/300], Step [160/384], Loss: 2.3145, LR: 0.000476
[12:45:20] Epoch [159/300], Step [180/384], Loss: 1.8909, LR: 0.000476
[12:45:22] Epoch [159/300], Step [200/384], Loss: 1.8181, LR: 0.000476
[12:45:24] Epoch [159/300], Step [220/384], Loss: 1.7986, LR: 0.000476
[12:45:27] Epoch [159/300], Step [240/384], Loss: 1.8115, LR: 0.000476
[12:45:29] Epoch [159/300], Step [260/384], Loss: 1.7392, LR: 0.000476
[12:45:31] Epoch [159/300], Step [280/384], Loss: 1.6174, LR: 0.000476
[12:45:33] Epoch [159/300], Step [300/384], Loss: 1.5342, LR: 0.000476
[12:45:35] Epoch [159/300], Step [320/384], Loss: 1.8749, LR: 0.000476
[12:45:38] Epoch [159/300], Step [340/384], Loss: 1.7405, LR: 0.000476
[12:45:40] Epoch [159/300], Step [360/384], Loss: 1.5419, LR: 0.000476
[12:45:42] Epoch [159/300], Step [380/384], Loss: 1.9596, LR: 0.000476
[12:45:42] Epoch 159 Complete. Avg Loss: 1.8045, LR: 0.000476
  -> New best model saved (loss: 1.8045)
[12:45:43] Epoch [160/300], Step [0/384], Loss: 1.8493, LR: 0.000471
[12:45:45] Epoch [160/300], Step [20/384], Loss: 1.9077, LR: 0.000471
[12:45:47] Epoch [160/300], Step [40/384], Loss: 2.0459, LR: 0.000471
[12:45:49] Epoch [160/300], Step [60/384], Loss: 1.5715, LR: 0.000471
[12:45:51] Epoch [160/300], Step [80/384], Loss: 1.7580, LR: 0.000471
[12:45:54] Epoch [160/300], Step [100/384], Loss: 1.9959, LR: 0.000471
[12:45:56] Epoch [160/300], Step [120/384], Loss: 1.8962, LR: 0.000471
[12:45:58] Epoch [160/300], Step [140/384], Loss: 1.9559, LR: 0.000471
[12:46:00] Epoch [160/300], Step [160/384], Loss: 1.9362, LR: 0.000471
[12:46:02] Epoch [160/300], Step [180/384], Loss: 2.0323, LR: 0.000471
[12:46:05] Epoch [160/300], Step [200/384], Loss: 1.7903, LR: 0.000471
[12:46:07] Epoch [160/300], Step [220/384], Loss: 2.0514, LR: 0.000471
[12:46:09] Epoch [160/300], Step [240/384], Loss: 2.3546, LR: 0.000471
[12:46:11] Epoch [160/300], Step [260/384], Loss: 1.5563, LR: 0.000471
[12:46:13] Epoch [160/300], Step [280/384], Loss: 2.4996, LR: 0.000471
[12:46:15] Epoch [160/300], Step [300/384], Loss: 1.6043, LR: 0.000471
[12:46:18] Epoch [160/300], Step [320/384], Loss: 1.1437, LR: 0.000471
[12:46:20] Epoch [160/300], Step [340/384], Loss: 2.2327, LR: 0.000471
[12:46:22] Epoch [160/300], Step [360/384], Loss: 1.5838, LR: 0.000471
[12:46:24] Epoch [160/300], Step [380/384], Loss: 1.9627, LR: 0.000471
[12:46:25] Epoch 160 Complete. Avg Loss: 1.8174, LR: 0.000471
[12:46:25] Epoch [161/300], Step [0/384], Loss: 1.8830, LR: 0.000466
[12:46:27] Epoch [161/300], Step [20/384], Loss: 1.5390, LR: 0.000466
[12:46:29] Epoch [161/300], Step [40/384], Loss: 1.7672, LR: 0.000466
[12:46:31] Epoch [161/300], Step [60/384], Loss: 1.9885, LR: 0.000466
[12:46:33] Epoch [161/300], Step [80/384], Loss: 2.1365, LR: 0.000466
[12:46:36] Epoch [161/300], Step [100/384], Loss: 1.8238, LR: 0.000466
[12:46:38] Epoch [161/300], Step [120/384], Loss: 2.0329, LR: 0.000466
[12:46:40] Epoch [161/300], Step [140/384], Loss: 1.9115, LR: 0.000466
[12:46:42] Epoch [161/300], Step [160/384], Loss: 1.4477, LR: 0.000466
[12:46:44] Epoch [161/300], Step [180/384], Loss: 1.7557, LR: 0.000466
[12:46:47] Epoch [161/300], Step [200/384], Loss: 1.6423, LR: 0.000466
[12:46:49] Epoch [161/300], Step [220/384], Loss: 1.7328, LR: 0.000466
[12:46:51] Epoch [161/300], Step [240/384], Loss: 1.4125, LR: 0.000466
[12:46:53] Epoch [161/300], Step [260/384], Loss: 1.6977, LR: 0.000466
[12:46:56] Epoch [161/300], Step [280/384], Loss: 2.3223, LR: 0.000466
[12:46:58] Epoch [161/300], Step [300/384], Loss: 2.2277, LR: 0.000466
[12:47:00] Epoch [161/300], Step [320/384], Loss: 1.6632, LR: 0.000466
[12:47:03] Epoch [161/300], Step [340/384], Loss: 2.4108, LR: 0.000466
[12:47:05] Epoch [161/300], Step [360/384], Loss: 1.6891, LR: 0.000466
[12:47:07] Epoch [161/300], Step [380/384], Loss: 2.0546, LR: 0.000466
[12:47:07] Epoch 161 Complete. Avg Loss: 1.7991, LR: 0.000466
  -> New best model saved (loss: 1.7991)
[12:47:07] Epoch [162/300], Step [0/384], Loss: 2.0040, LR: 0.000460
[12:47:09] Epoch [162/300], Step [20/384], Loss: 2.2112, LR: 0.000460
[12:47:11] Epoch [162/300], Step [40/384], Loss: 1.8089, LR: 0.000460
[12:47:14] Epoch [162/300], Step [60/384], Loss: 1.7700, LR: 0.000460
[12:47:16] Epoch [162/300], Step [80/384], Loss: 1.8489, LR: 0.000460
[12:47:18] Epoch [162/300], Step [100/384], Loss: 1.5152, LR: 0.000460
[12:47:20] Epoch [162/300], Step [120/384], Loss: 1.4570, LR: 0.000460
[12:47:22] Epoch [162/300], Step [140/384], Loss: 1.1518, LR: 0.000460
[12:47:25] Epoch [162/300], Step [160/384], Loss: 1.9937, LR: 0.000460
[12:47:27] Epoch [162/300], Step [180/384], Loss: 1.1674, LR: 0.000460
[12:47:29] Epoch [162/300], Step [200/384], Loss: 1.6122, LR: 0.000460
[12:47:31] Epoch [162/300], Step [220/384], Loss: 1.7092, LR: 0.000460
[12:47:33] Epoch [162/300], Step [240/384], Loss: 2.2419, LR: 0.000460
[12:47:35] Epoch [162/300], Step [260/384], Loss: 1.7081, LR: 0.000460
[12:47:37] Epoch [162/300], Step [280/384], Loss: 1.8982, LR: 0.000460
[12:47:40] Epoch [162/300], Step [300/384], Loss: 1.9605, LR: 0.000460
[12:47:42] Epoch [162/300], Step [320/384], Loss: 1.8577, LR: 0.000460
[12:47:44] Epoch [162/300], Step [340/384], Loss: 2.2855, LR: 0.000460
[12:47:46] Epoch [162/300], Step [360/384], Loss: 1.5939, LR: 0.000460
[12:47:48] Epoch [162/300], Step [380/384], Loss: 1.9711, LR: 0.000460
[12:47:48] Epoch 162 Complete. Avg Loss: 1.7932, LR: 0.000460
  -> New best model saved (loss: 1.7932)
[12:47:49] Epoch [163/300], Step [0/384], Loss: 1.9751, LR: 0.000455
[12:47:51] Epoch [163/300], Step [20/384], Loss: 1.8338, LR: 0.000455
[12:47:53] Epoch [163/300], Step [40/384], Loss: 1.3201, LR: 0.000455
[12:47:55] Epoch [163/300], Step [60/384], Loss: 2.1923, LR: 0.000455
[12:47:58] Epoch [163/300], Step [80/384], Loss: 1.5636, LR: 0.000455
[12:48:00] Epoch [163/300], Step [100/384], Loss: 1.8215, LR: 0.000455
[12:48:02] Epoch [163/300], Step [120/384], Loss: 2.1081, LR: 0.000455
[12:48:04] Epoch [163/300], Step [140/384], Loss: 1.3248, LR: 0.000455
[12:48:07] Epoch [163/300], Step [160/384], Loss: 1.7416, LR: 0.000455
[12:48:09] Epoch [163/300], Step [180/384], Loss: 1.8680, LR: 0.000455
[12:48:11] Epoch [163/300], Step [200/384], Loss: 1.7670, LR: 0.000455
[12:48:13] Epoch [163/300], Step [220/384], Loss: 2.2529, LR: 0.000455
[12:48:15] Epoch [163/300], Step [240/384], Loss: 1.6940, LR: 0.000455
[12:48:17] Epoch [163/300], Step [260/384], Loss: 2.1463, LR: 0.000455
[12:48:20] Epoch [163/300], Step [280/384], Loss: 1.9443, LR: 0.000455
[12:48:22] Epoch [163/300], Step [300/384], Loss: 1.8783, LR: 0.000455
[12:48:24] Epoch [163/300], Step [320/384], Loss: 2.0684, LR: 0.000455
[12:48:26] Epoch [163/300], Step [340/384], Loss: 1.7711, LR: 0.000455
[12:48:28] Epoch [163/300], Step [360/384], Loss: 1.9612, LR: 0.000455
[12:48:30] Epoch [163/300], Step [380/384], Loss: 1.9225, LR: 0.000455
[12:48:30] Epoch 163 Complete. Avg Loss: 1.7823, LR: 0.000455
  -> New best model saved (loss: 1.7823)
[12:48:30] Epoch [164/300], Step [0/384], Loss: 1.6030, LR: 0.000450
[12:48:33] Epoch [164/300], Step [20/384], Loss: 2.2010, LR: 0.000450
[12:48:35] Epoch [164/300], Step [40/384], Loss: 1.4088, LR: 0.000450
[12:48:37] Epoch [164/300], Step [60/384], Loss: 1.9959, LR: 0.000450
[12:48:39] Epoch [164/300], Step [80/384], Loss: 2.3651, LR: 0.000450
[12:48:41] Epoch [164/300], Step [100/384], Loss: 1.6895, LR: 0.000450
[12:48:43] Epoch [164/300], Step [120/384], Loss: 1.4652, LR: 0.000450
[12:48:45] Epoch [164/300], Step [140/384], Loss: 2.0664, LR: 0.000450
[12:48:47] Epoch [164/300], Step [160/384], Loss: 1.8267, LR: 0.000450
[12:48:49] Epoch [164/300], Step [180/384], Loss: 2.1893, LR: 0.000450
[12:48:52] Epoch [164/300], Step [200/384], Loss: 1.8822, LR: 0.000450
[12:48:54] Epoch [164/300], Step [220/384], Loss: 1.4606, LR: 0.000450
[12:48:56] Epoch [164/300], Step [240/384], Loss: 2.8515, LR: 0.000450
[12:48:58] Epoch [164/300], Step [260/384], Loss: 1.7752, LR: 0.000450
[12:49:00] Epoch [164/300], Step [280/384], Loss: 1.6503, LR: 0.000450
[12:49:02] Epoch [164/300], Step [300/384], Loss: 1.7240, LR: 0.000450
[12:49:04] Epoch [164/300], Step [320/384], Loss: 1.3064, LR: 0.000450
[12:49:07] Epoch [164/300], Step [340/384], Loss: 1.7589, LR: 0.000450
[12:49:09] Epoch [164/300], Step [360/384], Loss: 1.8034, LR: 0.000450
[12:49:11] Epoch [164/300], Step [380/384], Loss: 1.9364, LR: 0.000450
[12:49:11] Epoch 164 Complete. Avg Loss: 1.7724, LR: 0.000450
  -> New best model saved (loss: 1.7724)
[12:49:12] Epoch [165/300], Step [0/384], Loss: 1.4039, LR: 0.000445
[12:49:14] Epoch [165/300], Step [20/384], Loss: 1.4903, LR: 0.000445
[12:49:16] Epoch [165/300], Step [40/384], Loss: 1.5632, LR: 0.000445
[12:49:18] Epoch [165/300], Step [60/384], Loss: 1.5632, LR: 0.000445
[12:49:21] Epoch [165/300], Step [80/384], Loss: 1.7149, LR: 0.000445
[12:49:23] Epoch [165/300], Step [100/384], Loss: 1.7352, LR: 0.000445
[12:49:25] Epoch [165/300], Step [120/384], Loss: 1.7674, LR: 0.000445
[12:49:27] Epoch [165/300], Step [140/384], Loss: 2.6225, LR: 0.000445
[12:49:29] Epoch [165/300], Step [160/384], Loss: 1.7540, LR: 0.000445
[12:49:32] Epoch [165/300], Step [180/384], Loss: 1.9517, LR: 0.000445
[12:49:34] Epoch [165/300], Step [200/384], Loss: 1.9962, LR: 0.000445
[12:49:36] Epoch [165/300], Step [220/384], Loss: 1.7869, LR: 0.000445
[12:49:38] Epoch [165/300], Step [240/384], Loss: 2.7495, LR: 0.000445
[12:49:40] Epoch [165/300], Step [260/384], Loss: 1.6333, LR: 0.000445
[12:49:42] Epoch [165/300], Step [280/384], Loss: 2.2514, LR: 0.000445
[12:49:45] Epoch [165/300], Step [300/384], Loss: 2.3746, LR: 0.000445
[12:49:47] Epoch [165/300], Step [320/384], Loss: 1.4264, LR: 0.000445
[12:49:49] Epoch [165/300], Step [340/384], Loss: 1.9208, LR: 0.000445
[12:49:51] Epoch [165/300], Step [360/384], Loss: 2.4559, LR: 0.000445
[12:49:53] Epoch [165/300], Step [380/384], Loss: 1.7586, LR: 0.000445
[12:49:53] Epoch 165 Complete. Avg Loss: 1.7829, LR: 0.000445
[12:49:53] Epoch [166/300], Step [0/384], Loss: 2.0174, LR: 0.000439
[12:49:55] Epoch [166/300], Step [20/384], Loss: 1.6601, LR: 0.000439
[12:49:57] Epoch [166/300], Step [40/384], Loss: 1.4381, LR: 0.000439
[12:50:00] Epoch [166/300], Step [60/384], Loss: 1.4169, LR: 0.000439
[12:50:02] Epoch [166/300], Step [80/384], Loss: 2.2947, LR: 0.000439
[12:50:04] Epoch [166/300], Step [100/384], Loss: 1.3690, LR: 0.000439
[12:50:06] Epoch [166/300], Step [120/384], Loss: 1.6996, LR: 0.000439
[12:50:08] Epoch [166/300], Step [140/384], Loss: 2.0516, LR: 0.000439
[12:50:11] Epoch [166/300], Step [160/384], Loss: 1.9915, LR: 0.000439
[12:50:13] Epoch [166/300], Step [180/384], Loss: 1.8527, LR: 0.000439
[12:50:15] Epoch [166/300], Step [200/384], Loss: 1.7671, LR: 0.000439
[12:50:17] Epoch [166/300], Step [220/384], Loss: 1.3784, LR: 0.000439
[12:50:19] Epoch [166/300], Step [240/384], Loss: 1.4988, LR: 0.000439
[12:50:21] Epoch [166/300], Step [260/384], Loss: 1.7488, LR: 0.000439
[12:50:24] Epoch [166/300], Step [280/384], Loss: 1.7775, LR: 0.000439
[12:50:26] Epoch [166/300], Step [300/384], Loss: 1.8147, LR: 0.000439
[12:50:28] Epoch [166/300], Step [320/384], Loss: 1.2448, LR: 0.000439
[12:50:30] Epoch [166/300], Step [340/384], Loss: 1.4656, LR: 0.000439
[12:50:32] Epoch [166/300], Step [360/384], Loss: 1.7537, LR: 0.000439
[12:50:34] Epoch [166/300], Step [380/384], Loss: 1.7371, LR: 0.000439
[12:50:34] Epoch 166 Complete. Avg Loss: 1.7727, LR: 0.000439
[12:50:35] Epoch [167/300], Step [0/384], Loss: 1.6363, LR: 0.000434
[12:50:37] Epoch [167/300], Step [20/384], Loss: 1.9596, LR: 0.000434
[12:50:39] Epoch [167/300], Step [40/384], Loss: 1.3731, LR: 0.000434
[12:50:41] Epoch [167/300], Step [60/384], Loss: 1.8159, LR: 0.000434
[12:50:43] Epoch [167/300], Step [80/384], Loss: 1.4926, LR: 0.000434
[12:50:45] Epoch [167/300], Step [100/384], Loss: 1.4776, LR: 0.000434
[12:50:47] Epoch [167/300], Step [120/384], Loss: 1.5553, LR: 0.000434
[12:50:49] Epoch [167/300], Step [140/384], Loss: 1.9809, LR: 0.000434
[12:50:51] Epoch [167/300], Step [160/384], Loss: 1.3101, LR: 0.000434
[12:50:53] Epoch [167/300], Step [180/384], Loss: 1.5321, LR: 0.000434
[12:50:56] Epoch [167/300], Step [200/384], Loss: 1.6265, LR: 0.000434
[12:50:58] Epoch [167/300], Step [220/384], Loss: 2.0856, LR: 0.000434
[12:51:00] Epoch [167/300], Step [240/384], Loss: 1.6543, LR: 0.000434
[12:51:02] Epoch [167/300], Step [260/384], Loss: 2.3028, LR: 0.000434
[12:51:05] Epoch [167/300], Step [280/384], Loss: 1.8117, LR: 0.000434
[12:51:07] Epoch [167/300], Step [300/384], Loss: 1.8586, LR: 0.000434
[12:51:09] Epoch [167/300], Step [320/384], Loss: 2.2850, LR: 0.000434
[12:51:11] Epoch [167/300], Step [340/384], Loss: 1.2812, LR: 0.000434
[12:51:13] Epoch [167/300], Step [360/384], Loss: 1.8651, LR: 0.000434
[12:51:15] Epoch [167/300], Step [380/384], Loss: 1.6122, LR: 0.000434
[12:51:15] Epoch 167 Complete. Avg Loss: 1.7592, LR: 0.000434
  -> New best model saved (loss: 1.7592)
[12:51:16] Epoch [168/300], Step [0/384], Loss: 2.4273, LR: 0.000429
[12:51:18] Epoch [168/300], Step [20/384], Loss: 1.9689, LR: 0.000429
[12:51:20] Epoch [168/300], Step [40/384], Loss: 1.9737, LR: 0.000429
[12:51:22] Epoch [168/300], Step [60/384], Loss: 1.6897, LR: 0.000429
[12:51:24] Epoch [168/300], Step [80/384], Loss: 1.8514, LR: 0.000429
[12:51:26] Epoch [168/300], Step [100/384], Loss: 1.2784, LR: 0.000429
[12:51:28] Epoch [168/300], Step [120/384], Loss: 2.2641, LR: 0.000429
[12:51:30] Epoch [168/300], Step [140/384], Loss: 1.5862, LR: 0.000429
[12:51:32] Epoch [168/300], Step [160/384], Loss: 1.6294, LR: 0.000429
[12:51:35] Epoch [168/300], Step [180/384], Loss: 1.5953, LR: 0.000429
[12:51:37] Epoch [168/300], Step [200/384], Loss: 1.4798, LR: 0.000429
[12:51:39] Epoch [168/300], Step [220/384], Loss: 1.6305, LR: 0.000429
[12:51:41] Epoch [168/300], Step [240/384], Loss: 1.5256, LR: 0.000429
[12:51:43] Epoch [168/300], Step [260/384], Loss: 1.9244, LR: 0.000429
[12:51:45] Epoch [168/300], Step [280/384], Loss: 1.3174, LR: 0.000429
[12:51:47] Epoch [168/300], Step [300/384], Loss: 1.6765, LR: 0.000429
[12:51:50] Epoch [168/300], Step [320/384], Loss: 1.8827, LR: 0.000429
[12:51:52] Epoch [168/300], Step [340/384], Loss: 1.8340, LR: 0.000429
[12:51:54] Epoch [168/300], Step [360/384], Loss: 1.6689, LR: 0.000429
[12:51:57] Epoch [168/300], Step [380/384], Loss: 1.7310, LR: 0.000429
[12:51:57] Epoch 168 Complete. Avg Loss: 1.7653, LR: 0.000429
[12:51:57] Epoch [169/300], Step [0/384], Loss: 2.1170, LR: 0.000424
[12:51:59] Epoch [169/300], Step [20/384], Loss: 1.9657, LR: 0.000424
[12:52:01] Epoch [169/300], Step [40/384], Loss: 2.2749, LR: 0.000424
[12:52:03] Epoch [169/300], Step [60/384], Loss: 1.5696, LR: 0.000424
[12:52:05] Epoch [169/300], Step [80/384], Loss: 1.3164, LR: 0.000424
[12:52:08] Epoch [169/300], Step [100/384], Loss: 1.5497, LR: 0.000424
[12:52:10] Epoch [169/300], Step [120/384], Loss: 1.5544, LR: 0.000424
[12:52:12] Epoch [169/300], Step [140/384], Loss: 1.2497, LR: 0.000424
[12:52:14] Epoch [169/300], Step [160/384], Loss: 1.5653, LR: 0.000424
[12:52:16] Epoch [169/300], Step [180/384], Loss: 2.3660, LR: 0.000424
[12:52:18] Epoch [169/300], Step [200/384], Loss: 1.3091, LR: 0.000424
[12:52:20] Epoch [169/300], Step [220/384], Loss: 2.9053, LR: 0.000424
[12:52:22] Epoch [169/300], Step [240/384], Loss: 2.0192, LR: 0.000424
[12:52:24] Epoch [169/300], Step [260/384], Loss: 1.8486, LR: 0.000424
[12:52:27] Epoch [169/300], Step [280/384], Loss: 1.4227, LR: 0.000424
[12:52:29] Epoch [169/300], Step [300/384], Loss: 2.0261, LR: 0.000424
[12:52:31] Epoch [169/300], Step [320/384], Loss: 2.0593, LR: 0.000424
[12:52:34] Epoch [169/300], Step [340/384], Loss: 1.6504, LR: 0.000424
[12:52:36] Epoch [169/300], Step [360/384], Loss: 1.8695, LR: 0.000424
[12:52:38] Epoch [169/300], Step [380/384], Loss: 1.4498, LR: 0.000424
[12:52:38] Epoch 169 Complete. Avg Loss: 1.7558, LR: 0.000424
  -> New best model saved (loss: 1.7558)
[12:52:38] Epoch [170/300], Step [0/384], Loss: 1.6042, LR: 0.000418
[12:52:40] Epoch [170/300], Step [20/384], Loss: 1.5411, LR: 0.000418
[12:52:43] Epoch [170/300], Step [40/384], Loss: 1.7297, LR: 0.000418
[12:52:45] Epoch [170/300], Step [60/384], Loss: 1.6954, LR: 0.000418
[12:52:47] Epoch [170/300], Step [80/384], Loss: 1.9765, LR: 0.000418
[12:52:49] Epoch [170/300], Step [100/384], Loss: 2.1365, LR: 0.000418
[12:52:51] Epoch [170/300], Step [120/384], Loss: 1.3377, LR: 0.000418
[12:52:53] Epoch [170/300], Step [140/384], Loss: 1.9402, LR: 0.000418
[12:52:56] Epoch [170/300], Step [160/384], Loss: 1.4232, LR: 0.000418
[12:52:58] Epoch [170/300], Step [180/384], Loss: 1.4746, LR: 0.000418
[12:53:01] Epoch [170/300], Step [200/384], Loss: 1.6352, LR: 0.000418
[12:53:03] Epoch [170/300], Step [220/384], Loss: 1.2861, LR: 0.000418
[12:53:06] Epoch [170/300], Step [240/384], Loss: 1.8534, LR: 0.000418
[12:53:08] Epoch [170/300], Step [260/384], Loss: 2.0877, LR: 0.000418
[12:53:11] Epoch [170/300], Step [280/384], Loss: 1.6207, LR: 0.000418
[12:53:13] Epoch [170/300], Step [300/384], Loss: 1.4299, LR: 0.000418
[12:53:15] Epoch [170/300], Step [320/384], Loss: 1.2854, LR: 0.000418
[12:53:17] Epoch [170/300], Step [340/384], Loss: 1.8566, LR: 0.000418
[12:53:19] Epoch [170/300], Step [360/384], Loss: 1.7295, LR: 0.000418
[12:53:22] Epoch [170/300], Step [380/384], Loss: 1.4121, LR: 0.000418
[12:53:22] Epoch 170 Complete. Avg Loss: 1.7339, LR: 0.000418
  -> New best model saved (loss: 1.7339)
[12:53:22] Epoch [171/300], Step [0/384], Loss: 1.2729, LR: 0.000413
[12:53:24] Epoch [171/300], Step [20/384], Loss: 1.3724, LR: 0.000413
[12:53:27] Epoch [171/300], Step [40/384], Loss: 1.8350, LR: 0.000413
[12:53:29] Epoch [171/300], Step [60/384], Loss: 1.6666, LR: 0.000413
[12:53:31] Epoch [171/300], Step [80/384], Loss: 1.8926, LR: 0.000413
[12:53:33] Epoch [171/300], Step [100/384], Loss: 2.1923, LR: 0.000413
[12:53:35] Epoch [171/300], Step [120/384], Loss: 1.8577, LR: 0.000413
[12:53:38] Epoch [171/300], Step [140/384], Loss: 1.5843, LR: 0.000413
[12:53:40] Epoch [171/300], Step [160/384], Loss: 1.5509, LR: 0.000413
[12:53:42] Epoch [171/300], Step [180/384], Loss: 2.4881, LR: 0.000413
[12:53:44] Epoch [171/300], Step [200/384], Loss: 1.3181, LR: 0.000413
[12:53:46] Epoch [171/300], Step [220/384], Loss: 1.8073, LR: 0.000413
[12:53:49] Epoch [171/300], Step [240/384], Loss: 1.1599, LR: 0.000413
[12:53:51] Epoch [171/300], Step [260/384], Loss: 1.7377, LR: 0.000413
[12:53:53] Epoch [171/300], Step [280/384], Loss: 1.8313, LR: 0.000413
[12:53:55] Epoch [171/300], Step [300/384], Loss: 1.7798, LR: 0.000413
[12:53:57] Epoch [171/300], Step [320/384], Loss: 1.6986, LR: 0.000413
[12:53:59] Epoch [171/300], Step [340/384], Loss: 1.7720, LR: 0.000413
[12:54:02] Epoch [171/300], Step [360/384], Loss: 1.2788, LR: 0.000413
[12:54:04] Epoch [171/300], Step [380/384], Loss: 2.1228, LR: 0.000413
[12:54:04] Epoch 171 Complete. Avg Loss: 1.7372, LR: 0.000413
[12:54:05] Epoch [172/300], Step [0/384], Loss: 1.6117, LR: 0.000408
[12:54:07] Epoch [172/300], Step [20/384], Loss: 1.9158, LR: 0.000408
[12:54:09] Epoch [172/300], Step [40/384], Loss: 1.1582, LR: 0.000408
[12:54:11] Epoch [172/300], Step [60/384], Loss: 1.5658, LR: 0.000408
[12:54:14] Epoch [172/300], Step [80/384], Loss: 1.5068, LR: 0.000408
[12:54:16] Epoch [172/300], Step [100/384], Loss: 1.7093, LR: 0.000408
[12:54:18] Epoch [172/300], Step [120/384], Loss: 1.6230, LR: 0.000408
[12:54:21] Epoch [172/300], Step [140/384], Loss: 1.6720, LR: 0.000408
[12:54:23] Epoch [172/300], Step [160/384], Loss: 1.6497, LR: 0.000408
[12:54:25] Epoch [172/300], Step [180/384], Loss: 1.3048, LR: 0.000408
[12:54:27] Epoch [172/300], Step [200/384], Loss: 1.3178, LR: 0.000408
[12:54:29] Epoch [172/300], Step [220/384], Loss: 1.9800, LR: 0.000408
[12:54:32] Epoch [172/300], Step [240/384], Loss: 1.5616, LR: 0.000408
[12:54:34] Epoch [172/300], Step [260/384], Loss: 1.9714, LR: 0.000408
[12:54:36] Epoch [172/300], Step [280/384], Loss: 1.5791, LR: 0.000408
[12:54:38] Epoch [172/300], Step [300/384], Loss: 1.5273, LR: 0.000408
[12:54:40] Epoch [172/300], Step [320/384], Loss: 1.3813, LR: 0.000408
[12:54:42] Epoch [172/300], Step [340/384], Loss: 2.3646, LR: 0.000408
[12:54:44] Epoch [172/300], Step [360/384], Loss: 1.3073, LR: 0.000408
[12:54:46] Epoch [172/300], Step [380/384], Loss: 1.9376, LR: 0.000408
[12:54:47] Epoch 172 Complete. Avg Loss: 1.7321, LR: 0.000408
  -> New best model saved (loss: 1.7321)
[12:54:47] Epoch [173/300], Step [0/384], Loss: 1.5699, LR: 0.000403
[12:54:49] Epoch [173/300], Step [20/384], Loss: 1.5330, LR: 0.000403
[12:54:51] Epoch [173/300], Step [40/384], Loss: 1.5913, LR: 0.000403
[12:54:54] Epoch [173/300], Step [60/384], Loss: 2.1727, LR: 0.000403
[12:54:56] Epoch [173/300], Step [80/384], Loss: 1.9025, LR: 0.000403
[12:54:58] Epoch [173/300], Step [100/384], Loss: 1.6914, LR: 0.000403
[12:55:00] Epoch [173/300], Step [120/384], Loss: 1.5075, LR: 0.000403
[12:55:03] Epoch [173/300], Step [140/384], Loss: 1.6997, LR: 0.000403
[12:55:05] Epoch [173/300], Step [160/384], Loss: 1.8097, LR: 0.000403
[12:55:07] Epoch [173/300], Step [180/384], Loss: 1.2964, LR: 0.000403
[12:55:09] Epoch [173/300], Step [200/384], Loss: 1.9036, LR: 0.000403
[12:55:11] Epoch [173/300], Step [220/384], Loss: 2.1996, LR: 0.000403
[12:55:13] Epoch [173/300], Step [240/384], Loss: 1.6123, LR: 0.000403
[12:55:15] Epoch [173/300], Step [260/384], Loss: 2.3777, LR: 0.000403
[12:55:17] Epoch [173/300], Step [280/384], Loss: 1.7153, LR: 0.000403
[12:55:20] Epoch [173/300], Step [300/384], Loss: 1.5444, LR: 0.000403
[12:55:22] Epoch [173/300], Step [320/384], Loss: 1.7373, LR: 0.000403
[12:55:24] Epoch [173/300], Step [340/384], Loss: 1.7706, LR: 0.000403
[12:55:26] Epoch [173/300], Step [360/384], Loss: 1.7943, LR: 0.000403
[12:55:28] Epoch [173/300], Step [380/384], Loss: 0.9994, LR: 0.000403
[12:55:28] Epoch 173 Complete. Avg Loss: 1.7219, LR: 0.000403
  -> New best model saved (loss: 1.7219)
[12:55:29] Epoch [174/300], Step [0/384], Loss: 1.4333, LR: 0.000398
[12:55:31] Epoch [174/300], Step [20/384], Loss: 1.8537, LR: 0.000398
[12:55:33] Epoch [174/300], Step [40/384], Loss: 1.5253, LR: 0.000398
[12:55:35] Epoch [174/300], Step [60/384], Loss: 1.3374, LR: 0.000398
[12:55:37] Epoch [174/300], Step [80/384], Loss: 1.8277, LR: 0.000398
[12:55:39] Epoch [174/300], Step [100/384], Loss: 1.8336, LR: 0.000398
[12:55:41] Epoch [174/300], Step [120/384], Loss: 1.8418, LR: 0.000398
[12:55:44] Epoch [174/300], Step [140/384], Loss: 1.7662, LR: 0.000398
[12:55:46] Epoch [174/300], Step [160/384], Loss: 1.2310, LR: 0.000398
[12:55:48] Epoch [174/300], Step [180/384], Loss: 1.7446, LR: 0.000398
[12:55:50] Epoch [174/300], Step [200/384], Loss: 1.5867, LR: 0.000398
[12:55:52] Epoch [174/300], Step [220/384], Loss: 1.5342, LR: 0.000398
[12:55:55] Epoch [174/300], Step [240/384], Loss: 1.7386, LR: 0.000398
[12:55:57] Epoch [174/300], Step [260/384], Loss: 1.6621, LR: 0.000398
[12:55:59] Epoch [174/300], Step [280/384], Loss: 1.7458, LR: 0.000398
[12:56:01] Epoch [174/300], Step [300/384], Loss: 1.6053, LR: 0.000398
[12:56:04] Epoch [174/300], Step [320/384], Loss: 1.4584, LR: 0.000398
[12:56:06] Epoch [174/300], Step [340/384], Loss: 1.3160, LR: 0.000398
[12:56:08] Epoch [174/300], Step [360/384], Loss: 2.0732, LR: 0.000398
[12:56:10] Epoch [174/300], Step [380/384], Loss: 1.4861, LR: 0.000398
[12:56:10] Epoch 174 Complete. Avg Loss: 1.7196, LR: 0.000398
  -> New best model saved (loss: 1.7196)
[12:56:11] Epoch [175/300], Step [0/384], Loss: 1.7008, LR: 0.000393
[12:56:13] Epoch [175/300], Step [20/384], Loss: 1.9209, LR: 0.000393
[12:56:15] Epoch [175/300], Step [40/384], Loss: 1.7549, LR: 0.000393
[12:56:17] Epoch [175/300], Step [60/384], Loss: 1.4415, LR: 0.000393
[12:56:20] Epoch [175/300], Step [80/384], Loss: 1.5804, LR: 0.000393
[12:56:22] Epoch [175/300], Step [100/384], Loss: 1.7327, LR: 0.000393
[12:56:24] Epoch [175/300], Step [120/384], Loss: 1.3179, LR: 0.000393
[12:56:26] Epoch [175/300], Step [140/384], Loss: 1.4239, LR: 0.000393
[12:56:28] Epoch [175/300], Step [160/384], Loss: 1.8354, LR: 0.000393
[12:56:30] Epoch [175/300], Step [180/384], Loss: 1.6248, LR: 0.000393
[12:56:32] Epoch [175/300], Step [200/384], Loss: 1.6022, LR: 0.000393
[12:56:34] Epoch [175/300], Step [220/384], Loss: 2.3585, LR: 0.000393
[12:56:37] Epoch [175/300], Step [240/384], Loss: 1.2147, LR: 0.000393
[12:56:39] Epoch [175/300], Step [260/384], Loss: 1.5778, LR: 0.000393
[12:56:41] Epoch [175/300], Step [280/384], Loss: 1.3444, LR: 0.000393
[12:56:43] Epoch [175/300], Step [300/384], Loss: 2.0510, LR: 0.000393
[12:56:45] Epoch [175/300], Step [320/384], Loss: 1.9422, LR: 0.000393
[12:56:47] Epoch [175/300], Step [340/384], Loss: 1.2681, LR: 0.000393
[12:56:49] Epoch [175/300], Step [360/384], Loss: 1.2629, LR: 0.000393
[12:56:52] Epoch [175/300], Step [380/384], Loss: 1.9198, LR: 0.000393
[12:56:52] Epoch 175 Complete. Avg Loss: 1.7073, LR: 0.000393
  -> New best model saved (loss: 1.7073)
[12:56:52] Epoch [176/300], Step [0/384], Loss: 2.0319, LR: 0.000388
[12:56:54] Epoch [176/300], Step [20/384], Loss: 1.4150, LR: 0.000388
[12:56:57] Epoch [176/300], Step [40/384], Loss: 1.3602, LR: 0.000388
[12:56:59] Epoch [176/300], Step [60/384], Loss: 1.4279, LR: 0.000388
[12:57:01] Epoch [176/300], Step [80/384], Loss: 1.7876, LR: 0.000388
[12:57:03] Epoch [176/300], Step [100/384], Loss: 1.9379, LR: 0.000388
[12:57:05] Epoch [176/300], Step [120/384], Loss: 1.9255, LR: 0.000388
[12:57:07] Epoch [176/300], Step [140/384], Loss: 1.7088, LR: 0.000388
[12:57:10] Epoch [176/300], Step [160/384], Loss: 2.0389, LR: 0.000388
[12:57:12] Epoch [176/300], Step [180/384], Loss: 1.2797, LR: 0.000388
[12:57:14] Epoch [176/300], Step [200/384], Loss: 1.9566, LR: 0.000388
[12:57:16] Epoch [176/300], Step [220/384], Loss: 1.6847, LR: 0.000388
[12:57:18] Epoch [176/300], Step [240/384], Loss: 1.8231, LR: 0.000388
[12:57:20] Epoch [176/300], Step [260/384], Loss: 2.1918, LR: 0.000388
[12:57:23] Epoch [176/300], Step [280/384], Loss: 1.8806, LR: 0.000388
[12:57:25] Epoch [176/300], Step [300/384], Loss: 1.4244, LR: 0.000388
[12:57:27] Epoch [176/300], Step [320/384], Loss: 2.5229, LR: 0.000388
[12:57:29] Epoch [176/300], Step [340/384], Loss: 1.5632, LR: 0.000388
[12:57:31] Epoch [176/300], Step [360/384], Loss: 1.9172, LR: 0.000388
[12:57:34] Epoch [176/300], Step [380/384], Loss: 2.1882, LR: 0.000388
[12:57:34] Epoch 176 Complete. Avg Loss: 1.7029, LR: 0.000388
  -> New best model saved (loss: 1.7029)
[12:57:34] Epoch [177/300], Step [0/384], Loss: 1.6862, LR: 0.000382
[12:57:36] Epoch [177/300], Step [20/384], Loss: 1.6077, LR: 0.000382
[12:57:39] Epoch [177/300], Step [40/384], Loss: 1.2072, LR: 0.000382
[12:57:41] Epoch [177/300], Step [60/384], Loss: 1.7398, LR: 0.000382
[12:57:43] Epoch [177/300], Step [80/384], Loss: 2.5005, LR: 0.000382
[12:57:45] Epoch [177/300], Step [100/384], Loss: 1.5686, LR: 0.000382
[12:57:47] Epoch [177/300], Step [120/384], Loss: 1.6642, LR: 0.000382
[12:57:49] Epoch [177/300], Step [140/384], Loss: 1.8460, LR: 0.000382
[12:57:51] Epoch [177/300], Step [160/384], Loss: 1.6510, LR: 0.000382
[12:57:53] Epoch [177/300], Step [180/384], Loss: 1.4500, LR: 0.000382
[12:57:56] Epoch [177/300], Step [200/384], Loss: 1.4350, LR: 0.000382
[12:57:58] Epoch [177/300], Step [220/384], Loss: 1.7902, LR: 0.000382
[12:58:00] Epoch [177/300], Step [240/384], Loss: 1.6631, LR: 0.000382
[12:58:02] Epoch [177/300], Step [260/384], Loss: 1.8826, LR: 0.000382
[12:58:04] Epoch [177/300], Step [280/384], Loss: 1.8591, LR: 0.000382
[12:58:07] Epoch [177/300], Step [300/384], Loss: 1.3932, LR: 0.000382
[12:58:09] Epoch [177/300], Step [320/384], Loss: 2.1438, LR: 0.000382
[12:58:11] Epoch [177/300], Step [340/384], Loss: 1.6826, LR: 0.000382
[12:58:13] Epoch [177/300], Step [360/384], Loss: 1.4396, LR: 0.000382
[12:58:15] Epoch [177/300], Step [380/384], Loss: 1.6603, LR: 0.000382
[12:58:15] Epoch 177 Complete. Avg Loss: 1.6944, LR: 0.000382
  -> New best model saved (loss: 1.6944)
[12:58:16] Epoch [178/300], Step [0/384], Loss: 1.8529, LR: 0.000377
[12:58:18] Epoch [178/300], Step [20/384], Loss: 1.1577, LR: 0.000377
[12:58:20] Epoch [178/300], Step [40/384], Loss: 1.9242, LR: 0.000377
[12:58:22] Epoch [178/300], Step [60/384], Loss: 1.6604, LR: 0.000377
[12:58:24] Epoch [178/300], Step [80/384], Loss: 1.9414, LR: 0.000377
[12:58:27] Epoch [178/300], Step [100/384], Loss: 2.0338, LR: 0.000377
[12:58:29] Epoch [178/300], Step [120/384], Loss: 2.0486, LR: 0.000377
[12:58:31] Epoch [178/300], Step [140/384], Loss: 1.5922, LR: 0.000377
[12:58:33] Epoch [178/300], Step [160/384], Loss: 1.6987, LR: 0.000377
[12:58:35] Epoch [178/300], Step [180/384], Loss: 2.0938, LR: 0.000377
[12:58:37] Epoch [178/300], Step [200/384], Loss: 2.0380, LR: 0.000377
[12:58:40] Epoch [178/300], Step [220/384], Loss: 1.6192, LR: 0.000377
[12:58:42] Epoch [178/300], Step [240/384], Loss: 1.3762, LR: 0.000377
[12:58:44] Epoch [178/300], Step [260/384], Loss: 1.8111, LR: 0.000377
[12:58:46] Epoch [178/300], Step [280/384], Loss: 1.7386, LR: 0.000377
[12:58:49] Epoch [178/300], Step [300/384], Loss: 1.7400, LR: 0.000377
[12:58:51] Epoch [178/300], Step [320/384], Loss: 1.8336, LR: 0.000377
[12:58:53] Epoch [178/300], Step [340/384], Loss: 1.4421, LR: 0.000377
[12:58:55] Epoch [178/300], Step [360/384], Loss: 1.5352, LR: 0.000377
[12:58:57] Epoch [178/300], Step [380/384], Loss: 1.9838, LR: 0.000377
[12:58:57] Epoch 178 Complete. Avg Loss: 1.6998, LR: 0.000377
[12:58:58] Epoch [179/300], Step [0/384], Loss: 2.1031, LR: 0.000372
[12:59:00] Epoch [179/300], Step [20/384], Loss: 1.5088, LR: 0.000372
[12:59:02] Epoch [179/300], Step [40/384], Loss: 1.5721, LR: 0.000372
[12:59:04] Epoch [179/300], Step [60/384], Loss: 1.5303, LR: 0.000372
[12:59:06] Epoch [179/300], Step [80/384], Loss: 1.8837, LR: 0.000372
[12:59:08] Epoch [179/300], Step [100/384], Loss: 1.3664, LR: 0.000372
[12:59:10] Epoch [179/300], Step [120/384], Loss: 1.8693, LR: 0.000372
[12:59:13] Epoch [179/300], Step [140/384], Loss: 1.5204, LR: 0.000372
[12:59:15] Epoch [179/300], Step [160/384], Loss: 1.3733, LR: 0.000372
[12:59:17] Epoch [179/300], Step [180/384], Loss: 2.0951, LR: 0.000372
[12:59:19] Epoch [179/300], Step [200/384], Loss: 1.6447, LR: 0.000372
[12:59:21] Epoch [179/300], Step [220/384], Loss: 1.6809, LR: 0.000372
[12:59:23] Epoch [179/300], Step [240/384], Loss: 1.9627, LR: 0.000372
[12:59:25] Epoch [179/300], Step [260/384], Loss: 2.2441, LR: 0.000372
[12:59:28] Epoch [179/300], Step [280/384], Loss: 1.6435, LR: 0.000372
[12:59:30] Epoch [179/300], Step [300/384], Loss: 2.1020, LR: 0.000372
[12:59:32] Epoch [179/300], Step [320/384], Loss: 1.6410, LR: 0.000372
[12:59:34] Epoch [179/300], Step [340/384], Loss: 1.5921, LR: 0.000372
[12:59:37] Epoch [179/300], Step [360/384], Loss: 1.6641, LR: 0.000372
[12:59:38] Epoch [179/300], Step [380/384], Loss: 1.4043, LR: 0.000372
[12:59:39] Epoch 179 Complete. Avg Loss: 1.6831, LR: 0.000372
  -> New best model saved (loss: 1.6831)
[12:59:39] Epoch [180/300], Step [0/384], Loss: 2.2042, LR: 0.000367
[12:59:41] Epoch [180/300], Step [20/384], Loss: 1.8792, LR: 0.000367
[12:59:43] Epoch [180/300], Step [40/384], Loss: 1.5393, LR: 0.000367
[12:59:45] Epoch [180/300], Step [60/384], Loss: 2.0452, LR: 0.000367
[12:59:47] Epoch [180/300], Step [80/384], Loss: 2.1484, LR: 0.000367
[12:59:49] Epoch [180/300], Step [100/384], Loss: 1.5578, LR: 0.000367
[12:59:51] Epoch [180/300], Step [120/384], Loss: 1.7714, LR: 0.000367
[12:59:53] Epoch [180/300], Step [140/384], Loss: 1.5112, LR: 0.000367
[12:59:55] Epoch [180/300], Step [160/384], Loss: 2.4836, LR: 0.000367
[12:59:58] Epoch [180/300], Step [180/384], Loss: 1.3481, LR: 0.000367
[13:00:00] Epoch [180/300], Step [200/384], Loss: 1.9230, LR: 0.000367
[13:00:02] Epoch [180/300], Step [220/384], Loss: 1.4588, LR: 0.000367
[13:00:04] Epoch [180/300], Step [240/384], Loss: 1.6506, LR: 0.000367
[13:00:06] Epoch [180/300], Step [260/384], Loss: 2.0823, LR: 0.000367
[13:00:09] Epoch [180/300], Step [280/384], Loss: 1.8938, LR: 0.000367
[13:00:11] Epoch [180/300], Step [300/384], Loss: 2.3109, LR: 0.000367
[13:00:13] Epoch [180/300], Step [320/384], Loss: 1.6283, LR: 0.000367
[13:00:15] Epoch [180/300], Step [340/384], Loss: 1.5050, LR: 0.000367
[13:00:18] Epoch [180/300], Step [360/384], Loss: 1.7116, LR: 0.000367
[13:00:20] Epoch [180/300], Step [380/384], Loss: 1.4329, LR: 0.000367
[13:00:20] Epoch 180 Complete. Avg Loss: 1.6809, LR: 0.000367
  -> New best model saved (loss: 1.6809)
[13:00:20] Epoch [181/300], Step [0/384], Loss: 2.0129, LR: 0.000362
[13:00:23] Epoch [181/300], Step [20/384], Loss: 1.6624, LR: 0.000362
[13:00:25] Epoch [181/300], Step [40/384], Loss: 1.8738, LR: 0.000362
[13:00:27] Epoch [181/300], Step [60/384], Loss: 1.6016, LR: 0.000362
[13:00:29] Epoch [181/300], Step [80/384], Loss: 1.5689, LR: 0.000362
[13:00:31] Epoch [181/300], Step [100/384], Loss: 1.8887, LR: 0.000362
[13:00:33] Epoch [181/300], Step [120/384], Loss: 1.6559, LR: 0.000362
[13:00:35] Epoch [181/300], Step [140/384], Loss: 2.2914, LR: 0.000362
[13:00:37] Epoch [181/300], Step [160/384], Loss: 1.7882, LR: 0.000362
[13:00:39] Epoch [181/300], Step [180/384], Loss: 1.6244, LR: 0.000362
[13:00:42] Epoch [181/300], Step [200/384], Loss: 1.4894, LR: 0.000362
[13:00:44] Epoch [181/300], Step [220/384], Loss: 1.5690, LR: 0.000362
[13:00:46] Epoch [181/300], Step [240/384], Loss: 1.8414, LR: 0.000362
[13:00:48] Epoch [181/300], Step [260/384], Loss: 1.6232, LR: 0.000362
[13:00:50] Epoch [181/300], Step [280/384], Loss: 2.4077, LR: 0.000362
[13:00:52] Epoch [181/300], Step [300/384], Loss: 1.6186, LR: 0.000362
[13:00:55] Epoch [181/300], Step [320/384], Loss: 1.5385, LR: 0.000362
[13:00:57] Epoch [181/300], Step [340/384], Loss: 1.8653, LR: 0.000362
[13:00:59] Epoch [181/300], Step [360/384], Loss: 1.5869, LR: 0.000362
[13:01:02] Epoch [181/300], Step [380/384], Loss: 1.5554, LR: 0.000362
[13:01:02] Epoch 181 Complete. Avg Loss: 1.6740, LR: 0.000362
  -> New best model saved (loss: 1.6740)
[13:01:02] Epoch [182/300], Step [0/384], Loss: 2.1311, LR: 0.000357
[13:01:05] Epoch [182/300], Step [20/384], Loss: 1.5981, LR: 0.000357
[13:01:07] Epoch [182/300], Step [40/384], Loss: 1.7495, LR: 0.000357
[13:01:09] Epoch [182/300], Step [60/384], Loss: 1.6087, LR: 0.000357
[13:01:11] Epoch [182/300], Step [80/384], Loss: 1.9055, LR: 0.000357
[13:01:13] Epoch [182/300], Step [100/384], Loss: 1.4159, LR: 0.000357
[13:01:16] Epoch [182/300], Step [120/384], Loss: 1.9159, LR: 0.000357
[13:01:18] Epoch [182/300], Step [140/384], Loss: 1.9145, LR: 0.000357
[13:01:20] Epoch [182/300], Step [160/384], Loss: 1.8251, LR: 0.000357
[13:01:22] Epoch [182/300], Step [180/384], Loss: 1.5809, LR: 0.000357
[13:01:24] Epoch [182/300], Step [200/384], Loss: 1.8402, LR: 0.000357
[13:01:26] Epoch [182/300], Step [220/384], Loss: 1.9100, LR: 0.000357
[13:01:28] Epoch [182/300], Step [240/384], Loss: 1.0938, LR: 0.000357
[13:01:30] Epoch [182/300], Step [260/384], Loss: 2.1608, LR: 0.000357
[13:01:32] Epoch [182/300], Step [280/384], Loss: 1.9256, LR: 0.000357
[13:01:35] Epoch [182/300], Step [300/384], Loss: 1.9973, LR: 0.000357
[13:01:37] Epoch [182/300], Step [320/384], Loss: 2.0460, LR: 0.000357
[13:01:39] Epoch [182/300], Step [340/384], Loss: 1.4488, LR: 0.000357
[13:01:41] Epoch [182/300], Step [360/384], Loss: 1.5593, LR: 0.000357
[13:01:43] Epoch [182/300], Step [380/384], Loss: 1.3457, LR: 0.000357
[13:01:44] Epoch 182 Complete. Avg Loss: 1.6583, LR: 0.000357
  -> New best model saved (loss: 1.6583)
[13:01:44] Epoch [183/300], Step [0/384], Loss: 1.2944, LR: 0.000352
[13:01:46] Epoch [183/300], Step [20/384], Loss: 1.7376, LR: 0.000352
[13:01:48] Epoch [183/300], Step [40/384], Loss: 0.9952, LR: 0.000352
[13:01:50] Epoch [183/300], Step [60/384], Loss: 1.7215, LR: 0.000352
[13:01:52] Epoch [183/300], Step [80/384], Loss: 1.3702, LR: 0.000352
[13:01:55] Epoch [183/300], Step [100/384], Loss: 1.6484, LR: 0.000352
[13:01:57] Epoch [183/300], Step [120/384], Loss: 1.7639, LR: 0.000352
[13:01:59] Epoch [183/300], Step [140/384], Loss: 1.7167, LR: 0.000352
[13:02:01] Epoch [183/300], Step [160/384], Loss: 1.6714, LR: 0.000352
[13:02:03] Epoch [183/300], Step [180/384], Loss: 1.7042, LR: 0.000352
[13:02:05] Epoch [183/300], Step [200/384], Loss: 1.4598, LR: 0.000352
[13:02:07] Epoch [183/300], Step [220/384], Loss: 1.6355, LR: 0.000352
[13:02:09] Epoch [183/300], Step [240/384], Loss: 1.6984, LR: 0.000352
[13:02:12] Epoch [183/300], Step [260/384], Loss: 1.5554, LR: 0.000352
[13:02:14] Epoch [183/300], Step [280/384], Loss: 1.3993, LR: 0.000352
[13:02:16] Epoch [183/300], Step [300/384], Loss: 1.6450, LR: 0.000352
[13:02:18] Epoch [183/300], Step [320/384], Loss: 1.6976, LR: 0.000352
[13:02:21] Epoch [183/300], Step [340/384], Loss: 1.3715, LR: 0.000352
[13:02:23] Epoch [183/300], Step [360/384], Loss: 1.6470, LR: 0.000352
[13:02:25] Epoch [183/300], Step [380/384], Loss: 1.5807, LR: 0.000352
[13:02:25] Epoch 183 Complete. Avg Loss: 1.6667, LR: 0.000352
[13:02:26] Epoch [184/300], Step [0/384], Loss: 1.1915, LR: 0.000347
[13:02:28] Epoch [184/300], Step [20/384], Loss: 1.3819, LR: 0.000347
[13:02:30] Epoch [184/300], Step [40/384], Loss: 1.4669, LR: 0.000347
[13:02:32] Epoch [184/300], Step [60/384], Loss: 1.8147, LR: 0.000347
[13:02:34] Epoch [184/300], Step [80/384], Loss: 1.4157, LR: 0.000347
[13:02:36] Epoch [184/300], Step [100/384], Loss: 1.6964, LR: 0.000347
[13:02:38] Epoch [184/300], Step [120/384], Loss: 1.9152, LR: 0.000347
[13:02:40] Epoch [184/300], Step [140/384], Loss: 1.5714, LR: 0.000347
[13:02:43] Epoch [184/300], Step [160/384], Loss: 1.5840, LR: 0.000347
[13:02:45] Epoch [184/300], Step [180/384], Loss: 1.7517, LR: 0.000347
[13:02:47] Epoch [184/300], Step [200/384], Loss: 1.6060, LR: 0.000347
[13:02:49] Epoch [184/300], Step [220/384], Loss: 1.6529, LR: 0.000347
[13:02:51] Epoch [184/300], Step [240/384], Loss: 1.5085, LR: 0.000347
[13:02:54] Epoch [184/300], Step [260/384], Loss: 1.4510, LR: 0.000347
[13:02:56] Epoch [184/300], Step [280/384], Loss: 1.1930, LR: 0.000347
[13:02:58] Epoch [184/300], Step [300/384], Loss: 2.4521, LR: 0.000347
[13:03:00] Epoch [184/300], Step [320/384], Loss: 1.7132, LR: 0.000347
[13:03:03] Epoch [184/300], Step [340/384], Loss: 1.6030, LR: 0.000347
[13:03:05] Epoch [184/300], Step [360/384], Loss: 1.9948, LR: 0.000347
[13:03:07] Epoch [184/300], Step [380/384], Loss: 1.1251, LR: 0.000347
[13:03:07] Epoch 184 Complete. Avg Loss: 1.6538, LR: 0.000347
  -> New best model saved (loss: 1.6538)
[13:03:07] Epoch [185/300], Step [0/384], Loss: 1.8225, LR: 0.000342
[13:03:09] Epoch [185/300], Step [20/384], Loss: 1.3669, LR: 0.000342
[13:03:12] Epoch [185/300], Step [40/384], Loss: 1.4620, LR: 0.000342
[13:03:14] Epoch [185/300], Step [60/384], Loss: 1.4093, LR: 0.000342
[13:03:16] Epoch [185/300], Step [80/384], Loss: 1.3470, LR: 0.000342
[13:03:18] Epoch [185/300], Step [100/384], Loss: 1.7601, LR: 0.000342
[13:03:20] Epoch [185/300], Step [120/384], Loss: 2.0010, LR: 0.000342
[13:03:22] Epoch [185/300], Step [140/384], Loss: 1.9635, LR: 0.000342
[13:03:25] Epoch [185/300], Step [160/384], Loss: 1.7349, LR: 0.000342
[13:03:27] Epoch [185/300], Step [180/384], Loss: 1.9510, LR: 0.000342
[13:03:29] Epoch [185/300], Step [200/384], Loss: 1.5596, LR: 0.000342
[13:03:31] Epoch [185/300], Step [220/384], Loss: 1.4988, LR: 0.000342
[13:03:33] Epoch [185/300], Step [240/384], Loss: 1.7051, LR: 0.000342
[13:03:35] Epoch [185/300], Step [260/384], Loss: 1.6152, LR: 0.000342
[13:03:38] Epoch [185/300], Step [280/384], Loss: 1.4309, LR: 0.000342
[13:03:40] Epoch [185/300], Step [300/384], Loss: 1.9823, LR: 0.000342
[13:03:42] Epoch [185/300], Step [320/384], Loss: 1.5335, LR: 0.000342
[13:03:44] Epoch [185/300], Step [340/384], Loss: 1.7939, LR: 0.000342
[13:03:46] Epoch [185/300], Step [360/384], Loss: 1.2049, LR: 0.000342
[13:03:48] Epoch [185/300], Step [380/384], Loss: 2.0691, LR: 0.000342
[13:03:49] Epoch 185 Complete. Avg Loss: 1.6433, LR: 0.000342
  -> New best model saved (loss: 1.6433)
[13:03:49] Epoch [186/300], Step [0/384], Loss: 1.7563, LR: 0.000337
[13:03:51] Epoch [186/300], Step [20/384], Loss: 1.4479, LR: 0.000337
[13:03:53] Epoch [186/300], Step [40/384], Loss: 1.8839, LR: 0.000337
[13:03:55] Epoch [186/300], Step [60/384], Loss: 1.7256, LR: 0.000337
[13:03:58] Epoch [186/300], Step [80/384], Loss: 1.9792, LR: 0.000337
[13:04:00] Epoch [186/300], Step [100/384], Loss: 1.6784, LR: 0.000337
[13:04:02] Epoch [186/300], Step [120/384], Loss: 1.3389, LR: 0.000337
[13:04:04] Epoch [186/300], Step [140/384], Loss: 1.6691, LR: 0.000337
[13:04:06] Epoch [186/300], Step [160/384], Loss: 1.3166, LR: 0.000337
[13:04:08] Epoch [186/300], Step [180/384], Loss: 1.5441, LR: 0.000337
[13:04:10] Epoch [186/300], Step [200/384], Loss: 1.3395, LR: 0.000337
[13:04:12] Epoch [186/300], Step [220/384], Loss: 1.6782, LR: 0.000337
[13:04:15] Epoch [186/300], Step [240/384], Loss: 1.3819, LR: 0.000337
[13:04:17] Epoch [186/300], Step [260/384], Loss: 1.8594, LR: 0.000337
[13:04:19] Epoch [186/300], Step [280/384], Loss: 1.3911, LR: 0.000337
[13:04:21] Epoch [186/300], Step [300/384], Loss: 1.7087, LR: 0.000337
[13:04:23] Epoch [186/300], Step [320/384], Loss: 1.3233, LR: 0.000337
[13:04:26] Epoch [186/300], Step [340/384], Loss: 1.6877, LR: 0.000337
[13:04:28] Epoch [186/300], Step [360/384], Loss: 1.8020, LR: 0.000337
[13:04:30] Epoch [186/300], Step [380/384], Loss: 2.0986, LR: 0.000337
[13:04:30] Epoch 186 Complete. Avg Loss: 1.6412, LR: 0.000337
  -> New best model saved (loss: 1.6412)
[13:04:31] Epoch [187/300], Step [0/384], Loss: 1.8413, LR: 0.000332
[13:04:33] Epoch [187/300], Step [20/384], Loss: 1.3136, LR: 0.000332
[13:04:35] Epoch [187/300], Step [40/384], Loss: 1.5587, LR: 0.000332
[13:04:37] Epoch [187/300], Step [60/384], Loss: 1.6983, LR: 0.000332
[13:04:39] Epoch [187/300], Step [80/384], Loss: 1.3643, LR: 0.000332
[13:04:41] Epoch [187/300], Step [100/384], Loss: 1.4833, LR: 0.000332
[13:04:43] Epoch [187/300], Step [120/384], Loss: 1.8296, LR: 0.000332
[13:04:45] Epoch [187/300], Step [140/384], Loss: 1.5687, LR: 0.000332
[13:04:47] Epoch [187/300], Step [160/384], Loss: 1.3947, LR: 0.000332
[13:04:50] Epoch [187/300], Step [180/384], Loss: 1.6016, LR: 0.000332
[13:04:52] Epoch [187/300], Step [200/384], Loss: 1.7612, LR: 0.000332
[13:04:54] Epoch [187/300], Step [220/384], Loss: 1.8878, LR: 0.000332
[13:04:56] Epoch [187/300], Step [240/384], Loss: 1.8455, LR: 0.000332
[13:04:58] Epoch [187/300], Step [260/384], Loss: 1.4885, LR: 0.000332
[13:05:00] Epoch [187/300], Step [280/384], Loss: 1.4830, LR: 0.000332
[13:05:03] Epoch [187/300], Step [300/384], Loss: 1.4569, LR: 0.000332
[13:05:05] Epoch [187/300], Step [320/384], Loss: 1.7422, LR: 0.000332
[13:05:07] Epoch [187/300], Step [340/384], Loss: 1.5744, LR: 0.000332
[13:05:10] Epoch [187/300], Step [360/384], Loss: 1.6774, LR: 0.000332
[13:05:12] Epoch [187/300], Step [380/384], Loss: 1.8659, LR: 0.000332
[13:05:12] Epoch 187 Complete. Avg Loss: 1.6249, LR: 0.000332
  -> New best model saved (loss: 1.6249)
[13:05:12] Epoch [188/300], Step [0/384], Loss: 1.4481, LR: 0.000327
[13:05:15] Epoch [188/300], Step [20/384], Loss: 1.8440, LR: 0.000327
[13:05:17] Epoch [188/300], Step [40/384], Loss: 1.0483, LR: 0.000327
[13:05:19] Epoch [188/300], Step [60/384], Loss: 1.8545, LR: 0.000327
[13:05:21] Epoch [188/300], Step [80/384], Loss: 1.5877, LR: 0.000327
[13:05:23] Epoch [188/300], Step [100/384], Loss: 1.6672, LR: 0.000327
[13:05:26] Epoch [188/300], Step [120/384], Loss: 1.4279, LR: 0.000327
[13:05:28] Epoch [188/300], Step [140/384], Loss: 1.1302, LR: 0.000327
[13:05:30] Epoch [188/300], Step [160/384], Loss: 1.4170, LR: 0.000327
[13:05:32] Epoch [188/300], Step [180/384], Loss: 1.5574, LR: 0.000327
[13:05:34] Epoch [188/300], Step [200/384], Loss: 1.4789, LR: 0.000327
[13:05:36] Epoch [188/300], Step [220/384], Loss: 2.0357, LR: 0.000327
[13:05:39] Epoch [188/300], Step [240/384], Loss: 1.5863, LR: 0.000327
[13:05:41] Epoch [188/300], Step [260/384], Loss: 1.6040, LR: 0.000327
[13:05:43] Epoch [188/300], Step [280/384], Loss: 1.8837, LR: 0.000327
[13:05:45] Epoch [188/300], Step [300/384], Loss: 1.8726, LR: 0.000327
[13:05:47] Epoch [188/300], Step [320/384], Loss: 1.7939, LR: 0.000327
[13:05:50] Epoch [188/300], Step [340/384], Loss: 1.2452, LR: 0.000327
[13:05:52] Epoch [188/300], Step [360/384], Loss: 1.4606, LR: 0.000327
[13:05:54] Epoch [188/300], Step [380/384], Loss: 1.8099, LR: 0.000327
[13:05:54] Epoch 188 Complete. Avg Loss: 1.6211, LR: 0.000327
  -> New best model saved (loss: 1.6211)
[13:05:54] Epoch [189/300], Step [0/384], Loss: 1.7134, LR: 0.000322
[13:05:57] Epoch [189/300], Step [20/384], Loss: 2.1856, LR: 0.000322
[13:05:59] Epoch [189/300], Step [40/384], Loss: 1.4066, LR: 0.000322
[13:06:01] Epoch [189/300], Step [60/384], Loss: 1.1059, LR: 0.000322
[13:06:03] Epoch [189/300], Step [80/384], Loss: 1.8299, LR: 0.000322
[13:06:05] Epoch [189/300], Step [100/384], Loss: 1.8419, LR: 0.000322
[13:06:07] Epoch [189/300], Step [120/384], Loss: 1.3308, LR: 0.000322
[13:06:09] Epoch [189/300], Step [140/384], Loss: 1.7205, LR: 0.000322
[13:06:11] Epoch [189/300], Step [160/384], Loss: 1.4507, LR: 0.000322
[13:06:14] Epoch [189/300], Step [180/384], Loss: 1.4604, LR: 0.000322
[13:06:16] Epoch [189/300], Step [200/384], Loss: 1.7632, LR: 0.000322
[13:06:18] Epoch [189/300], Step [220/384], Loss: 1.6635, LR: 0.000322
[13:06:20] Epoch [189/300], Step [240/384], Loss: 2.0873, LR: 0.000322
[13:06:22] Epoch [189/300], Step [260/384], Loss: 2.3987, LR: 0.000322
[13:06:24] Epoch [189/300], Step [280/384], Loss: 1.3484, LR: 0.000322
[13:06:27] Epoch [189/300], Step [300/384], Loss: 1.6985, LR: 0.000322
[13:06:29] Epoch [189/300], Step [320/384], Loss: 1.8461, LR: 0.000322
[13:06:31] Epoch [189/300], Step [340/384], Loss: 1.0435, LR: 0.000322
[13:06:33] Epoch [189/300], Step [360/384], Loss: 1.6226, LR: 0.000322
[13:06:35] Epoch [189/300], Step [380/384], Loss: 1.9771, LR: 0.000322
[13:06:36] Epoch 189 Complete. Avg Loss: 1.6204, LR: 0.000322
  -> New best model saved (loss: 1.6204)
[13:06:36] Epoch [190/300], Step [0/384], Loss: 1.4738, LR: 0.000317
[13:06:38] Epoch [190/300], Step [20/384], Loss: 1.4792, LR: 0.000317
[13:06:40] Epoch [190/300], Step [40/384], Loss: 1.2942, LR: 0.000317
[13:06:43] Epoch [190/300], Step [60/384], Loss: 1.8290, LR: 0.000317
[13:06:45] Epoch [190/300], Step [80/384], Loss: 1.5704, LR: 0.000317
[13:06:47] Epoch [190/300], Step [100/384], Loss: 1.2413, LR: 0.000317
[13:06:49] Epoch [190/300], Step [120/384], Loss: 1.3927, LR: 0.000317
[13:06:52] Epoch [190/300], Step [140/384], Loss: 1.6154, LR: 0.000317
[13:06:54] Epoch [190/300], Step [160/384], Loss: 1.7813, LR: 0.000317
[13:06:56] Epoch [190/300], Step [180/384], Loss: 1.6634, LR: 0.000317
[13:06:58] Epoch [190/300], Step [200/384], Loss: 1.4434, LR: 0.000317
[13:07:00] Epoch [190/300], Step [220/384], Loss: 1.5747, LR: 0.000317
[13:07:02] Epoch [190/300], Step [240/384], Loss: 1.8875, LR: 0.000317
[13:07:04] Epoch [190/300], Step [260/384], Loss: 1.4673, LR: 0.000317
[13:07:07] Epoch [190/300], Step [280/384], Loss: 1.5112, LR: 0.000317
[13:07:09] Epoch [190/300], Step [300/384], Loss: 1.1295, LR: 0.000317
[13:07:11] Epoch [190/300], Step [320/384], Loss: 1.9959, LR: 0.000317
[13:07:13] Epoch [190/300], Step [340/384], Loss: 1.7137, LR: 0.000317
[13:07:15] Epoch [190/300], Step [360/384], Loss: 1.6497, LR: 0.000317
[13:07:17] Epoch [190/300], Step [380/384], Loss: 1.8665, LR: 0.000317
[13:07:17] Epoch 190 Complete. Avg Loss: 1.6106, LR: 0.000317
  -> New best model saved (loss: 1.6106)
[13:07:18] Epoch [191/300], Step [0/384], Loss: 1.3552, LR: 0.000313
[13:07:20] Epoch [191/300], Step [20/384], Loss: 1.1484, LR: 0.000313
[13:07:22] Epoch [191/300], Step [40/384], Loss: 1.4281, LR: 0.000313
[13:07:24] Epoch [191/300], Step [60/384], Loss: 1.4042, LR: 0.000313
[13:07:26] Epoch [191/300], Step [80/384], Loss: 1.3306, LR: 0.000313
[13:07:29] Epoch [191/300], Step [100/384], Loss: 1.2962, LR: 0.000313
[13:07:31] Epoch [191/300], Step [120/384], Loss: 1.6481, LR: 0.000313
[13:07:33] Epoch [191/300], Step [140/384], Loss: 1.8608, LR: 0.000313
[13:07:35] Epoch [191/300], Step [160/384], Loss: 1.3952, LR: 0.000313
[13:07:37] Epoch [191/300], Step [180/384], Loss: 1.8711, LR: 0.000313
[13:07:39] Epoch [191/300], Step [200/384], Loss: 1.5062, LR: 0.000313
[13:07:42] Epoch [191/300], Step [220/384], Loss: 1.6637, LR: 0.000313
[13:07:44] Epoch [191/300], Step [240/384], Loss: 1.9261, LR: 0.000313
[13:07:46] Epoch [191/300], Step [260/384], Loss: 2.0798, LR: 0.000313
[13:07:48] Epoch [191/300], Step [280/384], Loss: 1.3948, LR: 0.000313
[13:07:50] Epoch [191/300], Step [300/384], Loss: 1.4390, LR: 0.000313
[13:07:52] Epoch [191/300], Step [320/384], Loss: 1.5540, LR: 0.000313
[13:07:55] Epoch [191/300], Step [340/384], Loss: 1.2806, LR: 0.000313
[13:07:57] Epoch [191/300], Step [360/384], Loss: 1.6073, LR: 0.000313
[13:07:59] Epoch [191/300], Step [380/384], Loss: 1.2922, LR: 0.000313
[13:07:59] Epoch 191 Complete. Avg Loss: 1.6087, LR: 0.000313
  -> New best model saved (loss: 1.6087)
[13:07:59] Epoch [192/300], Step [0/384], Loss: 1.7584, LR: 0.000308
[13:08:02] Epoch [192/300], Step [20/384], Loss: 1.6080, LR: 0.000308
[13:08:04] Epoch [192/300], Step [40/384], Loss: 1.4253, LR: 0.000308
[13:08:06] Epoch [192/300], Step [60/384], Loss: 1.8531, LR: 0.000308
[13:08:09] Epoch [192/300], Step [80/384], Loss: 1.6100, LR: 0.000308
[13:08:11] Epoch [192/300], Step [100/384], Loss: 1.6929, LR: 0.000308
[13:08:13] Epoch [192/300], Step [120/384], Loss: 1.6810, LR: 0.000308
[13:08:15] Epoch [192/300], Step [140/384], Loss: 1.2112, LR: 0.000308
[13:08:18] Epoch [192/300], Step [160/384], Loss: 1.5267, LR: 0.000308
[13:08:20] Epoch [192/300], Step [180/384], Loss: 1.9910, LR: 0.000308
[13:08:22] Epoch [192/300], Step [200/384], Loss: 1.5309, LR: 0.000308
[13:08:24] Epoch [192/300], Step [220/384], Loss: 1.5109, LR: 0.000308
[13:08:26] Epoch [192/300], Step [240/384], Loss: 1.6525, LR: 0.000308
[13:08:28] Epoch [192/300], Step [260/384], Loss: 1.3010, LR: 0.000308
[13:08:30] Epoch [192/300], Step [280/384], Loss: 1.5609, LR: 0.000308
[13:08:32] Epoch [192/300], Step [300/384], Loss: 1.5742, LR: 0.000308
[13:08:35] Epoch [192/300], Step [320/384], Loss: 1.7134, LR: 0.000308
[13:08:37] Epoch [192/300], Step [340/384], Loss: 1.5609, LR: 0.000308
[13:08:39] Epoch [192/300], Step [360/384], Loss: 1.7912, LR: 0.000308
[13:08:41] Epoch [192/300], Step [380/384], Loss: 1.3046, LR: 0.000308
[13:08:41] Epoch 192 Complete. Avg Loss: 1.5958, LR: 0.000308
  -> New best model saved (loss: 1.5958)
[13:08:41] Epoch [193/300], Step [0/384], Loss: 1.7414, LR: 0.000303
[13:08:43] Epoch [193/300], Step [20/384], Loss: 1.5587, LR: 0.000303
[13:08:46] Epoch [193/300], Step [40/384], Loss: 1.7355, LR: 0.000303
[13:08:48] Epoch [193/300], Step [60/384], Loss: 1.2846, LR: 0.000303
[13:08:50] Epoch [193/300], Step [80/384], Loss: 1.9149, LR: 0.000303
[13:08:52] Epoch [193/300], Step [100/384], Loss: 1.5094, LR: 0.000303
[13:08:54] Epoch [193/300], Step [120/384], Loss: 1.6652, LR: 0.000303
[13:08:56] Epoch [193/300], Step [140/384], Loss: 1.4540, LR: 0.000303
[13:08:59] Epoch [193/300], Step [160/384], Loss: 1.6104, LR: 0.000303
[13:09:01] Epoch [193/300], Step [180/384], Loss: 1.9428, LR: 0.000303
[13:09:03] Epoch [193/300], Step [200/384], Loss: 1.8786, LR: 0.000303
[13:09:06] Epoch [193/300], Step [220/384], Loss: 1.5388, LR: 0.000303
[13:09:08] Epoch [193/300], Step [240/384], Loss: 1.8230, LR: 0.000303
[13:09:10] Epoch [193/300], Step [260/384], Loss: 1.8638, LR: 0.000303
[13:09:12] Epoch [193/300], Step [280/384], Loss: 1.5838, LR: 0.000303
[13:09:14] Epoch [193/300], Step [300/384], Loss: 1.5347, LR: 0.000303
[13:09:16] Epoch [193/300], Step [320/384], Loss: 1.4230, LR: 0.000303
[13:09:18] Epoch [193/300], Step [340/384], Loss: 1.4406, LR: 0.000303
[13:09:21] Epoch [193/300], Step [360/384], Loss: 1.3264, LR: 0.000303
[13:09:23] Epoch [193/300], Step [380/384], Loss: 1.8355, LR: 0.000303
[13:09:23] Epoch 193 Complete. Avg Loss: 1.5945, LR: 0.000303
  -> New best model saved (loss: 1.5945)
[13:09:23] Epoch [194/300], Step [0/384], Loss: 1.2649, LR: 0.000298
[13:09:25] Epoch [194/300], Step [20/384], Loss: 1.3569, LR: 0.000298
[13:09:27] Epoch [194/300], Step [40/384], Loss: 1.3167, LR: 0.000298
[13:09:30] Epoch [194/300], Step [60/384], Loss: 1.5802, LR: 0.000298
[13:09:32] Epoch [194/300], Step [80/384], Loss: 1.5132, LR: 0.000298
[13:09:34] Epoch [194/300], Step [100/384], Loss: 1.6260, LR: 0.000298
[13:09:36] Epoch [194/300], Step [120/384], Loss: 1.6320, LR: 0.000298
[13:09:38] Epoch [194/300], Step [140/384], Loss: 1.3828, LR: 0.000298
[13:09:40] Epoch [194/300], Step [160/384], Loss: 1.7463, LR: 0.000298
[13:09:42] Epoch [194/300], Step [180/384], Loss: 1.5854, LR: 0.000298
[13:09:44] Epoch [194/300], Step [200/384], Loss: 1.3200, LR: 0.000298
[13:09:47] Epoch [194/300], Step [220/384], Loss: 1.7785, LR: 0.000298
[13:09:49] Epoch [194/300], Step [240/384], Loss: 1.6624, LR: 0.000298
[13:09:51] Epoch [194/300], Step [260/384], Loss: 1.3610, LR: 0.000298
[13:09:53] Epoch [194/300], Step [280/384], Loss: 1.7117, LR: 0.000298
[13:09:55] Epoch [194/300], Step [300/384], Loss: 1.5687, LR: 0.000298
[13:09:57] Epoch [194/300], Step [320/384], Loss: 1.4861, LR: 0.000298
[13:10:00] Epoch [194/300], Step [340/384], Loss: 1.7368, LR: 0.000298
[13:10:02] Epoch [194/300], Step [360/384], Loss: 1.8541, LR: 0.000298
[13:10:04] Epoch [194/300], Step [380/384], Loss: 1.5375, LR: 0.000298
[13:10:04] Epoch 194 Complete. Avg Loss: 1.5798, LR: 0.000298
  -> New best model saved (loss: 1.5798)
[13:10:05] Epoch [195/300], Step [0/384], Loss: 1.5155, LR: 0.000293
[13:10:07] Epoch [195/300], Step [20/384], Loss: 1.7387, LR: 0.000293
[13:10:09] Epoch [195/300], Step [40/384], Loss: 1.6002, LR: 0.000293
[13:10:11] Epoch [195/300], Step [60/384], Loss: 1.5032, LR: 0.000293
[13:10:13] Epoch [195/300], Step [80/384], Loss: 1.9328, LR: 0.000293
[13:10:15] Epoch [195/300], Step [100/384], Loss: 1.9109, LR: 0.000293
[13:10:18] Epoch [195/300], Step [120/384], Loss: 1.2421, LR: 0.000293
[13:10:20] Epoch [195/300], Step [140/384], Loss: 1.4556, LR: 0.000293
[13:10:22] Epoch [195/300], Step [160/384], Loss: 1.7946, LR: 0.000293
[13:10:24] Epoch [195/300], Step [180/384], Loss: 1.2784, LR: 0.000293
[13:10:26] Epoch [195/300], Step [200/384], Loss: 1.0327, LR: 0.000293
[13:10:28] Epoch [195/300], Step [220/384], Loss: 2.0331, LR: 0.000293
[13:10:31] Epoch [195/300], Step [240/384], Loss: 1.3824, LR: 0.000293
[13:10:33] Epoch [195/300], Step [260/384], Loss: 1.3108, LR: 0.000293
[13:10:35] Epoch [195/300], Step [280/384], Loss: 1.5555, LR: 0.000293
[13:10:37] Epoch [195/300], Step [300/384], Loss: 1.4719, LR: 0.000293
[13:10:39] Epoch [195/300], Step [320/384], Loss: 1.0892, LR: 0.000293
[13:10:42] Epoch [195/300], Step [340/384], Loss: 1.5864, LR: 0.000293
[13:10:44] Epoch [195/300], Step [360/384], Loss: 1.7185, LR: 0.000293
[13:10:46] Epoch [195/300], Step [380/384], Loss: 1.6740, LR: 0.000293
[13:10:46] Epoch 195 Complete. Avg Loss: 1.5799, LR: 0.000293
[13:10:47] Epoch [196/300], Step [0/384], Loss: 2.2667, LR: 0.000289
[13:10:49] Epoch [196/300], Step [20/384], Loss: 1.4231, LR: 0.000289
[13:10:51] Epoch [196/300], Step [40/384], Loss: 1.5181, LR: 0.000289
[13:10:53] Epoch [196/300], Step [60/384], Loss: 1.7145, LR: 0.000289
[13:10:55] Epoch [196/300], Step [80/384], Loss: 1.4053, LR: 0.000289
[13:10:57] Epoch [196/300], Step [100/384], Loss: 2.1051, LR: 0.000289
[13:11:00] Epoch [196/300], Step [120/384], Loss: 1.3890, LR: 0.000289
[13:11:02] Epoch [196/300], Step [140/384], Loss: 1.5554, LR: 0.000289
[13:11:04] Epoch [196/300], Step [160/384], Loss: 1.3165, LR: 0.000289
[13:11:06] Epoch [196/300], Step [180/384], Loss: 1.5993, LR: 0.000289
[13:11:08] Epoch [196/300], Step [200/384], Loss: 1.6915, LR: 0.000289
[13:11:10] Epoch [196/300], Step [220/384], Loss: 1.2804, LR: 0.000289
[13:11:13] Epoch [196/300], Step [240/384], Loss: 1.6902, LR: 0.000289
[13:11:15] Epoch [196/300], Step [260/384], Loss: 1.3816, LR: 0.000289
[13:11:17] Epoch [196/300], Step [280/384], Loss: 1.2831, LR: 0.000289
[13:11:19] Epoch [196/300], Step [300/384], Loss: 1.9362, LR: 0.000289
[13:11:21] Epoch [196/300], Step [320/384], Loss: 1.7390, LR: 0.000289
[13:11:23] Epoch [196/300], Step [340/384], Loss: 0.9720, LR: 0.000289
[13:11:26] Epoch [196/300], Step [360/384], Loss: 1.2140, LR: 0.000289
[13:11:28] Epoch [196/300], Step [380/384], Loss: 1.2555, LR: 0.000289
[13:11:28] Epoch 196 Complete. Avg Loss: 1.5724, LR: 0.000289
  -> New best model saved (loss: 1.5724)
[13:11:28] Epoch [197/300], Step [0/384], Loss: 1.4598, LR: 0.000284
[13:11:31] Epoch [197/300], Step [20/384], Loss: 1.3999, LR: 0.000284
[13:11:33] Epoch [197/300], Step [40/384], Loss: 1.2820, LR: 0.000284
[13:11:35] Epoch [197/300], Step [60/384], Loss: 0.9648, LR: 0.000284
[13:11:37] Epoch [197/300], Step [80/384], Loss: 1.1470, LR: 0.000284
[13:11:39] Epoch [197/300], Step [100/384], Loss: 1.4664, LR: 0.000284
[13:11:41] Epoch [197/300], Step [120/384], Loss: 1.4060, LR: 0.000284
[13:11:44] Epoch [197/300], Step [140/384], Loss: 1.5303, LR: 0.000284
[13:11:46] Epoch [197/300], Step [160/384], Loss: 1.7146, LR: 0.000284
[13:11:48] Epoch [197/300], Step [180/384], Loss: 1.5921, LR: 0.000284
[13:11:50] Epoch [197/300], Step [200/384], Loss: 1.3980, LR: 0.000284
[13:11:52] Epoch [197/300], Step [220/384], Loss: 1.5723, LR: 0.000284
[13:11:54] Epoch [197/300], Step [240/384], Loss: 1.4605, LR: 0.000284
[13:11:56] Epoch [197/300], Step [260/384], Loss: 1.7301, LR: 0.000284
[13:11:59] Epoch [197/300], Step [280/384], Loss: 1.4389, LR: 0.000284
[13:12:01] Epoch [197/300], Step [300/384], Loss: 1.5406, LR: 0.000284
[13:12:03] Epoch [197/300], Step [320/384], Loss: 1.5377, LR: 0.000284
[13:12:06] Epoch [197/300], Step [340/384], Loss: 1.7413, LR: 0.000284
[13:12:08] Epoch [197/300], Step [360/384], Loss: 1.5423, LR: 0.000284
[13:12:10] Epoch [197/300], Step [380/384], Loss: 1.4214, LR: 0.000284
[13:12:10] Epoch 197 Complete. Avg Loss: 1.5564, LR: 0.000284
  -> New best model saved (loss: 1.5564)
[13:12:10] Epoch [198/300], Step [0/384], Loss: 1.4647, LR: 0.000279
[13:12:13] Epoch [198/300], Step [20/384], Loss: 1.4624, LR: 0.000279
[13:12:15] Epoch [198/300], Step [40/384], Loss: 1.2226, LR: 0.000279
[13:12:17] Epoch [198/300], Step [60/384], Loss: 2.1286, LR: 0.000279
[13:12:19] Epoch [198/300], Step [80/384], Loss: 1.6377, LR: 0.000279
[13:12:22] Epoch [198/300], Step [100/384], Loss: 1.9234, LR: 0.000279
[13:12:24] Epoch [198/300], Step [120/384], Loss: 1.7333, LR: 0.000279
[13:12:26] Epoch [198/300], Step [140/384], Loss: 1.7193, LR: 0.000279
[13:12:28] Epoch [198/300], Step [160/384], Loss: 1.5229, LR: 0.000279
[13:12:30] Epoch [198/300], Step [180/384], Loss: 1.7834, LR: 0.000279
[13:12:33] Epoch [198/300], Step [200/384], Loss: 1.6198, LR: 0.000279
[13:12:35] Epoch [198/300], Step [220/384], Loss: 1.6224, LR: 0.000279
[13:12:37] Epoch [198/300], Step [240/384], Loss: 1.0080, LR: 0.000279
[13:12:39] Epoch [198/300], Step [260/384], Loss: 1.6737, LR: 0.000279
[13:12:41] Epoch [198/300], Step [280/384], Loss: 1.9436, LR: 0.000279
[13:12:43] Epoch [198/300], Step [300/384], Loss: 1.5416, LR: 0.000279
[13:12:45] Epoch [198/300], Step [320/384], Loss: 1.6405, LR: 0.000279
[13:12:48] Epoch [198/300], Step [340/384], Loss: 1.6073, LR: 0.000279
[13:12:50] Epoch [198/300], Step [360/384], Loss: 1.2954, LR: 0.000279
[13:12:52] Epoch [198/300], Step [380/384], Loss: 1.6475, LR: 0.000279
[13:12:53] Epoch 198 Complete. Avg Loss: 1.5489, LR: 0.000279
  -> New best model saved (loss: 1.5489)
[13:12:53] Epoch [199/300], Step [0/384], Loss: 1.1037, LR: 0.000274
[13:12:55] Epoch [199/300], Step [20/384], Loss: 1.4386, LR: 0.000274
[13:12:57] Epoch [199/300], Step [40/384], Loss: 1.7669, LR: 0.000274
[13:12:59] Epoch [199/300], Step [60/384], Loss: 1.4632, LR: 0.000274
[13:13:01] Epoch [199/300], Step [80/384], Loss: 2.0063, LR: 0.000274
[13:13:04] Epoch [199/300], Step [100/384], Loss: 1.5958, LR: 0.000274
[13:13:06] Epoch [199/300], Step [120/384], Loss: 1.9853, LR: 0.000274
[13:13:08] Epoch [199/300], Step [140/384], Loss: 1.6898, LR: 0.000274
[13:13:10] Epoch [199/300], Step [160/384], Loss: 1.3013, LR: 0.000274
[13:13:12] Epoch [199/300], Step [180/384], Loss: 1.2373, LR: 0.000274
[13:13:15] Epoch [199/300], Step [200/384], Loss: 1.3034, LR: 0.000274
[13:13:17] Epoch [199/300], Step [220/384], Loss: 1.3481, LR: 0.000274
[13:13:19] Epoch [199/300], Step [240/384], Loss: 1.4342, LR: 0.000274
[13:13:21] Epoch [199/300], Step [260/384], Loss: 1.8236, LR: 0.000274
[13:13:24] Epoch [199/300], Step [280/384], Loss: 1.2051, LR: 0.000274
[13:13:26] Epoch [199/300], Step [300/384], Loss: 1.0957, LR: 0.000274
[13:13:28] Epoch [199/300], Step [320/384], Loss: 1.4485, LR: 0.000274
[13:13:30] Epoch [199/300], Step [340/384], Loss: 1.4017, LR: 0.000274
[13:13:32] Epoch [199/300], Step [360/384], Loss: 1.5650, LR: 0.000274
[13:13:34] Epoch [199/300], Step [380/384], Loss: 1.5123, LR: 0.000274
[13:13:35] Epoch 199 Complete. Avg Loss: 1.5413, LR: 0.000274
  -> New best model saved (loss: 1.5413)
[13:13:35] Epoch [200/300], Step [0/384], Loss: 1.8550, LR: 0.000270
[13:13:37] Epoch [200/300], Step [20/384], Loss: 1.4002, LR: 0.000270
[13:13:39] Epoch [200/300], Step [40/384], Loss: 1.7076, LR: 0.000270
[13:13:42] Epoch [200/300], Step [60/384], Loss: 1.1903, LR: 0.000270
[13:13:44] Epoch [200/300], Step [80/384], Loss: 1.4246, LR: 0.000270
[13:13:46] Epoch [200/300], Step [100/384], Loss: 1.9921, LR: 0.000270
[13:13:48] Epoch [200/300], Step [120/384], Loss: 1.5332, LR: 0.000270
[13:13:50] Epoch [200/300], Step [140/384], Loss: 1.4233, LR: 0.000270
[13:13:52] Epoch [200/300], Step [160/384], Loss: 1.9455, LR: 0.000270
[13:13:54] Epoch [200/300], Step [180/384], Loss: 1.3943, LR: 0.000270
[13:13:56] Epoch [200/300], Step [200/384], Loss: 1.8863, LR: 0.000270
[13:13:59] Epoch [200/300], Step [220/384], Loss: 1.6045, LR: 0.000270
[13:14:01] Epoch [200/300], Step [240/384], Loss: 1.6252, LR: 0.000270
[13:14:03] Epoch [200/300], Step [260/384], Loss: 1.6823, LR: 0.000270
[13:14:06] Epoch [200/300], Step [280/384], Loss: 1.8024, LR: 0.000270
[13:14:08] Epoch [200/300], Step [300/384], Loss: 1.1791, LR: 0.000270
[13:14:10] Epoch [200/300], Step [320/384], Loss: 1.5933, LR: 0.000270
[13:14:12] Epoch [200/300], Step [340/384], Loss: 1.6666, LR: 0.000270
[13:14:15] Epoch [200/300], Step [360/384], Loss: 1.6305, LR: 0.000270
[13:14:17] Epoch [200/300], Step [380/384], Loss: 1.4467, LR: 0.000270
[13:14:17] Epoch 200 Complete. Avg Loss: 1.5385, LR: 0.000270
  -> New best model saved (loss: 1.5385)
[13:14:17] Epoch [201/300], Step [0/384], Loss: 1.6746, LR: 0.000265
[13:14:20] Epoch [201/300], Step [20/384], Loss: 1.5017, LR: 0.000265
[13:14:23] Epoch [201/300], Step [40/384], Loss: 1.2966, LR: 0.000265
[13:14:25] Epoch [201/300], Step [60/384], Loss: 1.5955, LR: 0.000265
[13:14:28] Epoch [201/300], Step [80/384], Loss: 1.7841, LR: 0.000265
[13:14:30] Epoch [201/300], Step [100/384], Loss: 1.5928, LR: 0.000265
[13:14:32] Epoch [201/300], Step [120/384], Loss: 1.4633, LR: 0.000265
[13:14:34] Epoch [201/300], Step [140/384], Loss: 1.0989, LR: 0.000265
[13:14:36] Epoch [201/300], Step [160/384], Loss: 1.6545, LR: 0.000265
[13:14:39] Epoch [201/300], Step [180/384], Loss: 0.9211, LR: 0.000265
[13:14:41] Epoch [201/300], Step [200/384], Loss: 1.1816, LR: 0.000265
[13:14:43] Epoch [201/300], Step [220/384], Loss: 1.7001, LR: 0.000265
[13:14:45] Epoch [201/300], Step [240/384], Loss: 2.3644, LR: 0.000265
[13:14:48] Epoch [201/300], Step [260/384], Loss: 1.8407, LR: 0.000265
[13:14:50] Epoch [201/300], Step [280/384], Loss: 1.5337, LR: 0.000265
[13:14:52] Epoch [201/300], Step [300/384], Loss: 1.2898, LR: 0.000265
[13:14:54] Epoch [201/300], Step [320/384], Loss: 1.3065, LR: 0.000265
[13:14:56] Epoch [201/300], Step [340/384], Loss: 1.8218, LR: 0.000265
[13:14:58] Epoch [201/300], Step [360/384], Loss: 1.0914, LR: 0.000265
[13:15:01] Epoch [201/300], Step [380/384], Loss: 1.2970, LR: 0.000265
[13:15:01] Epoch 201 Complete. Avg Loss: 1.5369, LR: 0.000265
  -> New best model saved (loss: 1.5369)
[13:15:01] Epoch [202/300], Step [0/384], Loss: 1.5387, LR: 0.000261
[13:15:03] Epoch [202/300], Step [20/384], Loss: 1.2620, LR: 0.000261
[13:15:06] Epoch [202/300], Step [40/384], Loss: 1.3815, LR: 0.000261
[13:15:08] Epoch [202/300], Step [60/384], Loss: 1.3351, LR: 0.000261
[13:15:10] Epoch [202/300], Step [80/384], Loss: 1.8818, LR: 0.000261
[13:15:12] Epoch [202/300], Step [100/384], Loss: 1.4262, LR: 0.000261
[13:15:14] Epoch [202/300], Step [120/384], Loss: 1.5748, LR: 0.000261
[13:15:17] Epoch [202/300], Step [140/384], Loss: 1.6047, LR: 0.000261
[13:15:19] Epoch [202/300], Step [160/384], Loss: 1.9597, LR: 0.000261
[13:15:21] Epoch [202/300], Step [180/384], Loss: 1.4481, LR: 0.000261
[13:15:23] Epoch [202/300], Step [200/384], Loss: 1.4272, LR: 0.000261
[13:15:26] Epoch [202/300], Step [220/384], Loss: 1.4857, LR: 0.000261
[13:15:28] Epoch [202/300], Step [240/384], Loss: 1.9835, LR: 0.000261
[13:15:30] Epoch [202/300], Step [260/384], Loss: 1.3986, LR: 0.000261
[13:15:32] Epoch [202/300], Step [280/384], Loss: 1.3053, LR: 0.000261
[13:15:35] Epoch [202/300], Step [300/384], Loss: 1.6657, LR: 0.000261
[13:15:37] Epoch [202/300], Step [320/384], Loss: 1.4962, LR: 0.000261
[13:15:39] Epoch [202/300], Step [340/384], Loss: 2.1118, LR: 0.000261
[13:15:41] Epoch [202/300], Step [360/384], Loss: 1.3284, LR: 0.000261
[13:15:44] Epoch [202/300], Step [380/384], Loss: 1.7252, LR: 0.000261
[13:15:44] Epoch 202 Complete. Avg Loss: 1.5240, LR: 0.000261
  -> New best model saved (loss: 1.5240)
[13:15:44] Epoch [203/300], Step [0/384], Loss: 1.7835, LR: 0.000256
[13:15:47] Epoch [203/300], Step [20/384], Loss: 1.5744, LR: 0.000256
[13:15:49] Epoch [203/300], Step [40/384], Loss: 1.7861, LR: 0.000256
[13:15:51] Epoch [203/300], Step [60/384], Loss: 1.5449, LR: 0.000256
[13:15:53] Epoch [203/300], Step [80/384], Loss: 1.6488, LR: 0.000256
[13:15:55] Epoch [203/300], Step [100/384], Loss: 1.7986, LR: 0.000256
[13:15:57] Epoch [203/300], Step [120/384], Loss: 1.2608, LR: 0.000256
[13:16:00] Epoch [203/300], Step [140/384], Loss: 1.3310, LR: 0.000256
[13:16:02] Epoch [203/300], Step [160/384], Loss: 1.6413, LR: 0.000256
[13:16:04] Epoch [203/300], Step [180/384], Loss: 1.2652, LR: 0.000256
[13:16:07] Epoch [203/300], Step [200/384], Loss: 1.5325, LR: 0.000256
[13:16:09] Epoch [203/300], Step [220/384], Loss: 1.3740, LR: 0.000256
[13:16:11] Epoch [203/300], Step [240/384], Loss: 1.1789, LR: 0.000256
[13:16:13] Epoch [203/300], Step [260/384], Loss: 1.3670, LR: 0.000256
[13:16:16] Epoch [203/300], Step [280/384], Loss: 1.5632, LR: 0.000256
[13:16:18] Epoch [203/300], Step [300/384], Loss: 1.4986, LR: 0.000256
[13:16:21] Epoch [203/300], Step [320/384], Loss: 1.2048, LR: 0.000256
[13:16:23] Epoch [203/300], Step [340/384], Loss: 1.1414, LR: 0.000256
[13:16:25] Epoch [203/300], Step [360/384], Loss: 1.7174, LR: 0.000256
[13:16:28] Epoch [203/300], Step [380/384], Loss: 1.5454, LR: 0.000256
[13:16:28] Epoch 203 Complete. Avg Loss: 1.5422, LR: 0.000256
[13:16:28] Epoch [204/300], Step [0/384], Loss: 1.4053, LR: 0.000251
[13:16:30] Epoch [204/300], Step [20/384], Loss: 1.8127, LR: 0.000251
[13:16:32] Epoch [204/300], Step [40/384], Loss: 1.4766, LR: 0.000251
[13:16:35] Epoch [204/300], Step [60/384], Loss: 1.2792, LR: 0.000251
[13:16:37] Epoch [204/300], Step [80/384], Loss: 1.5160, LR: 0.000251
[13:16:39] Epoch [204/300], Step [100/384], Loss: 1.3483, LR: 0.000251
[13:16:41] Epoch [204/300], Step [120/384], Loss: 1.6079, LR: 0.000251
[13:16:44] Epoch [204/300], Step [140/384], Loss: 1.2436, LR: 0.000251
[13:16:46] Epoch [204/300], Step [160/384], Loss: 1.4155, LR: 0.000251
[13:16:48] Epoch [204/300], Step [180/384], Loss: 1.1495, LR: 0.000251
[13:16:50] Epoch [204/300], Step [200/384], Loss: 1.8435, LR: 0.000251
[13:16:52] Epoch [204/300], Step [220/384], Loss: 1.4830, LR: 0.000251
[13:16:55] Epoch [204/300], Step [240/384], Loss: 1.5715, LR: 0.000251
[13:16:57] Epoch [204/300], Step [260/384], Loss: 1.1271, LR: 0.000251
[13:16:59] Epoch [204/300], Step [280/384], Loss: 1.2460, LR: 0.000251
[13:17:01] Epoch [204/300], Step [300/384], Loss: 1.5348, LR: 0.000251
[13:17:03] Epoch [204/300], Step [320/384], Loss: 1.7790, LR: 0.000251
[13:17:05] Epoch [204/300], Step [340/384], Loss: 1.7292, LR: 0.000251
[13:17:08] Epoch [204/300], Step [360/384], Loss: 1.5382, LR: 0.000251
[13:17:10] Epoch [204/300], Step [380/384], Loss: 1.7596, LR: 0.000251
[13:17:10] Epoch 204 Complete. Avg Loss: 1.5122, LR: 0.000251
  -> New best model saved (loss: 1.5122)
[13:17:10] Epoch [205/300], Step [0/384], Loss: 1.4708, LR: 0.000247
[13:17:12] Epoch [205/300], Step [20/384], Loss: 1.4771, LR: 0.000247
[13:17:15] Epoch [205/300], Step [40/384], Loss: 1.7113, LR: 0.000247
[13:17:17] Epoch [205/300], Step [60/384], Loss: 1.1846, LR: 0.000247
[13:17:19] Epoch [205/300], Step [80/384], Loss: 1.5345, LR: 0.000247
[13:17:21] Epoch [205/300], Step [100/384], Loss: 1.6860, LR: 0.000247
[13:17:24] Epoch [205/300], Step [120/384], Loss: 1.7475, LR: 0.000247
[13:17:26] Epoch [205/300], Step [140/384], Loss: 1.8662, LR: 0.000247
[13:17:28] Epoch [205/300], Step [160/384], Loss: 1.2130, LR: 0.000247
[13:17:30] Epoch [205/300], Step [180/384], Loss: 1.7315, LR: 0.000247
[13:17:32] Epoch [205/300], Step [200/384], Loss: 1.6094, LR: 0.000247
[13:17:34] Epoch [205/300], Step [220/384], Loss: 1.7863, LR: 0.000247
[13:17:37] Epoch [205/300], Step [240/384], Loss: 1.4550, LR: 0.000247
[13:17:39] Epoch [205/300], Step [260/384], Loss: 1.2016, LR: 0.000247
[13:17:41] Epoch [205/300], Step [280/384], Loss: 1.5778, LR: 0.000247
[13:17:43] Epoch [205/300], Step [300/384], Loss: 1.7021, LR: 0.000247
[13:17:45] Epoch [205/300], Step [320/384], Loss: 2.0476, LR: 0.000247
[13:17:47] Epoch [205/300], Step [340/384], Loss: 1.9066, LR: 0.000247
[13:17:50] Epoch [205/300], Step [360/384], Loss: 1.4542, LR: 0.000247
[13:17:52] Epoch [205/300], Step [380/384], Loss: 1.5551, LR: 0.000247
[13:17:52] Epoch 205 Complete. Avg Loss: 1.5004, LR: 0.000247
  -> New best model saved (loss: 1.5004)
[13:17:52] Epoch [206/300], Step [0/384], Loss: 1.7457, LR: 0.000242
[13:17:55] Epoch [206/300], Step [20/384], Loss: 1.5441, LR: 0.000242
[13:17:57] Epoch [206/300], Step [40/384], Loss: 1.6440, LR: 0.000242
[13:17:59] Epoch [206/300], Step [60/384], Loss: 1.5662, LR: 0.000242
[13:18:02] Epoch [206/300], Step [80/384], Loss: 1.3011, LR: 0.000242
[13:18:04] Epoch [206/300], Step [100/384], Loss: 1.2058, LR: 0.000242
[13:18:06] Epoch [206/300], Step [120/384], Loss: 1.3530, LR: 0.000242
[13:18:08] Epoch [206/300], Step [140/384], Loss: 1.3466, LR: 0.000242
[13:18:11] Epoch [206/300], Step [160/384], Loss: 1.0954, LR: 0.000242
[13:18:13] Epoch [206/300], Step [180/384], Loss: 1.6828, LR: 0.000242
[13:18:15] Epoch [206/300], Step [200/384], Loss: 1.2467, LR: 0.000242
[13:18:17] Epoch [206/300], Step [220/384], Loss: 1.6124, LR: 0.000242
[13:18:20] Epoch [206/300], Step [240/384], Loss: 1.3206, LR: 0.000242
[13:18:22] Epoch [206/300], Step [260/384], Loss: 1.4612, LR: 0.000242
[13:18:24] Epoch [206/300], Step [280/384], Loss: 1.3990, LR: 0.000242
[13:18:26] Epoch [206/300], Step [300/384], Loss: 1.6295, LR: 0.000242
[13:18:28] Epoch [206/300], Step [320/384], Loss: 1.2135, LR: 0.000242
[13:18:31] Epoch [206/300], Step [340/384], Loss: 1.8042, LR: 0.000242
[13:18:33] Epoch [206/300], Step [360/384], Loss: 1.3516, LR: 0.000242
[13:18:35] Epoch [206/300], Step [380/384], Loss: 1.0435, LR: 0.000242
[13:18:35] Epoch 206 Complete. Avg Loss: 1.4980, LR: 0.000242
  -> New best model saved (loss: 1.4980)
[13:18:35] Epoch [207/300], Step [0/384], Loss: 1.4307, LR: 0.000238
[13:18:38] Epoch [207/300], Step [20/384], Loss: 1.8909, LR: 0.000238
[13:18:40] Epoch [207/300], Step [40/384], Loss: 1.5349, LR: 0.000238
